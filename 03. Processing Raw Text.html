<html lang="ru" dir="ltr" xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ascii"></meta>
<meta name="generator" content="Docutils 0.12: http://docutils.sourceforge.net/"></meta>
<title></title>
<style type="text/css">/* :Author: Edward Loper, James Curran:Copyright: This stylesheet has been placed in the public domain.Stylesheet for use with Docutils.This stylesheet defines new css classes used by NLTK.It uses a Python syntax highlighting scheme that matchesthe colour scheme used by IDLE, which makes it easier forbeginners to check they are typing things in correctly. */
/* Include the standard docutils stylesheet. */
</style>
</head>
<body dir="ltr">
<div class="document">


<!-- -*- mode: rst -*- -->
<!-- -*- mode: rst -*- -->
<!-- CAP abbreviations (map to small caps in LaTeX) -->
<!-- Other candidates for global consistency -->
<!-- PTB removed since it must be indexed -->
<!-- WN removed since it must be indexed -->
<!-- misc & punctuation -->
<!-- cdots was unicode U+22EF but not working -->
<!-- exercise meta-tags -->
<!-- Unicode tests -->
<!-- phonetic -->
<!-- misc -->
<!-- used in Unicode section -->
<!-- arrows -->
<!-- unification stuff -->
<!-- Math & Logic -->
<!-- sets -->
<!-- Greek -->
<!-- Chinese -->
<!-- URLs -->
<!-- Python example - a snippet of code in running text -->
<!-- PlaceHolder example -  something that should be replaced by actual code -->
<!-- Linguistic eXample - cited form in running text -->
<!-- Emphasized (more declarative than just using *) -->
<!-- Grammatical Category - e.g. NP and verb as technical terms
.. role:: gc
   :class: category -->
<!-- Math expression - e.g. especially for variables -->
<!-- Textual Math expression - for words &#39;inside&#39; a math environment -->
<!-- Feature (or attribute) -->
<!-- Raw LaTeX -->
<!-- Raw HTML -->
<!-- Feature-value -->
<!-- Lexemes -->
<!-- Replacements that rely on previous definitions :-) -->
<div class="compound">
</div>
<!-- standard global imports

>>> import nltk, re, pprint
>>> from nltk import word_tokenize -->
<!-- TODO: more on regular expressions, including () -->
<!-- TODO: talk about fact that English lexicon is open set (e.g. malware = malicious software) -->
<!-- TODO: add pointers to regexp toolkits (e.g. Kodos) -->
<!-- TODO: other issues
- nltk.corpus.brown.items returns a tuple, not a list (cf discussion in ch 6)
- invocation of pprint.pprint is a little clunky
- regexp_tokenize() doesn&#39;t work when it is given a compiled pattern -->
<!-- TODO: add more graphical plots -->
<!-- TODO: map and reduce -->
<!-- FreqDist of CHARACTER BIGRAMS... -->
<!-- TODO: corpus of word frequencies, so we can do certain tasks on the n most frequent words -->
<!-- TODO: plain wsj corpus -->
<!-- TODO: cover tag soup when talking about HTML -->
<!-- TODO: type conversion using int(), list(), etc -->
<!-- TODO: vowel harmony example: extract vowel sequence using re.findall; extract bigrams from the
vowel sequences; then build a conditional frequency distribution -->
<div class="section" id="processing-raw-text">
<span id="chap-words"></span><h1>3 Обработка исходного текста</h1>
<p>Наиболее важным источником текстов, несомненно, является Сеть.  Удобно иметь существующие текстовые коллекции для изучения, такие как своды, которые мы видели в предыдущих главах.  Тем не менее, вы, вероятно, имеете в виду свои собственные источники текста, и вам нужно узнать, как получить к ним доступ.</p>
<p>Цель этой главы заключается в том, чтобы ответить на следующие вопросы:</p>
<ol class="arabic simple">
<li>Как мы можем писать программы для доступа к тексту из локальных файлов и из сети для того, чтобы овладеть неограниченным рядом языкового материала?</li>
<li>Как мы можем разделить документы на отдельные слова и символы пунктуации, чтобы мы могли выполнять те же виды анализа, которые мы выполняли с текстовыми корпусами в предыдущих главах?</li>
<li>Как мы можем писать программы, чтобы получить форматированный текст и сохранить его в файле?</li>
</ol>
<p>Для решения этих вопросов, мы будем рассматривать ключевые концепции NLP, в том числе токенизацию и стемминг.
Параллельно вы будете консолидировать свои знания Python и узнаете о строках, файлах и регулярных выражениях.  Поскольку так много текста в Интернете в формате HTML, мы также увидим, как освободить текст от разметки.</p>
<div class="note">
<p class="first admonition-title">Замечание</p>
<p><strong>Важно:</strong> 
Начиная с этой главы наши образцы программ будут предполагать, что вы начинаете интерактивный сеанс или программу со следующих предложений импорта:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; from __future__ import division  # Python 2 users only
&gt;&gt;&gt; import nltk, re, pprint
&gt;&gt;&gt; from nltk import word_tokenize</pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="accessing-text-from-the-web-and-from-disk">
<span id="sec-accessing-text"></span><h2>3.1 Обращение к тексту в сети и на диске</h2>
<div class="section" id="electronic-books">
<h3>Электронные книги</h3>
<p>Небольшой образец текстов из Project Gutenberg есть в коллекции корпусов NLTK.
Однако вы можете быть заинтересованы в анализе других текстов из Project Gutenberg.
Вы можете просмотреть каталог 25.000 бесплатных онлайн книг на <tt class="doctest"><span class="pre">http://www.gutenberg.org/catalog/</span></tt>, и получить URL в ASCII текстовый файл.
Хотя 90% текстов в Project Gutenberg на английском языке, он включает в себя материал на более чем 50 других языках, включая каталанский, китайский, голландский, финский, французский, немецкий, итальянский, португальский и испанский языки (с более чем 100 текстов на каждом).</p>
<p>Текст номер 2554 является английским переводом <em>Преступления и наказания</em>, и мы можем получить доступ к нему следующим образом.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; from urllib import request
&gt;&gt;&gt; url = "http://www.gutenberg.org/files/2554/2554.txt"
&gt;&gt;&gt; response = request.urlopen(url)
&gt;&gt;&gt; raw = response.read().decode('utf8')
&gt;&gt;&gt; type(raw)
&lt;class 'str'&gt;
&gt;&gt;&gt; len(raw)
1176893
&gt;&gt;&gt; raw[:75]
'The Project Gutenberg EBook of Crime and Punishment, by Fyodor Dostoevsky\r\n'</pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="note">
<p class="first admonition-title">Замечание</p>
<p>Выполнение <tt class="doctest"><span class="pre">read()</span></tt> займет несколько секунд, пока он загружает эту большую книгу.
Если вы используете прокси, который не правильно определяется Python, вам может понадобиться указать прокси вручную перед использованием <tt class="doctest"><span class="pre">urlopen</span></tt> следующим образом:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; proxies = {'http': 'http://www.someproxy.com:3128'}
&gt;&gt;&gt; request.ProxyHandler(proxies)</pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<p>Переменная <tt class="doctest"><span class="pre">raw</span></tt> содержит строку с 1.176.893 символами.
(Мы можем увидеть, что это строка, используя <tt class="doctest"><span class="pre">type(raw)</span></tt>.)
Это необработанное содержание книги, включающее многие детали, в которых мы не заинтересованы, таких как пробелы, разрывы строк и пустые строки.  Обратите внимание на <tt class="doctest"><span class="pre">\г</span></tt> и <tt class="doctest"><span class="pre">\n</span></tt> в открывающей строке файла, который представляет собой то, как Python отображает специальные символы возврата каретки и перевода строки (файл должно быть был создан на компьютере Windows).  Для нашей обработки языка мы хотим разбить строку на слова и знаки препинания, как мы видели в <a class="reference external" href="http://www.nltk.org/book/ch01.html#chap-introduction">1.</a>.  Этот шаг называется <a name="tokenization_index_term"></a><span class="termdef">токенизация</span>, и она производит нашу знакомую структуру, список слов и знаков препинания.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; tokens = word_tokenize(raw)
&gt;&gt;&gt; type(tokens)
&lt;class 'list'&gt;
&gt;&gt;&gt; len(tokens)
254354
&gt;&gt;&gt; tokens[:10]
['The', 'Project', 'Gutenberg', 'EBook', 'of', 'Crime', 'and', 'Punishment', ',', 'by']</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Обратите внимание на то, что NLTK был необходим для токенизации, но не для какой-либо из предыдущих задач открытия URL и считывания ее в строку.
Если мы теперь сделаем еще один шаг в создании текста NLTK из этого списка, мы можем выполнить всю другую лингвистическую обработку, которую мы видели в <a class="reference external" href="http://www.nltk.org/book/ch01.html#chap-introduction">1.</a>, наряду с регулярными списочными операциями, такими как слайсинг:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; text = nltk.Text(tokens)
&gt;&gt;&gt; type(text)
&lt;class 'nltk.text.Text'&gt;
&gt;&gt;&gt; text[1024:1062]
['CHAPTER', 'I', 'On', 'an', 'exceptionally', 'hot', 'evening', 'early', 'in',
 'July', 'a', 'young', 'man', 'came', 'out', 'of', 'the', 'garret', 'in',
 'which', 'he', 'lodged', 'in', 'S.', 'Place', 'and', 'walked', 'slowly',
 ',', 'as', 'though', 'in', 'hesitation', ',', 'towards', 'K.', 'bridge', '.']
&gt;&gt;&gt; text.collocations()
Katerina Ivanovna; Pyotr Petrovitch; Pulcheria Alexandrovna; Avdotya
Romanovna; Rodion Romanovitch; Marfa Petrovna; Sofya Semyonovna; old
woman; Project Gutenberg-tm; Porfiry Petrovitch; Amalia Ivanovna;
great deal; Nikodim Fomitch; young man; Ilya Petrovitch; n't know;
Project Gutenberg; Dmitri Prokofitch; Andrey Semyonovitch; Hay Market</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Обратите внимание на то, что <span class="example">Project Gutenberg</span> выглядит как словосочетание.
Это происходит потому, что каждый текст, загруженный из Project Gutenberg, содержит заголовок с названием текста, именем автора, именами людей, которые сканировали и исправили текст, лицензию и так далее.  Иногда эта информация появляется в колонтитулах в конце файла.  Мы не можем надежно обнаружить, где содержание начинается и заканчивается, и поэтому нам приходится прибегать к ручной проверке файла, чтобы обнаружить уникальные строки, которые отмечают начало и конец, до обрезки <tt class="doctest"><span class="pre">raw</span></tt>, чтобы в нем было только содержание и больше ничего:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; raw.find("PART I")
5338
&gt;&gt;&gt; raw.rfind("End of Project Gutenberg's Crime")
1157743
&gt;&gt;&gt; raw = raw[5338:1157743] 
&gt;&gt;&gt; raw.find("PART I")
0</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Методы <tt class="doctest"><span class="pre">find()</span></tt> и <tt class="doctest"><span class="pre">rfind()</span></tt> ( "обратный поиск") помогают нам получить правильные значения индекса для слайсинга строки <a class="reference internal" href="http://www.nltk.org/book/ch03.html#raw-slice"><span id="ref-raw-slice"><img class="callout" alt="[1]" src="http://www.nltk.org/book/callouts/callout1.gif"></span></a>.
Мы перезаписываем <tt class="doctest"><span class="pre">raw</span></tt> этой вырезкой, так что теперь он начинается с "Часть I" и идет до (но не включая) фразы, которая отмечает конец содержания.</p>
<p>Это была наша первая встреча с реальностью сети: тексты, найденные в сети, могут содержать нежелательный материал, а автоматического способа удалить его может не быть.
Но с помощью небольшого количества дополнительной работы мы можем извлечь материал, который нам нужен.</p>
</div>
<div class="section" id="dealing-with-html">
<h3>Работа с HTML</h3>
<p>Большая часть текста в Интернете находится в формате HTML-документов.
Вы можете использовать веб-браузер, чтобы сохранить страницу в виде текста в локальный файл, а затем получить доступ к этому, как описано в разделе о файлах ниже.
Тем не менее, если вы собираетесь делать это часто, легче всего поручить Python делать эту работу.  Первый шаг такой же, как и раньше, с использованием <tt class="doctest"><span class="pre">urlopen</span></tt>.  Забавы ради мы выберем историю BBC News под названием <em>Блондинки вымрут через 200 лет</em>, городская легенда выданная BBC за установленный научный факт:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; url = "http://news.bbc.co.uk/2/hi/health/2284783.stm"
&gt;&gt;&gt; html = request.urlopen(url).read().decode('utf8')
&gt;&gt;&gt; html[:60]
'&lt;!doctype html public "-//W3C//DTD HTML 4.0 Transitional//EN'</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Вы можете ввести <tt class="doctest"><span class="pre"><span class="pysrc-keyword">print</span>(html)</span></tt>, чтобы увидеть содержимое HTML во всей своей красе, включая метатеги, карту изображений, JavaScript, формы и таблицы.</p>
<p>Чтобы получить текст из HTML мы будем использовать библиотеку Python под названием <em>BeautifulSoup</em> доступную для скачивания с сайта <tt class="doctest"><span class="pre">http://www.crummy.com/software/BeautifulSoup/</span></tt>:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; from bs4 import BeautifulSoup
&gt;&gt;&gt; raw = BeautifulSoup(html).get_text()
&gt;&gt;&gt; tokens = word_tokenize(raw)
&gt;&gt;&gt; tokens
['BBC', 'NEWS', '|', 'Health', '|', 'Blondes', "'to", 'die', 'out', ...]</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Этот список все еще содержит нежелательный материал, касающийся навигации по сайту, и связанные истории.  Методом проб и ошибок вы можете найти начальные и конечные индексы содержания, выбрать токены, представляющие интерес, и инициализировать текст, как мы делали до этого.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; tokens = tokens[110:390]
&gt;&gt;&gt; text = nltk.Text(tokens)
&gt;&gt;&gt; text.concordance('gene')
Displaying 5 of 5 matches:
hey say too few people now carry the gene for blondes to last beyond the next
blonde hair is caused by a recessive gene . In order for a child to have blond
have blonde hair , it must have the gene on both sides of the family in the g
ere is a disadvantage of having that gene or by chance . They do n't disappear
des would disappear is if having the gene was a disadvantage and I do not thin</pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="processing-search-engine-results">
<h3>Обработка результатов работы поисковых систем</h3>
<p>Сеть можно рассматривать как огромный корпус неаннотированного текста.  Системы веб-поиска обеспечивают эффективное средство поиска релевантных лингвистических примеров в таком большом количестве текста.  Основным преимуществом поисковых систем является размер: так как вы ищете в таком большом наборе документов, у вас больше шансов найти какой-либо лингвистический паттерн, в котором вы заинтересованы.  Более того, вы можете использовать очень узкие паттерны, которым будут соответствовать только один или два примера на меньшем материале, но которым могут соответствовать десятки тысяч примеров, когда поиск выполняется в сети.  Вторым преимуществом систем веб-поиска является то, что они очень просты в использовании.  Таким образом, они обеспечивают очень удобный инструмент для быстрой проверки теории, позволяют увидеть, является ли она приемлемой.</p>
<!-- XXX Accessing a search engine programmatically: search results; counts;
Python code to produce the contents of tab-absolutely_; mention
Yahoo Python API and xref to discussion of this in chap-data_.] -->
<span class="target" id="tab-absolutely"></span><table border="1" class="docutils" id="tab-absolutely">
<colgroup>
<col width="27%">
<col width="19%">
<col width="17%">
<col width="17%">
<col width="20%">
</colgroup>
<thead valign="bottom">
<tr><th class="head">Google хиты</th>
<th class="head"><span class="example">adore</span></th>
<th class="head"><span class="example">love</span></th>
<th class="head"><span class="example">like</span></th>
<th class="head"><span class="example">prefer</span></th>
</tr>
</thead>
<tbody valign="top">
<tr><td><span class="example">absolutely</span></td>
<td>289.000</td>
<td>905.000</td>
<td>16.200</td>
<td>644</td>
</tr>
<tr><td><span class="example">definitely</span></td>
<td>1.460</td>
<td>51.000</td>
<td>158.000</td>
<td>62.600</td>
</tr>
<tr><td>соотношение</td>
<td>198: 1</td>
<td>18: 1</td>
<td>1:10</td>
<td>1:97</td>
</tr>
</tbody>
<td><p class="caption"><span class="caption-label">Таблица 3.1:</span> <p>Google хиты для словосочетаний: число обращений к словосочетаниям с участием слова <span class="example">absolutely</span> или <span class="example">definitely</span>, за которым следует один из <span class="example">adore</span>, <span class="example">love</span>, <span class="example">like</span> или <span class="example">prefer</span>.
(Liberman, в <em>LanguageLog</em>, 2005).</p>
</p>
</td></table>
<p>К сожалению, поисковые системы имеют некоторые существенные недостатки.
Во-первых, допустимый диапазон паттернов поиска строго ограничен.
В отличие от локального корпуса, где вы пишете программы для поиска сколь угодно сложных паттернов, поисковые системы, как правило, позволяют Вам только искать отдельные слова или строки слов, иногда с подстановочными символами.  Во-вторых, поисковые системы дают противоречивые результаты, и могут дать совершенно различные цифры при использовании в разное время или в разных географических регионах.  Когда содержание дублируется на нескольких сайтах, результаты поиска могут быть преувеличены.
И, наконец, разметка в результате, возвращаемом поисковой системой, может непредсказуемо изменяться, нарушая любой метод обнаружения конкретного содержания, основанный на паттерне (проблема, которая облегчается  использованием API поисковой системы).</p>
<div class="note">
<p class="first admonition-title">Замечание</p>
<p class="last"><strong>Your Turn:</strong> 
Поищите в Интернете <tt class="doctest"><span class="pre"><span class="pysrc-string">"the of"</span></span></tt> (в кавычках).  Основываясь на большом количестве результатов, можем мы сделать вывод о том, что <span class="example">"the of"</span> является частым словосочетанием в английском языке?</p>
</div>
</div>
<div class="section" id="processing-rss-feeds">
<h3>Обработка RSS-каналов</h3>
<!-- XX We either need to control the feed more (is this possible?) or -->
<!-- else warn the reader that they will get different results -->
<p>Блогосфера является важным источником текста в формальных и неформальных регистрах.
С помощью библиотеки Python <em>Universal Feed Parser</em> доступной на <tt class="doctest"><span class="pre">https://pypi.python.org/pypi/feedparserj</span></tt> мы можем получить доступ к содержанию любого блога, как показано ниже:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; import feedparser
&gt;&gt;&gt; llog = feedparser.parse("http://languagelog.ldc.upenn.edu/nll/?feed=atom")
&gt;&gt;&gt; llog['feed']['title']
'Language Log'
&gt;&gt;&gt; len(llog.entries)
15
&gt;&gt;&gt; post = llog.entries[2]
&gt;&gt;&gt; post.title
"He's My BF"
&gt;&gt;&gt; content = post.content[0].value
&gt;&gt;&gt; content[:70]
'&lt;p&gt;Today I was chatting with three of our visiting graduate students f'
&gt;&gt;&gt; raw = BeautifulSoup(content).get_text()
&gt;&gt;&gt; word_tokenize(raw)
['Today', 'I', 'was', 'chatting', 'with', 'three', 'of', 'our', 'visiting',
'graduate', 'students', 'from', 'the', 'PRC', '.', 'Thinking', 'that', 'I',
'was', 'being', 'au', 'courant', ',', 'I', 'mentioned', 'the', 'expression',
'DUI4XIANG4', '\u5c0d\u8c61', '("', 'boy', '/', 'girl', 'friend', '"', ...]</pre>
</td>
</tr></table></td></tr>
</table></div>
<!-- >>> word_tokenize(nltk.clean_html(llog.entries[2].content[0].value)) -->
<p>Немного потрудившись, мы можем написать программы для создания небольшого свода блогерских сообщений и использовать это в качестве основы для нашей работы по NLP.</p>
<!-- XXX I&#39;ve played around with feeds myself, and found it kind of
frustrating, in the sense that it&#39;s very hard to know what kind of
data structure you&#39;re getting back, and therefore hard to know what
kind of operations you can perform. This snippet illustrates the
problem rather poignantly. How can the reader get a handle on what
something like this means?
   >>> content = post.content[0].value
NB this also prints out unicode strings, which haven&#39;t been
explained yet. There&#39;s also a "so what" feeling about this - -
there&#39;s a chunk of code, but no discussion about what it amounts to. -->
</div>
<div class="section" id="reading-local-files">
<h3>Чтение локальных файлов</h3>
<!-- Monkey-patching to fake the file/web examples in this section:

>>> from io import StringIO
>>> def fake_open(filename, mode=None):
...     return StringIO('Time flies like an arrow.nFruit flies like a banana.n')
>>> def fake_urlopen(url):
...     return StringIO('<!doctype html public "-//W3C//DTD HTML 4.0 Transitional//EN"&#39;)
>>> open = fake_open
>>> from urllib import request
>>> request.urlopen.read = lambda: fake_urlopen -->
<p>Для того чтобы прочитать локальный файл, мы должны использовать встроенную функцию Python <tt class="doctest"><span class="pre">open()</span></tt>, за которой следует метод <tt class="doctest"><span class="pre">read()</span></tt>.  Предположим, у вас есть файл <tt class="doctest"><span class="pre">document.txt</span></tt>, вы можете загрузить его содержимое вот так:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; f = open('document.txt')
&gt;&gt;&gt; raw = f.read()</pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="note">
<p class="first admonition-title">Замечание</p>
<p class="last"><strong>Ваша очередь:</strong> 
Создайте файл с именем <tt class="doctest"><span class="pre">document.txt</span></tt> с помощью текстового редактора, наберите в нем несколько строк текста и сохраните его как простой текст.
Если вы используете IDLE, выберите команду <em>New Window</em> в меню <em>File</em>, введите нужный текст в это окно, а затем сохраните файл как <tt class="doctest"><span class="pre">document.txt</span></tt> внутри директории, которую IDLE предложит во всплывающем диалоговом окне.
Далее в интерпретаторе Python откройте файл с помощью <tt class="doctest"><span class="pre">n = open( <span class="pysrc-string">'document.txt'</span>)</span></tt>, а затем проверьте его содержимое с помощью <tt class="doctest"><span class="pre"><span class="pysrc-keyword">print</span>(f.read())</span></tt>.</p>
</div>
<p>Что-то, возможно, пошло не так, когда вы пытались сделать это.
Если интерпретатор смог бы найти файл, вы бы увидели ошибку:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; f = open('document.txt')
Traceback (most recent call last):
File "&lt;pyshell#7&gt;", line 1, in -toplevel-
f = open('document.txt')
IOError: [Errno 2] No such file or directory: 'document.txt'</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Чтобы проверить, что файл, который вы пытаетесь открыть, действительно в нужном каталоге, используйте команду IDLE <em>Open</em> в меню <em>Файл</em>; она отобразит список всех файлов в каталоге, где работает IDLE. В качестве альтернативы можно проверить текущую директорию из Python:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; import os
&gt;&gt;&gt; os.listdir('.')</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Другая возможная проблема, которая у вас могла возникнуть при доступе к текстовому файлу, связана с соглашениями о новой строке, которые различны для разных операционных систем.
Встроенная функция <tt class="doctest"><span class="pre">open()</span></tt> имеет второй параметр для управления тем, как открывается файл: <tt class="doctest"><span class="pre">open(<span class="pysrc-string">'Document.txt'</span>, <span class="pysrc-string">'rU'</span>)</span></tt> - <tt class="doctest"><span class="pre"><span class="pysrc-string">'г'</span></span></tt> означает открыть файл для чтения (по умолчанию), а <tt class="doctest"><span class="pre"><span class="pysrc-string">'U'</span></span></tt> означает "Universal", что позволяет нам игнорировать различные условные обозначения, которые были использованы для маркировки новой строки.</p>
<p>Предполагая, что вы можете открыть файл, существует несколько методов для его чтения.
Метод <tt class="doctest"><span class="pre">read()</span></tt> создает строку с содержимым всего файла:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; f.read()
'Time flies like an arrow.\nFruit flies like a banana.\n'</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Напомним, что <tt class="doctest"><span class="pre"><span class="pysrc-string">'\n'</span></span></tt><a name="newlines_index_term"></a> - это символы <span class="termdef">перевода строки</span>; они эквивалентны нажатию <em>Enter</em> на клавиатуре и началу новой строки.</p>
<!-- XXX I think we also mentioned print, for suppressing a newline - -
do they need to know about both of these? -->
<p>Мы также можем прочитать файл по одной строке за один раз, используя <tt class="doctest"><span class="pre"><span class="pysrc-keyword">for</span></span></tt> цикл:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; f = open('document.txt', 'rU')
&gt;&gt;&gt; for line in f:
...     print(line.strip())
Time flies like an arrow.
<span class="pysrc-output">Fruit flies like a banana.</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>При этом мы используем метод <tt class="doctest"><span class="pre">strip()</span></tt>, чтобы удалить символ новой строки в конце строки ввода.</p>
<p>К файлам корпусов NLTK также можно обратиться, используя эти методы.  Мы просто должны использовать <tt class="doctest"><span class="pre">nltk.data.find()</span></tt>, чтобы получить имя файла для любого элемента корпуса.
Тогда мы можем открыть и прочитать его так, как мы только что показали выше:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; path = nltk.data.find('corpora/gutenberg/melville-moby_dick.txt')
&gt;&gt;&gt; raw = open(path, 'rU').read()</pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="extracting-text-from-pdf-msword-and-other-binary-formats">
<h3>Извлечение текста из PDF, MSWord и других двоичных форматов</h3>
<p>ASCII-текст и HTML-текст - это читаемые форматы.  Но текст часто находится в бинарных форматах - как PDF и MSWord - которые могут быть открыты только с помощью специализированного программного обеспечения.  Сторонние библиотеки, такие как <tt class="doctest"><span class="pre">pypdf</span></tt> и <tt class="doctest"><span class="pre">pywin32</span></tt> обеспечивают доступ к этим форматам.  Извлечение текста из документов с несколькими столбцами является чрезвычайно сложным делом.  Для одноразового преобразования нескольких документов проще открыть документ в соответствующем приложении, а затем сохранить его как текст на локальном диске и обращаться к нему, как описано ниже.
Если документ уже в сети, вы можете ввести его URL в поле поиска Google.
Результат поиска часто включает в себя ссылку на HTML версию документа, которую можно сохранить в виде текста.</p>
</div>
<div class="section" id="capturing-user-input">
<h3>Захват пользовательского ввода</h3>
<p>Иногда мы хотим захватить текст, который пользователь вводит, когда он взаимодействует с нашей программой. Для того, чтобы предложить пользователю ввести строку ввода, вызовите в Python функцию <tt class="doctest"><span class="pre">input()</span></tt>.
После сохранения пользовательского ввода в переменную, мы можем работать с ним так же, как мы работали с другими строками.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; s = input("Enter some text: ")
Enter some text: On an exceptionally hot evening early in July
&gt;&gt;&gt; print("You typed", len(word_tokenize(s)), "words.")
You typed 8 words.</pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="the-nlp-pipeline">
<h3>Последовательная схема NLP </h3>
<p><a class="reference internal" href="http://www.nltk.org/book/ch03.html#fig-pipeline1">3.1</a> обобщает то, что мы рассмотрели в этом разделе, в том числе процесс построения словаря, который мы видели в <a class="reference external" href="http://www.nltk.org/book/ch01.html#chap-introduction">1.</a>.  (Один из шагов, нормализация, будет обсуждаться в <a class="reference internal" href="http://www.nltk.org/book/ch03.html#sec-normalizing-text">3.6</a>.)</p>
<span class="target" id="fig-pipeline1"></span><div class="figure" id="fig-pipeline1">
<img alt="../images/pipeline1.png" src="http://www.nltk.org/images/pipeline1.png" style="width:571.5px;height:212.7px">
<p class="caption"><span class="caption-label">Рисунок 3.1:</span> Последовательная схема обработки: мы открываем URL и читаем его HTML содержимое, удаляем разметку и выбираем часть символов; они затем токенизируются и конвертируются в <tt class="doctest"><span class="pre">nltk.Text</span></tt> объект; мы можем также перевести все слова в нижний регистр и извлечь словарь.</p>
</div>
<p>Много чего происходит в этом "трубопроводе".  Понять его правильно поможет четкое представление о типе каждой переменной, которая упоминается.  Мы выясняем тип любого объекта Python <tt class="doctest"><span class="pre">х</span></tt>, используя <tt class="doctest"><span class="pre">type(х)</span></tt>, например, <tt class="doctest"><span class="pre">type(1)</span></tt> - <tt class="doctest"><span class="pre">&lt;int&gt;</span></tt>, так как <tt class="doctest"><span class="pre">1</span></tt> представляет собой целое число.</p>
<p>Когда мы загружаем содержимое URL или файла или когда мы вырезаем HTML - разметку, мы имеем дело со строками, типом данных Python <tt class="doctest"><span class="pre">&lt;str&gt;</span></tt>.
(Мы узнаем больше о строках в <a class="reference internal" href="http://www.nltk.org/book/ch03.html#sec-strings">3.2</a>):</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; raw = open('document.txt').read()
&gt;&gt;&gt; type(raw)
&lt;class 'str'&gt;</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Когда мы токенизируем строку мы получаем список (слов), это тип данных Python <tt class="doctest"><span class="pre">&lt;list&gt;</span></tt>.  В результате нормализации и сортировки списков получаются другие списки:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; tokens = word_tokenize(raw)
&gt;&gt;&gt; type(tokens)
&lt;class 'list'&gt;
&gt;&gt;&gt; words = [w.lower() for w in tokens]
&gt;&gt;&gt; type(words)
&lt;class 'list'&gt;
&gt;&gt;&gt; vocab = sorted(set(words))
&gt;&gt;&gt; type(vocab)
&lt;class 'list'&gt;</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Тип объекта определяет, какие операции можно выполнять над ним.
Так, например, мы можем вызвать функцию append() для списка, но не для строки:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; vocab.append('blog')
&gt;&gt;&gt; raw.append('blog')
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
AttributeError: 'str' object has no attribute 'append'</pre>
</td>
</tr></table></td></tr>
</table></div>
<!-- XXX partial duplication with text on p86 of hardcopy -->
<p>Подобно этому, мы можем конкатенировать строки со строками и списки со списками, но мы не можем конкатенировать строки со списками:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; query = 'Who knows?'
&gt;&gt;&gt; beatles = ['john', 'paul', 'george', 'ringo']
&gt;&gt;&gt; query + beatles
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
TypeError: cannot concatenate 'str' and 'list' objects</pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
</div>
<div class="section" id="strings-text-processing-at-the-lowest-level">
<span id="sec-strings"></span><h2>3.2 Строки: Обработка текста на самом низком уровне</h2>
<p>Пришло время изучить фундаментальный тип данных, которые мы прилежно избегали до сих пор.  В предыдущих главах мы сосредоточились на тексте в виде списка слов.  Мы не слишком пристально вглядывались в слова и как они обрабатываются на языке программирования.  Используя интерфейс NLTK мы могли игнорировать файлы, из которых эти тексты пришли.  Содержание слова, а также файла, представляется языками программирования в виде фундаментального типа данных известного как <a name="string_index_term"></a><span class="termdef">строка</span>.  В этом разделе мы рассмотрим строки в деталях и покажем связь между строками, словами, текстами и файлами.</p>
<div class="section" id="basic-operations-with-strings">
<h3>Основные операции со строками</h3>
<p>Строки задаются с помощью одиночных кавычек <a class="reference internal" href="http://www.nltk.org/book/ch03.html#single-quotes"><span id="ref-single-quotes"><img class="callout" alt="[1]" src="http://www.nltk.org/book/callouts/callout1.gif"></span></a> или двойных кавычек <a class="reference internal" href="http://www.nltk.org/book/ch03.html#double-quotes"><span id="ref-double-quotes"><img class="callout" alt="[2]" src="http://www.nltk.org/book/callouts/callout2.gif"></span></a>, как показано ниже.
Если строка содержит одиночную кавычку (апостроф), мы должны с помощью обратных косых черт выделить эту кавычку <a class="reference internal" href="http://www.nltk.org/book/ch03.html#backslash-escape"><span id="ref-backslash-escape"><img class="callout" alt="[3]" src="http://www.nltk.org/book/callouts/callout3.gif"></span></a>, чтобы Python знал, что имелась в виду буквально кавычка, либо поместить строку в двойные кавычки <a class="reference internal" href="http://www.nltk.org/book/ch03.html#double-quotes"><img class="callout" alt="[2]" src="http://www.nltk.org/book/callouts/callout2.gif"></a>.
В противном случае кавычка внутри строки <a class="reference internal" href="http://www.nltk.org/book/ch03.html#unescaped-quote"><span id="ref-unescaped-quote"><img class="callout" alt="[4]" src="http://www.nltk.org/book/callouts/callout4.gif"></span></a> будет интерпретироваться как закрывающая кавычка и интерпретатор Python сообщит о синтаксической ошибке:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; monty = 'Monty Python' 
&gt;&gt;&gt; monty
'Monty Python'
&gt;&gt;&gt; circus = "Monty Python's Flying Circus" 
&gt;&gt;&gt; circus
"Monty Python's Flying Circus"
&gt;&gt;&gt; circus = 'Monty Python\'s Flying Circus' 
&gt;&gt;&gt; circus
"Monty Python's Flying Circus"
&gt;&gt;&gt; circus = 'Monty Python's Flying Circus' 
  File "&lt;stdin&gt;", line 1
    circus = 'Monty Python's Flying Circus'
                           ^
SyntaxError: invalid syntax</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Иногда текстовые данные занимают несколько строк.  Python предоставляет нам различные способы их ввода.  В следующем примере последовательность из двух строк объединяется в одну строку.
Нам необходимо использовать обратную косую черту <a class="reference internal" href="http://www.nltk.org/book/ch03.html#string-backslash"><span id="ref-string-backslash"><img class="callout" alt="[1]" src="http://www.nltk.org/book/callouts/callout1.gif"></span></a> или круглые скобки <a class="reference internal" href="http://www.nltk.org/book/ch03.html#string-parentheses"><span id="ref-string-parentheses"><img class="callout" alt="[2]" src="http://www.nltk.org/book/callouts/callout2.gif"></span></a>, чтобы интерпретатор знал, что выражение не завершено после первой строки.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; couplet = "Shall I compare thee to a Summer's day?"\
...           "Thou are more lovely and more temperate:" 
&gt;&gt;&gt; print(couplet)
Shall I compare thee to a Summer's day?Thou are more lovely and more temperate:
&gt;&gt;&gt; couplet = ("Rough winds do shake the darling buds of May,"
...           "And Summer's lease hath all too short a date:") 
&gt;&gt;&gt; print(couplet)
Rough winds do shake the darling buds of May,And Summer's lease hath all too short a date:</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>К сожалению, эти методы не дают нам символ новой строки между двумя строками сонета.  Вместо этого мы можем использовать строку, заключенную в тройные кавычки, следующим образом:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; couplet = """Shall I compare thee to a Summer's day?
<span class="pysrc-more">... </span> Thou are more lovely and more temperate:"""
&gt;&gt;&gt; print(couplet)
Shall I compare thee to a Summer's day?
Thou are more lovely and more temperate:
&gt;&gt;&gt; couplet = '''Rough winds do shake the darling buds of May,
... And Summer's lease hath all too short a date:'''
&gt;&gt;&gt; print(couplet)
Rough winds do shake the darling buds of May,
And Summer's lease hath all too short a date:</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Теперь, когда мы можем определять строки, мы можем попробовать некоторые простые операции над ними.
Прежде всего, давайте посмотрим на операцию <tt class="doctest"><span class="pre">+</span></tt> известную как <a name="concatenation_index_term"></a> <span class="termdef">конкатенация</span> <a class="reference internal" href="http://www.nltk.org/book/ch03.html#string-concatenation"><span id="ref-string-concatenation"><img class="callout" alt="[1]" src="http://www.nltk.org/book/callouts/callout1.gif"></span></a>.
Она производит новую строку, которая является копией двух исходных строк, приклеенных одна к другой.  Обратите внимание на то, что конкатенация не делает ничего умного, например, не вставляет пробел между словами.  Мы можем даже умножать строки <a class="reference internal" href="http://www.nltk.org/book/ch03.html#string-multiplication"><span id="ref-string-multiplication"><img class="callout" alt="[2]" src="http://www.nltk.org/book/callouts/callout2.gif"></span></a> :</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; 'very' + 'very' + 'very' 
'veryveryvery'
&gt;&gt;&gt; 'very' * 3 
'veryveryvery'</pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="note">
<p class="first admonition-title">Замечание</p>
<p><strong>Ваша очередь:</strong> 
Попробуйте запустить следующий код, а затем попытайтесь использовать ваше понимание строковых операций <tt class="doctest"><span class="pre">+</span></tt> и <tt class="doctest"><span class="pre">*</span></tt>, чтобы выяснить, как он работает.
Будьте осторожны - различайте строки: <tt class="doctest"><span class="pre"><span class="pysrc-string">' '</span></span></tt>, которая представляет собой один символ пробела, и <tt class="doctest"><span class="pre"><span class="pysrc-string">''</span></span></tt>, которая является пустой строкой.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; a = [1, 2, 3, 4, 5, 6, 7, 6, 5, 4, 3, 2, 1]
&gt;&gt;&gt; b = [' ' * 2 * (7 - i) + 'very' * i for i in a]
&gt;&gt;&gt; for line in b:
...     print(line)</pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<!-- XXX we haven&#39;t drawn an analogy yet. -->
<p>Мы видели, что операции сложения и умножения применяются к строкам, а не только к числам.  Однако обратите внимание, что мы не можем использовать вычитание или деление со строками:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; 'very' - 'y'
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
TypeError: unsupported operand type(s) for -: 'str' and 'str'
&gt;&gt;&gt; 'very' / 2
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
TypeError: unsupported operand type(s) for /: 'str' and 'int'</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Эти сообщения об ошибках являются еще одним примером того, как Python говорит нам, что мы смешали наши типы данных. В первом случае нам говорят, что операция вычитания (т. е., <tt class="doctest"><span class="pre">-</span></tt>) не может применяться к объектам типа <tt class="doctest"><span class="pre">str</span></tt> (строки), а во втором нам говорят, что деление не может принимать <tt class="doctest"><span class="pre">str</span></tt> и <tt class="doctest"><span class="pre">int</span></tt> в качестве своих двух операндов.</p>
</div>
<div class="section" id="printing-strings">
<h3>Печать строк</h3>
<p>До сих пор, когда мы хотели посмотреть на содержимое переменной или увидеть результат расчета, мы просто вводили имя переменной в интерпретатор.  Мы также можем увидеть содержимое переменной с помощью выражения <tt class="doctest"><span class="pre"><span class="pysrc-keyword">print</span></span></tt>:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; print(monty)
Monty Python</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Обратите внимание на то, что на этот раз нет никаких кавычек.  Когда мы исследуем переменную, введя ее имя в интерпретатор, интерпретатор печатает представление Python ее значения.  Так как это строка, то результат в кавычках.  Тем не менее, когда мы говорим интерпретатору <tt class="doctest"><span class="pre"><span class="pysrc-keyword">print</span></span></tt> содержимое переменной, мы не видим символов кавычек, так как их нет внутри строки.</p>
<p>Выражение <tt class="doctest"><span class="pre"><span class="pysrc-keyword">print</span></span></tt> позволяет отображать более одного элемента на строке различными способами, как показано ниже:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; grail = 'Holy Grail'
&gt;&gt;&gt; print(monty + grail)
Monty PythonHoly Grail
&gt;&gt;&gt; print(monty, grail)
Monty Python Holy Grail
&gt;&gt;&gt; print(monty, "and the", grail)
Monty Python and the Holy Grail</pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="accessing-individual-characters">
<h3>Обращение к отдельным символам</h3>
<p>Как мы видели в <a class="reference external" href="http://www.nltk.org/book/ch01.html#sec-a-closer-look-at-python-texts-as-lists-of-words">2</a> для списков, строки тоже индексируются, начиная с нуля.
Когда мы индексируем строку, мы получаем одну из ее символов (или букв).  Один символ не является чем-то особенным - это просто строка длинной <tt class="doctest"><span class="pre">1</span></tt>.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; monty[0]
'M'
&gt;&gt;&gt; monty[3]
't'
&gt;&gt;&gt; monty[5]
' '</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Как и со списками, если мы попытаемся получить доступ к индексу, который находится за пределами строки, мы получим ошибку:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; monty[20]
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in ?
<span class="pysrc-except">IndexError: string index out of range</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<!-- XXX I don&#39;t think it works very well here to have these two observations
followed by two code examples - - it&#39;s hard to see what the point of
the ``5 = len(monty) - 7`` remark is in this context. Since you
probably don&#39;t want to split up the two examples, callouts might
ameliorate it. -->
<p>Снова, как и со списками, мы можем использовать отрицательные индексы для строк, где <tt class="doctest"><span class="pre">-1</span></tt> является индексом последнего символа <a class="reference internal" href="http://www.nltk.org/book/ch03.html#last-character"><span id="ref-last-character"><img class="callout" alt="[1]" src="http://www.nltk.org/book/callouts/callout1.gif"></span></a>.
Положительные и отрицательные индексы дают нам два способа сослаться на любую позицию в строке.  В этом случае, когда строка имела длину 12, оба индекса <tt class="doctest"><span class="pre">5</span></tt> и <tt class="doctest"><span class="pre">-7</span></tt> относятся к тому же символ (пробел).
(Обратите внимание на то, что <tt class="doctest"><span class="pre">5 = len(monty) - 7</span></tt>.)</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; monty[-1] 
'n'
&gt;&gt;&gt; monty[5]
' '
&gt;&gt;&gt; monty[-7]
' '</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Мы можем написать <tt class="doctest"><span class="pre"><span class="pysrc-keyword">for</span></span></tt> цикл для перебора символов в строках.  Эта функция <tt class="doctest"><span class="pre"><span class="pysrc-keyword">print</span></span></tt> включает в себя дополнительный параметр <tt class="doctest"><span class="pre">end = <span class="pysrc-string">' '</span></span></tt>, который представляет собой то, как мы говорим Python печатать в конце пробел вместо новой строки.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; sent = 'colorless green ideas sleep furiously'
&gt;&gt;&gt; for char in sent:
...     print(char, end=' ')
...
<span class="pysrc-output">c o l o r l e s s   g r e e n   i d e a s   s l e e p   f u r i o u s l y</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Мы можем также считать отдельные символы.  Мы должны игнорировать различие регистра, приводя все к нижнему регистру и отфильтровывая небуквенные символы:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; from nltk.corpus import gutenberg
&gt;&gt;&gt; raw = gutenberg.raw('melville-moby_dick.txt')
&gt;&gt;&gt; fdist = nltk.FreqDist(ch.lower() for ch in raw if ch.isalpha())
&gt;&gt;&gt; fdist.most_common(5)
[('e', 117092), ('t', 87996), ('a', 77916), ('o', 69326), ('n', 65617)]
&gt;&gt;&gt; [char for (char, count) in fdist.most_common()]
['e', 't', 'a', 'o', 'n', 'i', 's', 'h', 'r', 'l', 'd', 'u', 'm', 'c', 'w',
'f', 'g', 'p', 'b', 'y', 'v', 'k', 'q', 'j', 'x', 'z']</pre>
</td>
</tr></table></td></tr>
</table></div>
<table class="docutils citation" id="sb" frame="void" rules="none">
<colgroup><col class="label"><col></colgroup>
<tbody valign="top">
<tr><td class="label">[sb]</td><td>объяснить этот кортеж распаковкой где-нибудь?</td></tr>
</tbody>
</table>
<p>Это дает нам буквы алфавита, с наиболее часто встречающимися буквами, перечисленными в первую очередь (это довольно сложно и мы объясним это более тщательно ниже).
Вы могли бы захотеть визуализировать распределение с использованием <tt class="doctest"><span class="pre">fdist.plot()</span></tt>.
Относительные частоты символом текста могут быть использованы в автоматической идентификации языка текста.</p>
</div>
<div class="section" id="accessing-substrings">
<h3>Обращение к частям строк</h3>
<span class="target" id="fig-string-slicing"></span><div class="figure" id="fig-string-slicing">
<img alt="../images/string-slicing.png" src="http://www.nltk.org/images/string-slicing.png" style="width:388.75px;height:129.25px">
<p class="caption"><span class="caption-label">Рисунок 3.2:</span> Срез строки: Строка "Monty Python" отображается вместе со своими положительными и отрицательными индексами; две подстроки выбираются с помощью обозначения среза.
Срез <tt class="doctest"><span class="pre">[m, n]</span></tt> содержит символы с позиции <tt class="doctest"><span class="pre">m</span></tt> по <tt class="doctest"><span class="pre">n-1</span></tt>.</p>
</div>
<p>Подстрока - это любая непрерывная часть строки, которую мы хотим вытащить для дальнейшей обработки.  Мы можем легко получить доступ к подстроке, используя то же обозначение среза, которое мы использовали для списков (см. <a class="reference internal" href="http://www.nltk.org/book/ch03.html#fig-string-slicing">3.2</a>).
Например, следующий код обращается к подстроке с позиции <tt class="doctest"><span class="pre">6</span></tt> до (не включая) позиции <tt class="doctest"><span class="pre">10</span></tt>:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; monty[6:10]
'Pyth'</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Здесь мы видим, символы <tt class="doctest"><span class="pre"><span class="pysrc-string">'P'</span></span></tt>, <tt class="doctest"><span class="pre"><span class="pysrc-string">'y'</span></span></tt>, <tt class="doctest"><span class="pre"><span class="pysrc-string">'t'</span></span></tt> и <tt class="doctest"><span class="pre"><span class="pysrc-string">'h'</span></span></tt>, которые соответствуют <tt class="doctest"><span class="pre">monty[6]</span></tt> ... <tt class="doctest"><span class="pre">monty[9]</span></tt>, но не <tt class="doctest"><span class="pre">monty [10]</span></tt>. Это происходит потому, что срез <span class="emphasis">начинается</span> с первого индекса, но завершается за <span class="emphasis">один до</span> конечного индекса.</p>
<p>Мы также можем сделать срез с отрицательными индексами - то же базовое правило - начало с первого индекса и конец за один до последнего - применимо; здесь мы останавливаемся перед символом пробела.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; monty[-12:-7]
'Monty'</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Как и со срезами списков, если опустить первое значение, то подстрока начинается с начала строки.  Если мы опустим второе значение, то подстрока продолжается до конца строки:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; monty[:5]
'Monty'
&gt;&gt;&gt; monty[6:]
'Python'</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Мы проверяем, содержит ли строка определенную подстроку, используя оператор <tt class="doctest"><span class="pre"><span class="pysrc-keyword">in</span></span></tt>, следующим образом:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; phrase = 'And now for something completely different'
&gt;&gt;&gt; if 'thing' in phrase:
...     print('found "thing"')
found "thing"</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Мы можем также найти положение подстроки в строке с помощью функции <tt class="doctest"><span class="pre">find()</span></tt>:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; monty.find('Python')
6</pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="note">
<p class="first admonition-title">Замечание</p>
<p class="last"><strong>Ваша очередь:</strong> 
Придумайте предложение и присвойте его переменной, например <tt class="doctest"><span class="pre">sent = <span class="pysrc-string">'my sentence...'</span></span></tt>.
Теперь запишите выражение среза, чтобы достать из него отдельные слова.  (Это, очевидно, неудобный способ обработки слов текста!)</p>
</div>
</div>
<div class="section" id="more-operations-on-strings">
<h3>Другие операции со строками</h3>
<p>Python имеет всестороннюю поддержку обработки строк.  Свод, включающий некоторые операции, которые мы еще не видели, показан в <a class="reference internal" href="http://www.nltk.org/book/ch03.html#tab-string-methods">3.2</a> .  Для получения дополнительной информации о строках, наберите <tt class="doctest"><span class="pre">help(str)</span></tt> в командной строке Python.</p>
<span class="target" id="tab-string-methods"></span><table border="1" class="docutils" id="tab-string-methods">
<colgroup>
<col width="21%">
<col width="79%">
</colgroup>
<thead valign="bottom">
<tr><th class="head">Метод</th>
<th class="head">Функциональные возможности</th>
</tr>
</thead>
<tbody valign="top">
<tr><td><tt class="doctest"><span class="pre">s.find(t)</span></tt></td>
<td>индекс первого экземпляра строки <tt class="doctest"><span class="pre">t</span></tt> внутри <tt class="doctest"><span class="pre">s</span></tt> (<tt class="doctest"><span class="pre">-1</span></tt>, если строка t не найдена)</td>
</tr>
<tr><td><tt class="doctest"><span class="pre">s.rfind(t)</span></tt></td>
<td>Индекс последнего экземпляра строки <tt class="doctest"><span class="pre">t</span></tt> внутри <tt class="doctest"><span class="pre">s</span></tt> (<tt class="doctest"><span class="pre">-1</span></tt>, если строка t не найдена)</td>
</tr>
<tr><td><tt class="doctest"><span class="pre">s.index(t)</span></tt></td>
<td>как <tt class="doctest"><span class="pre">s.find(t)</span></tt> за исключением того, что вызывает <tt class="doctest"><span class="pre">ValueError</span></tt> если строка t не найдена</td>
</tr>
<tr><td><tt class="doctest"><span class="pre">s.rindex(t)</span></tt></td>
<td>как <tt class="doctest"><span class="pre">s.rfind(t)</span></tt> за исключением того, что вызывает <tt class="doctest"><span class="pre">ValueError</span></tt> если строка t не найдена</td>
</tr>
<tr><td><tt class="doctest"><span class="pre">s.join(text)</span></tt></td>
<td>объединить элементы списка text в строку, используя <tt class="doctest"><span class="pre">s</span></tt> в качестве связующего звена</td>
</tr>
<tr><td><tt class="doctest"><span class="pre">s.split(t)</span></tt></td>
<td>разделить <tt class="doctest"><span class="pre">s</span></tt> на элементы, используя в качестве разделителя между элементами <tt class="doctest"><span class="pre">t</span></tt> (пробел по умолчанию)</td>
</tr>
<tr><td><tt class="doctest"><span class="pre">s.splitlines()</span></tt></td>
<td>разделить <tt class="doctest"><span class="pre">s</span></tt> на строки</td>
</tr>
<tr><td><tt class="doctest"><span class="pre">s.lower()</span></tt></td>
<td>версия строки <tt class="doctest"><span class="pre">s</span></tt> в нижнем регистре</td>
</tr>
<tr><td><tt class="doctest"><span class="pre">s.upper()</span></tt></td>
<td>версия строки <tt class="doctest"><span class="pre">s</span></tt> в верхнем регистре</td>
</tr>
<tr><td><tt class="doctest"><span class="pre">s.title()</span></tt></td>
<td>версия строки <tt class="doctest"><span class="pre">s</span></tt> в титульном регистре</td>
</tr>
<tr><td><tt class="doctest"><span class="pre">s.strip()</span></tt></td>
<td>копия <tt class="doctest"><span class="pre">s</span></tt> без начальных или конечных пробелов</td>
</tr>
<tr><td><tt class="doctest"><span class="pre">s.replace(t, u)</span></tt></td>
<td>заменить экземпляры <tt class="doctest"><span class="pre">t</span></tt> на <tt class="doctest"><span class="pre">u</span></tt> внутри <tt class="doctest"><span class="pre">s</span></tt></td>
</tr>
</tbody>
<td><p class="caption"><span class="caption-label">Таблица 3.2:</span> <p>Полезные методы строк: операции со строками в дополнение к тестам строк, показанным на <a class="reference external" href="http://www.nltk.org/book/ch01.html#tab-word-tests">4.2</a>; все методы дают новую строку или список</p>
</p>
</td></table>
</div>
<div class="section" id="the-difference-between-lists-and-strings">
<h3>Различие между списками и строками</h3>
<p>И строки и списки - это виды <a name="sequence_index_term"></a><span class="termdef">последовательности</span>.  Из строки и из списка мы можем выделить части путем индексирования и срезов, и можем соединять строки и списки воедино путем конкатенации.  Тем не менее, мы не можем соединять строки и списки:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; query = 'Who knows?'
&gt;&gt;&gt; beatles = ['John', 'Paul', 'George', 'Ringo']
&gt;&gt;&gt; query[2]
'o'
&gt;&gt;&gt; beatles[2]
'George'
&gt;&gt;&gt; query[:2]
'Wh'
&gt;&gt;&gt; beatles[:2]
['John', 'Paul']
&gt;&gt;&gt; query + " I don't"
"Who knows? I don't"
&gt;&gt;&gt; beatles + 'Brian'
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
TypeError: can only concatenate list (not "str") to list
&gt;&gt;&gt; beatles + ['Brian']
['John', 'Paul', 'George', 'Ringo', 'Brian']</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Когда мы открываем файл для чтения в программе на Python, мы получаем строку, соответствующую содержанию всего файла. Если мы используем цикл <tt class="doctest"><span class="pre"><span class="pysrc-keyword">for</span></span></tt> для обработки элементов этой строки, все, что мы можем выбрать, - это отдельные символы, - мы не получаем возможности выбрать уровень детализации. В отличие от элементов строки, элементы списка могут быть сколь угодно большими или маленькими: например, элементами могут быть параграфы, предложения, фразы, слова, символы. Таким образом, списки имеют то преимущество, что мы можем быть гибкими в отношении элементов, которые они содержат, и соответственно можем быть гибкими в отношении обработки элементов списка.
Следовательно, одна из первых вещей, которую мы, вероятно, сделаем в части NLP кода, - это токенизация строки в список строк (<a class="reference internal" href="http://www.nltk.org/book/ch03.html#sec-tokenization">3.7</a>).
И наоборот, когда мы хотим записать наши результаты в файл или вывести на терминал, мы обычно форматируем их в виде строки (<a class="reference internal" href="http://www.nltk.org/book/ch03.html#sec-formatting">3.9</a>).</p>
<p>Списки и строки имеют различную функциональность.
Списки имеют дополнительное преимущество, которое заключается в том, что вы можете изменять их элементы:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; beatles[0] = "John Lennon"
&gt;&gt;&gt; del beatles[-1]
&gt;&gt;&gt; beatles</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>С другой стороны, если мы попытаемся сделать это со <em>строкой</em> - изменить 0-ой символ в <tt class="doctest"><span class="pre">query</span></tt> на <tt class="doctest"><span class="pre"><span class="pysrc-string">'F'</span></span></tt> - мы получим:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; query[0] = 'F'
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in ?
<span class="pysrc-except">TypeError: object does not support item assignment</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p> Это происходит потому, что строки <a name="immutable_index_term"></a><span class="termdef">неизменны</span> - вы не можете изменить строку после того, как вы ее создали.  Однако списки <a name="mutable_index_term"></a><span class="termdef">изменяемы,</span> и их содержание может быть изменено в любое время.  В результате списки поддерживают операции, которые изменяют первоначальное значение, а не производят новое значение.</p>
<div class="note">
<p class="first admonition-title">Замечание</p>
<p class="last"><strong>Ваша очередь:</strong> 
Консолидируйте свои знания строк, попробовав выполнить некоторые из упражнений на строки в конце этой главы.</p>
</div>
</div>
</div>
<div class="section" id="text-processing-with-unicode">
<span id="sec-unicode"></span><h2>3.3 Обработка текста с Unicode</h2>
<p>Нашим программам часто придется иметь дело с различными языками и различными наборами символов.  Понятие "обычный текст" является фикцией.
Если вы живете в англо-говорящем мире, вы, вероятно, используете ASCII, возможно, не осознавая этого.  Если вы живете в Европе, вы можете использовать один из расширенных латинских наборов символов, содержащих такие символы, как "ø" для датского и норвежского, "õ" для венгерского, "ñ" для испанского и бретонского, и "n" с перевернутой крышечкой для чешского и словацкого. В этом разделе мы дадим краткий обзор того, как использовать Unicode для обработки текстов, которые используют не-ASCII наборы символов.</p>
<div class="section" id="what-is-unicode">
<h3>Что такое Unicode?</h3>
<p>Unicode поддерживает более миллиона символов.  Каждому символу присваивается номер, который называется <a name="code_point_index_term"></a><span class="termdef">кодовый пункт</span>.  В Python кодовые пункты записываются в виде <tt class="doctest"><span class="pre">\u</span></tt><em>XXXX</em>, где <em>XXXX</em> - 4-х значное шестнадцатеричное число.</p>
<p>В рамках программы мы можем манипулировать строками Unicode, как нормальными строками.
Тем не менее, когда символы Unicode сохраняются в файлы или отображаются на экране терминала, они должны быть закодированы как поток байтов.  Некоторые кодировки (например, ASCII и Latin-2) используют один байт на одну кодовую точку, так что они могут поддерживать только небольшое подмножество Юникод символов достаточное для одного языка.  Другие кодировки (такие как UTF-8) используют несколько байтов и могут представлять полный набор символов Unicode.</p>
<p>Текст в файлах будет в определенной кодировке, поэтому нам нужен некоторый механизм для перевода его в Юникод - перевод в Юникод называется <a name="decoding_index_term"></a><span class="termdef">декодированием</span>. И наоборот, чтобы записать Юникод в файл или на терминал, нам сначала нужно перевести его в подходящую кодировку - этот перевод из Юникод называется <a name="encoding_index_term"></a> <span class="termdef">кодированием</span>, он показан на <a class="reference internal" href="http://www.nltk.org/book/ch03.html#fig-unicode">3.3</a>.</p>
<span class="target" id="fig-unicode"></span><div class="figure" id="fig-unicode">
<img alt="../images/unicode.png" src="http://www.nltk.org/images/unicode.png" style="width:466.70000000000005px;height:234.20000000000002px">
<p class="caption"><span class="caption-label">Рисунок 3.3:</span> Unicode декодирование и кодирование</p>
</div>
<p>С точки зрения Unicode, символы - это абстрактные сущности, которые могут быть реализованы в виде одного или более <a name="glyphs_index_term"></a><span class="termdef">глифов</span>. Только глифы могут появляться на экране или печататься на бумаге. Шрифт является отображением символов в глифах.</p>
</div>
<div class="section" id="extracting-encoded-text-from-files">
<h3>Извлечение закодированного текста из файлов</h3>
<p>Давайте предположим, что у нас есть небольшой текстовый файл и что мы знаем, как он закодирован. Например, <tt class="doctest"><span class="pre">polish-lat2.txt</span></tt>, как следует из названия, представляет собой фрагмент польского текста (из польской Википедии, см <tt class="doctest"><span class="pre">http://pl.wikipedia.org/wiki/Biblioteka_Pruska)</span></tt>.  Этот файл закодирован как Latin-2, также известный как ISO-8859-2. Функция <tt class="doctest"><span class="pre">nltk.data.find()</span></tt> находит файл для нас.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; path = nltk.data.find('corpora/unicode_samples/polish-lat2.txt')</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Функция Python <tt class="doctest"><span class="pre">open()</span></tt> может считывать закодированные данные в строки Юникод и записывать строки Юникод в закодированной форме.  Она принимает параметр, указывающий кодировку файла чтения или записи. Итак давайте откроем наш польский файл с кодировкой <tt class="doctest"><span class="pre"><span class="pysrc-string">'latin2'</span></span></tt> и проверим содержимое файла:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; f = open(path, encoding='latin2')
&gt;&gt;&gt; for line in f:
...    line = line.strip()
...    print(line)
Pruska Biblioteka Państwowa.Jej dawne zbiory znane pod nazwą
"Berlinka" to skarb kultury i sztuki niemieckiej. Przewiezione przez
Niemców pod koniec II wojny światowej na Dolny Śląsk, zostały
odnalezione po 1945 r. na terytorium Polski.Trafiły do Biblioteki
Jagiellońskiej w Krakowie, obejmują ponad 500 tys. zabytkowych
archiwaliów, m.in. manuskrypty Goethego, Mozarta, Beethovena, Bacha.</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Если этот текст отображается на вашем терминале некорректно или если мы хотим увидеть лежащие в основе символов числовые значения (или «кодовые пункты»), то мы можем преобразовать все символы не-ASCII в их двузначные <tt class="doctest"><span class="pre">\х</span></tt><em>XX</em> и четырехзначные <tt class="doctest"><span class="pre">\u</span></tt><em>XXXX</em> представления:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; f = open(path, encoding='latin2')
&gt;&gt;&gt; for line in f:
...     line = line.strip()
...     print(line.encode('unicode_escape'))
b'Pruska Biblioteka Pa\\u0144stwowa.Jej dawne zbiory znane pod nazw\\u0105'
b'"Berlinka" to skarb kultury i sztuki niemieckiej.Przewiezione przez'
b'Niemc\\xf3w pod koniec II wojny \\u015bwiatowej na Dolny \\u015al\\u0105sk, zosta\\u0142y'
b'odnalezione po 1945 r. na terytorium Polski. Trafi\\u0142y do Biblioteki'
b'Jagiello\\u0144skiej w Krakowie, obejmuj\\u0105 ponad 500 tys. zabytkowych'
b'archiwali\\xf3w, m.in. manuskrypty Goethego, Mozarta, Beethovena, Bacha.'</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Первая строка выше иллюстрирует управляющую строку Юникод, которой предшествует в управляющая строка <tt class="doctest"><span class="pre">\u</span></tt>, а именно <tt class="doctest"><span class="pre">\u0144</span></tt>. Соответствующий Юникод символ будет изображен на экране как глиф ń.  В третьей строке предыдущего примера мы видим <tt class="doctest"><span class="pre">\xf3</span></tt>, что соответствует глифу ó и находится в пределах диапазона 128-255.</p>
<p>В Python 3 исходный код кодируется с использованием UTF-8 по умолчанию и вы можете включать символы Юникод в строки, если вы используете IDLE или другой редактор программ, который поддерживает Юникод.
Любые Юникод символы могут быть включены с помощью <tt class="doctest"><span class="pre">\u</span></tt><em>XXXX</em> управляющей последовательности.
Мы находим целочисленный порядковый номер символа с помощью функции <tt class="doctest"><span class="pre">ord()</span></tt>. Например:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; ord('ń')
324</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Шестнадцатеричным четырехзначным обозначением для 324 будет 0144 (наберите <tt class="doctest"><span class="pre">hex(324)</span></tt>, чтобы увидеть это), и мы можем определить строку с соответствующей управляющей последовательностью.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; nacute = '\u0144'
&gt;&gt;&gt; nacute
'ń'</pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="note">
<p class="first admonition-title">Замечание</p>
<p class="last">Есть много факторов, определяющих, какие символы отображаются на экране. Если вы уверены, что у вас правильная кодировка, но ваш Python код по-прежнему не в состоянии воспроизвести глифы, которые вы ожидаете увидеть, вам следует также проверить, что в вашей системе установлены необходимые шрифты. Возможно, необходимо настроить региональные настройки для визуализации UTF-8 закодированных символов, а затем использовать <tt class="doctest"><span class="pre"><span class="pysrc-keyword">print</span>(nacute.encode(<span class="pysrc-string">'utf8'</span>))</span></tt>, чтобы увидеть ń в вашем терминале.</p>
</div>
<p>Мы также можем увидеть, как этот символ представляется в виде последовательности байтов внутри текстового файла:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; nacute.encode('utf8')
b'\xc5\x84'</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Модуль <tt class="doctest"><span class="pre">unicodedata</span></tt> позволяет нам проверить свойства символов Юникод. В следующем примере мы выбираем все символы в третьей строке нашего польского текста вне диапазона ASCII и печатаем их UTF-8 последовательности байтов, за которыми следуют их целочисленные кодовые точки, используя стандартное соглашение в Юникод (т.е. предваряя шестнадцатиричные числа <tt class="doctest"><span class="pre">U+</span></tt>), за которыми следуют их названия в Юникод.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; import unicodedata
&gt;&gt;&gt; lines = open(path, encoding='latin2').readlines()
&gt;&gt;&gt; line = lines[2]
&gt;&gt;&gt; print(line.encode('unicode_escape'))
b'Niemc\\xf3w pod koniec II wojny \\u015bwiatowej na Dolny \\u015al\\u0105sk, zosta\\u0142y\\n'
&gt;&gt;&gt; for c in line: 
...     if ord(c) &gt; 127:
...         print('{} U+{:04x} {}'.format(c.encode('utf8'), ord(c), unicodedata.name(c)))
b'\xc3\xb3' U+00f3 LATIN SMALL LETTER O WITH ACUTE
b'\xc5\x9b' U+015b LATIN SMALL LETTER S WITH ACUTE
b'\xc5\x9a' U+015a LATIN CAPITAL LETTER S WITH ACUTE
b'\xc4\x85' U+0105 LATIN SMALL LETTER A WITH OGONEK
b'\xc5\x82' U+0142 LATIN SMALL LETTER L WITH STROKE</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Если заменить <tt class="doctest"><span class="pre">c.encode(<span class="pysrc-string">'utf8'</span>)</span></tt> в <a class="reference internal" href="http://www.nltk.org/book/ch03.html#unicode-info"><span id="ref-unicode-info"><img class="callout" alt="[1]" src="http://www.nltk.org/book/callouts/callout1.gif"></span></a> на <tt class="doctest"><span class="pre">c</span></tt> и ваша система поддерживает UTF-8, вы должны увидеть результат наподобие следующего:</p>
<div class="line-block">
<div class="line">ó U+00f3 LATIN SMALL LETTER O WITH ACUTE</div>
<div class="line">ś U+015b LATIN SMALL LETTER S WITH ACUTE</div>
<div class="line">Ś U+015a LATIN CAPITAL LETTER S WITH ACUTE</div>
<div class="line">ą U+0105 LATIN SMALL LETTER A WITH OGONEK</div>
<div class="line">ł U+0142 LATIN SMALL LETTER L WITH STROKE</div>
</div>
<p>Или, возможно, вам потребуется заменить кодировку <tt class="doctest"><span class="pre"><span class="pysrc-string">'utf8'</span></span></tt> в примере на <tt class="doctest"><span class="pre"><span class="pysrc-string">'latin2'</span></span></tt>, опять же в зависимости от конфигурации вашей системы.</p>
<p>Следующие примеры иллюстрируют, как методы работы со строками Python и модуль <tt class="doctest"><span class="pre">re</span></tt> может работать с символами Юникод. (Мы подробно остановимся на модуле <tt class="doctest"><span class="pre">re</span></tt> в следующем разделе. <tt class="doctest"><span class="pre">\w</span></tt> соответствует "word character" (словарный символ), cf <a class="reference internal" href="http://www.nltk.org/book/ch03.html#tab-re-symbols">3.4</a>).</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; line.find('zosta\u0142y')
54
&gt;&gt;&gt; line = line.lower()
&gt;&gt;&gt; line
'niemców pod koniec ii wojny światowej na dolny śląsk, zostały\n'
&gt;&gt;&gt; line.encode('unicode_escape')
b'niemc\\xf3w pod koniec ii wojny \\u015bwiatowej na dolny \\u015bl\\u0105sk, zosta\\u0142y\\n'
&gt;&gt;&gt; import re
&gt;&gt;&gt; m = re.search('\u015b\w*', line)
&gt;&gt;&gt; m.group()
'\u015bwiatowej'</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>NLTK токенизаторы допускают Юникод строки в качестве входных данных и, соответственно, возвращают Юникод строки в качестве результата.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; word_tokenize(line)
['niemców', 'pod', 'koniec', 'ii', 'wojny', 'światowej', 'na', 'dolny', 'śląsk', ',', 'zostały']</pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="using-your-local-encoding-in-python">
<h3>Использование вашей локальной кодировки в Python</h3>
<p>Если вы привыкли работать с символами в той или иной локальной кодировке, вы, вероятно, хотите иметь возможность использовать свои стандартные методы для ввода и редактирования строк в файле Python. Чтобы сделать это, вам необходимо включить строку <tt class="doctest"><span class="pre"><span class="pysrc-string">'# -*- coding: &lt;coding&gt; -*-'</span></span></tt> в качестве первой или второй строки вашего файла. Обратите внимание, что <em>&lt;coding&gt;</em> необходимо заменить на название кодировки, например <tt class="doctest"><span class="pre"><span class="pysrc-string">'latin-1'</span></span></tt>, <tt class="doctest"><span class="pre"><span class="pysrc-string">'big5'</span></span></tt> или <tt class="doctest"><span class="pre"><span class="pysrc-string">'utf-8'</span></span></tt> (см. <a class="reference internal" href="http://www.nltk.org/book/ch03.html#fig-polish-utf8">3.4</a>).</p>
<span class="target" id="fig-polish-utf8"></span><div class="figure" id="fig-polish-utf8">
<img alt="../images/polish-utf8.png" src="http://www.nltk.org/images/polish-utf8.png" style="width:605.0px;height:326.0px">
<p class="caption"><span class="caption-label">Рисунок 3.4:</span> Юникод и IDLE: закодированные в UTF-8 строковые литералы в редакторе IDLE; для этого необходимо установить соответствующий шрифт в настройках IDLE; здесь мы выбрали Courier CE.</p>
</div>
<!-- cf http://mail.python.org/pipermail/python-list/2004-February/247783.html

It is also possible to enter non-ASCII characters in interactive
mode. IDLE will convert them to the locale&#39;s encoding before
evaluating the source code; if that fails, you get the message you
see. So where you trying to enter hangul characters in interactive
mode in a locale that does not support hangul, or are you lacking
a codec for your locale?

In interactive mode, UTF-8 is never used (unless you have an
UTF-8 locale). -->
<p>Приведенный выше пример также иллюстрирует, как регулярные выражения могут использовать закодированные строки.</p>
<!-- If you are using Emacs as your editor, the coding specification
will also be interpreted as a specification of the editor&#39;s coding
for the file. Not all of the valid Python names for codings are
accepted by Emacs. -->
</div>
</div>
<div class="section" id="regular-expressions-for-detecting-word-patterns">
<span id="sec-regular-expressions-word-patterns"></span><h2>3.4 Регулярные выражения для обнаружения словарных паттернов</h2>
<p>Многие задачи лингвистической обработки включают установление соответствия образцу.
Например, мы можем найти слова, заканчивающиеся на <span class="example">ed</span> с помощью <tt class="doctest"><span class="pre">endswith(<span class="pysrc-string">'ed'</span>)</span></tt>.  Мы видели множество таких "словарных тестов" в <a class="reference external" href="http://www.nltk.org/book/ch01.html#tab-word-tests">4.2</a>.
Регулярные выражения дают нам более мощный и гибкий способ описания символьных шаблонов.</p>
<div class="note">
<p class="first admonition-title">Замечание</p>
<p class="last">Существует множество опубликованных введений в тему регулярных выражений, организованных вокруг синтаксиса регулярных выражений и примененных для поиска по текстовым файлам.  Вместо того, чтобы делать это снова, мы сконцентрируемся на использовании регулярных выражений на разных этапах лингвистической обработки.  Как обычно, мы будем применять проблемно-ориентированный подход и будем представлять новые возможности, только когда они необходимы для решения практических задач.  В нашем обсуждении мы будем отмечать регулярные выражения, используя двойные угловые кавычки (шевроны) следующим образом: <tt class="doctest"><span class="pre">«patt»</span></tt>.</p>
</div>
<p>Чтобы использовать регулярные выражения в Python мы должны импортировать библиотеку <tt class="doctest"><span class="pre">re</span></tt> с помощью: <tt class="doctest"><span class="pre"><span class="pysrc-keyword">import</span> re</span></tt>.  Нам также нужен список слов для поиска; мы снова будем использовать Words Corpus(<a class="reference external" href="http://www.nltk.org/book/ch02.html#sec-lexical-resources">4</a>).  Мы предварительно обработаем его, убрав из него все собственные имена.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; import re
&gt;&gt;&gt; wordlist = [w for w in nltk.corpus.words.words('en') if w.islower()]</pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="section" id="using-basic-meta-characters">
<h3>Использование основных метасимволов</h3>
<p>Давайте найдем слова, оканчивающиеся на <span class="example">ed</span> используя регулярное выражение <tt class="doctest"><span class="pre">«ed$»</span></tt>.
Мы будем использовать функцию <tt class="doctest"><span class="pre">re.search(р, s)</span></tt>, чтобы проверить, можно ли шаблон <tt class="doctest"><span class="pre">р</span></tt> найти где-нибудь внутри строки <tt class="doctest"><span class="pre">s</span></tt>.
Нам нужно указать интересующие нас символы и использовать знак доллара, который имеет особое поведение в контексте регулярных выражений, которое заключается в том, что оно заменяет конец слова:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; [w for w in wordlist if re.search('ed$', w)]
['abaissed', 'abandoned', 'abased', 'abashed', 'abatised', 'abed', 'aborted', ...]</pre>
</td>
</tr></table></td></tr>
</table></div>
<p><a name="wildcard_index_term"></a>Символ <span class="termdef">подстановки</span> <tt class="doctest"><span class="pre">.</span></tt> соответствует любому одиночному символу.
Предположим, что у нас есть место в кроссворде для слова из 8 букв с <span class="example">j</span> в качестве третьей буквы и <span class="example">t</span> в качестве шестой буквы.
На месте каждой пустой ячейки мы используем точку:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; [w for w in wordlist if re.search('^..j..t..$', w)]
['abjectly', 'adjuster', 'dejected', 'dejectly', 'injector', 'majestic', ...]</pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="note">
<p class="first admonition-title">Замечание</p>
<p class="last"><strong>Ваша очередь:</strong> 
Символ каретки <tt class="doctest"><span class="pre">^</span></tt> соответствует началу строки, так же, как <tt class="doctest"><span class="pre">$</span></tt> соответствует концу.  Какие результаты мы получим из приведенного выше примера, если мы опустим оба из них, и будем искать <tt class="doctest"><span class="pre">«..j..t ..»</span></tt>?</p>
</div>
<p>И, наконец, знак <tt class="doctest"><span class="pre">?</span></tt> указывает, что предыдущий символ не является обязательным.
Таким образом, <tt class="doctest"><span class="pre">«^е-?mail$»</span></tt> будет соответствовать как <span class="example">emali</span>, так и <span class="example">e-mail</span>.
Мы могли бы подсчитать общее число вхождений этого слова (в любом написании) в тексте, используя <tt class="doctest"><span class="pre">sum(1 <span class="pysrc-keyword">for</span> w <span class="pysrc-keyword">in</span> text <span class="pysrc-keyword">if</span> re.search(<span class="pysrc-string">'^ e-?mail$'</span>, w))</span></tt>.</p>
</div>
<div class="section" id="ranges-and-closures">
<h3>Диапазоны и замыкания</h3>
<span class="target" id="fig-t9"></span><div class="figure" id="fig-t9">
<img alt="../images/T9.png" src="http://www.nltk.org/images/T9.png" style="width:297.6px;height:131.0px">
<p class="caption"><span class="caption-label">Рисунок 3.5</span>: T9: Текст на 9 ключах</p>
</div>
<p><a name="t9_index_term"></a>Система <span class="termdef">T9</span> используется для ввода текста на мобильных телефонах (см. <a class="reference internal" href="http://www.nltk.org/book/ch03.html#fig-t9">3.5</a>).  Два или более слов, которые вводятся той же последовательностью нажатий клавиш, известны как <a name="textonyms_index_term"></a><span class="termdef">текстонимы</span>.
Например, <span class="example">hole</span> и <span class="example">golf</span> вводятся нажатием последовательности 4653.  Какие другие слова могли быть введены с помощью той же последовательности?  Здесь мы используем регулярное выражение <tt class="doctest"><span class="pre">«^[ghi][mno][jlk][def]$»</span></tt>:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; [w for w in wordlist if re.search('^[ghi][mno][jlk][def]$', w)]
['gold', 'golf', 'hold', 'hole']</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Первая часть выражения, <tt class="doctest"><span class="pre">«^[ghi]»</span></tt>, соответствует началу слова, за которым следует <span class="example">g</span>, <span class="example">h</span> или <span class="example">i</span>.  Следующая часть выражения, <tt class="doctest"><span class="pre">«[mno]»</span></tt>, определяет, что второй символ может быть <span class="example">m</span>, <span class="example">n</span> или <span class="example">o</span>.  Третий и четвертый символы также ограничены.
Только четыре слова удовлетворяют всем этим ограничениям.
Обратите внимание, что порядок символов внутри квадратных скобок не имеет существенного значения, так что мы могли бы написать <tt class="doctest"><span class="pre">«^[hig][nom][ljk][fed]$»</span></tt> и нашли бы те же слова.</p>
<div class="note">
<p class="first admonition-title">Замечание</p>
<p class="last"><strong>Ваша очередь</strong>: 
Найдите несколько "выкручивателей пальцев", путем поиска слов, которые используют только часть номерной панели.  Например, <tt class="doctest"><span class="pre">«^[ghijklmno]+$»</span></tt> или более кратко <tt class="doctest"><span class="pre">«^[g-o]+$»,</span></tt> будет соответствовать словам, которые используют только кнопки 4, 5, 6 в центральном ряду, а <tt class="doctest"><span class="pre">«^[a-fj-o]+$»</span></tt> будет соответствовать словам, которые используют ключи 2, 3, 5, 6 в правом верхнем углу.
Что означают <tt class="doctest"><span class="pre">-</span></tt> и <tt class="doctest"><span class="pre">+</span></tt>?</p>
</div>
<p>Давайте исследуем символ <tt class="doctest"><span class="pre">+</span></tt> еще немного.  Обратите внимание на то, что он может быть применен как к отдельной букве, так и к наборам букв, заключенным в квадратные скобки:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; chat_words = sorted(set(w for w in nltk.corpus.nps_chat.words()))
&gt;&gt;&gt; [w for w in chat_words if re.search('^m+i+n+e+$', w)]
['miiiiiiiiiiiiinnnnnnnnnnneeeeeeeeee', 'miiiiiinnnnnnnnnneeeeeeee', 'mine',
'mmmmmmmmiiiiiiiiinnnnnnnnneeeeeeee']
&gt;&gt;&gt; [w for w in chat_words if re.search('^[ha]+$', w)]
['a', 'aaaaaaaaaaaaaaaaa', 'aaahhhh', 'ah', 'ahah', 'ahahah', 'ahh',
'ahhahahaha', 'ahhh', 'ahhhh', 'ahhhhhh', 'ahhhhhhhhhhhhhh', 'h', 'ha', 'haaa',
'hah', 'haha', 'hahaaa', 'hahah', 'hahaha', 'hahahaa', 'hahahah', 'hahahaha', ...]</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Должно быть ясно, что <tt class="doctest"><span class="pre">+</span></tt> означает просто "один или несколько экземпляров предыдущего элемента", который может быть индивидуальным символов, как <tt class="doctest"><span class="pre">m</span></tt>, набором, как <tt class="doctest"><span class="pre">[fed]</span></tt>, или диапозоном, как <tt class="doctest"><span class="pre">[d-f]</span></tt>.
Теперь давайте заменим <tt class="doctest"><span class="pre">+</span></tt> на <tt class="doctest"><span class="pre">*</span></tt>, который означает "ноль или более экземпляров предыдущего пункта".
Регулярное выражение <tt class="doctest"><span class="pre">«^m*i*n*e*$»</span></tt> будет соответствовать всему, что мы нашли с помощью <tt class="doctest"><span class="pre">«^m+i+n+e+$»</span></tt>, а также словам, где некоторые из указанных букв не появляются вообще, например: <span class="example">me</span>, <span class="example">min</span> и <span class="example">mmmmm</span>.
Обратите внимание, что символы <tt class="doctest"><span class="pre">+</span></tt> и <tt class="doctest"><span class="pre">*</span></tt> иногда называют <a name="kleene_closures_index_term"></a><span class="termdef">замыканиями Клини</span>, или просто <a name="closures_index_term"></a><span class="termdef">замыканиями</span>.</p>
<p>Оператор <tt class="doctest"><span class="pre">^</span></tt> имеет другую функцию, когда он появляется в качестве первого символа внутри квадратных скобок.  Например <tt class="doctest"><span class="pre">«[^aeiouAEIOU]»</span></tt> соответствует любому символу, кроме гласного.
Мы можем выполнить поиск по NPS Chat Corpus слов, которые состоят исключительно из символов, которые не являются гласными, с помощью выражения <tt class="doctest"><span class="pre">«^ [^ aeiouAEIOU]+$»</span></tt>, чтобы найти элементы подобные этим: <tt class="doctest"><span class="pre">:) :) :)</span></tt>, <tt class="doctest"><span class="pre">grrr</span></tt>, <tt class="doctest"><span class="pre">cyb3r</span></tt> и <tt class="doctest"><span class="pre">zzzzzzzz</span></tt>.  Обратите внимание, результат включает в себя не-буквенные символы.</p>
<p>Вот еще несколько примеров регулярных выражений, которые используются, чтобы найти токены, которые соответствуют определенному шаблону, иллюстрирующие использование некоторых новых символов: <tt class="doctest"><span class="pre">\</span></tt>, <tt class="doctest"><span class="pre">{}</span></tt>, <tt class="doctest"><span class="pre">()</span></tt> и <tt class="doctest"><span class="pre">|</span></tt>:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; wsj = sorted(set(nltk.corpus.treebank.words()))
&gt;&gt;&gt; [w for w in wsj if re.search('^[0-9]+\.[0-9]+$', w)]
['0.0085', '0.05', '0.1', '0.16', '0.2', '0.25', '0.28', '0.3', '0.4', '0.5',
'0.50', '0.54', '0.56', '0.60', '0.7', '0.82', '0.84', '0.9', '0.95', '0.99',
'1.01', '1.1', '1.125', '1.14', '1.1650', '1.17', '1.18', '1.19', '1.2', ...]
&gt;&gt;&gt; [w for w in wsj if re.search('^[A-Z]+\$$', w)]
['C$', 'US$']
&gt;&gt;&gt; [w for w in wsj if re.search('^[0-9]{4}$', w)]
['1614', '1637', '1787', '1901', '1903', '1917', '1925', '1929', '1933', ...]
&gt;&gt;&gt; [w for w in wsj if re.search('^[0-9]+-[a-z]{3,5}$', w)]
['10-day', '10-lap', '10-year', '100-share', '12-point', '12-year', ...]
&gt;&gt;&gt; [w for w in wsj if re.search('^[a-z]{5,}-[a-z]{2,3}-[a-z]{,6}$', w)]
['black-and-white', 'bread-and-butter', 'father-in-law', 'machine-gun-toting',
'savings-and-loan']
&gt;&gt;&gt; [w for w in wsj if re.search('(ed|ing)$', w)]
['62%-owned', 'Absorbed', 'According', 'Adopting', 'Advanced', 'Advancing', ...]
</pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="note">
<p class="first admonition-title">Замечание</p>
<p class="last"><strong>Ваша очередь:</strong> 
Изучите приведенные выше примеры и попытайтесь понять , что означают символы <tt class="doctest"><span class="pre">\</span></tt>, <tt class="doctest"><span class="pre">{}</span></tt>, <tt class="doctest"><span class="pre">()</span></tt> и <tt class="doctest"><span class="pre">|</span></tt>, прежде чем читать дальше.</p>
</div>
<p>Вы, наверное, поняли, что обратная косая черта означает, что следующий символ лишается своих особых полномочий и должен буквально соответствовать символу в слове.  Таким образом, если <tt class="doctest"><span class="pre">.</span></tt> является особым символом, то <tt class="doctest"><span class="pre">\.</span></tt> соответствует только точке.
Выражения, заключенные в фигурные скобки, как <tt class="doctest"><span class="pre">{3,5}</span></tt>, указывают количество повторений предыдущего элемента.
Символ вертикальная черта указывает на выбор между материалом с левой и правой стороны от него.
Скобки показывают сферу применения оператора: они могут быть использованы вместе с символом вертикальной черты (или дизъюнкции) следующим образом: <tt class="doctest"><span class="pre">«w(i|e|ai|oo)t»</span></tt>, что соответствует словам <span class="example">wit</span>, <span class="example">wet</span>, <span class="example">wait</span> и <span class="example">woot</span>.  Поучительно посмотреть, что произойдет, если вы опустите скобки из последнего выражения выше и будете искать <tt class="doctest"><span class="pre">«ed | ing$»</span></tt>.</p>
<p>Метасимволы, которые мы увидели, кратко охарактеризованы в <a class="reference internal" href="http://www.nltk.org/book/ch03.html#tab-regexp-meta-characters1">3.3</a>.</p>
<span class="target" id="tab-regexp-meta-characters1"></span><table border="1" class="docutils" id="tab-regexp-meta-characters1">
<colgroup>
<col width="15%">
<col width="85%">
</colgroup>
<thead valign="bottom">
<tr><th class="head">оператор</th>
<th class="head">Поведение</th>
</tr>
</thead>
<tbody valign="top">
<tr><td><tt class="doctest"><span class="pre">.</span></tt></td>
<td>Подстановочный символ, соответствует любому символу</td>
</tr>
<tr><td><tt class="doctest"><span class="pre">^abc</span></tt></td>
<td>Соответствует некоторому шаблону <span class="math">abc</span> в начале строки</td>
</tr>
<tr><td><tt class="doctest"><span class="pre">abc$</span></tt></td>
<td>Соответствует некоторому шаблону <span class="math">abc</span> в конце строки</td>
</tr>
<tr><td><tt class="doctest"><span class="pre">[abc]</span></tt></td>
<td>Соответствует одному из набора символов</td>
</tr>
<tr><td><tt class="doctest"><span class="pre">[A-Z0-9]</span></tt></td>
<td>Соответствует одному из диапазона символов</td>
</tr>
<tr><td><tt class="doctest"><span class="pre">ed | ing | s</span></tt></td>
<td>Соответствует одной из указанных строк (дизъюнкция)</td>
</tr>
<tr><td><tt class="doctest"><span class="pre">*</span></tt></td>
<td>Ноль или более экземпляров предыдущего элемента, например, <tt class="doctest"><span class="pre">a*</span></tt>, <tt class="doctest"><span class="pre">[a-z]*</span></tt> (также известный как <em>Замыкания Клини</em>)</td>
</tr>
<tr><td><tt class="doctest"><span class="pre">+</span></tt></td>
<td>Один или несколько экземпляров предыдущего элемента, например, <tt class="doctest"><span class="pre">a+</span></tt>, <tt class="doctest"><span class="pre">[a-z]+</span></tt></td>
</tr>
<tr><td><tt class="doctest"><span class="pre">?</span></tt></td>
<td>Ноль или один экземпляр предыдущего элемента (т.е. опционально), например, <tt class="doctest"><span class="pre">a?</span></tt>, <tt class="doctest"><span class="pre">[a-z]?</span></tt></td>
</tr>
<tr><td><tt class="doctest"><span class="pre">{n}</span></tt></td>
<td>Ровно <span class="math">n</span> повторов, где n является неотрицательным целым числом</td>
</tr>
<tr><td><tt class="doctest"><span class="pre">{n,}</span></tt></td>
<td>По крайней мере, <span class="math">n</span> повторов</td>
</tr>
<tr><td><tt class="doctest"><span class="pre">{,n}</span></tt></td>
<td>Не больше, чем <span class="math">n</span> повторов</td>
</tr>
<tr><td><tt class="doctest"><span class="pre">{m,n}</span></tt></td>
<td>По крайней мере <span class="math">m</span>, но не более чем <span class="math">n</span> повторов</td>
</tr>
<tr><td><tt class="doctest"><span class="pre">a(b|c)+</span></tt></td>
<td>Скобки, которые указывают на сферу действия операторов</td>
</tr>
</tbody>
<td><p class="caption"><span class="caption-label">Таблица 3.3</span>: <p>Основные метасимволы регулярных выражений, в том числе подстановочные, диапазоны и замыкания</p>
</p>
</td></table>
<p>Для интерпретатора Python регулярное выражение подобно любой другой строке.
Если строка содержит обратную косую черту, за которой следуют определенные символы, он будет интерпретировать их особым образом.  Например, <tt class="doctest"><span class="pre">\b</span></tt> будет интерпретироваться как возврат на одну позицию.  В общем, при использовании регулярных выражений, содержащих обратную косую черту, мы должны поручить интерпретатору не смотреть внутрь строки совсем, а просто передать ее непосредственно в библиотеку <tt class="doctest"><span class="pre">re</span></tt> для обработки.
Мы делаем это, предваряя строку буквой <tt class="doctest"><span class="pre">r</span></tt>, чтобы указать, что это <a name="raw_string_index_term"></a><span class="termdef">сырая строка</span>.  Например, сырая строка <tt class="doctest"><span class="pre">r<span class="pysrc-string">'\band\b'</span></span></tt> содержит два <tt class="doctest"><span class="pre">\b</span></tt> символа, которые интерпретируются библиотекой <tt class="doctest"><span class="pre">re</span></tt> как соответствующие границам слова, а не как символы возврата на одну позицию назад.
Если вы приучитесь использовать <tt class="doctest"><span class="pre">г<span class="pysrc-string">'...'</span></span></tt> для регулярных выражений - как мы будем делать с этого момента - вы избавите себя от необходимости думать об этих сложностях.</p>
</div>
</div>
<div class="section" id="useful-applications-of-regular-expressions">
<span id="sec-useful-applications-of-regular-expressions"></span><h2>3.5 Полезные приложения регулярных выражений</h2>
<p>Все выше приведенные примеры включали в себя поиск слов <span class="math">w</span>, которые соответствуют некоторому регулярному выражению <span class="example">regexp</span> с помощью <tt class="doctest"><span class="pre">re.search(regexp, w)</span></tt>.
Помимо проверки того, что регулярное выражение соответствует слову, мы можем использовать регулярные выражения для извлечения материала из слов или чтобы изменять слова определенным образом.</p>
<div class="section" id="extracting-word-pieces">
<h3>Извлечение частей слова</h3>
<p>Метод <tt class="doctest"><span class="pre">re.findall()</span></tt> ( "найти все") находит все (непересекающиеся) соответствия данного регулярного выражения.  Давайте найдем все гласные в слове, а затем сосчитаем их:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; word = 'supercalifragilisticexpialidocious'
&gt;&gt;&gt; re.findall(r'[aeiou]', word)
['u', 'e', 'a', 'i', 'a', 'i', 'i', 'i', 'e', 'i', 'a', 'i', 'o', 'i', 'o', 'u']
&gt;&gt;&gt; len(re.findall(r'[aeiou]', word))
16</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Давайте найдем все последовательности из двух или более гласных в некотором тексте и определим их относительную частоту:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; wsj = sorted(set(nltk.corpus.treebank.words()))
&gt;&gt;&gt; fd = nltk.FreqDist(vs for word in wsj
...                       for vs in re.findall(r'[aeiou]{2,}', word))
&gt;&gt;&gt; fd.most_common(12)
[('io', 549), ('ea', 476), ('ie', 331), ('ou', 329), ('ai', 261), ('ia', 253),
('ee', 217), ('oo', 174), ('ua', 109), ('au', 106), ('ue', 105), ('ui', 95)]</pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="note">
<p class="first admonition-title">Замечание</p>
<p><strong>Ваша очередь</strong>: 
В формате даты времени W3C даты представлены следующим образом : 2009-12-31.
Замените <tt class="doctest"><span class="pre">?</span></tt> в следующем коде Python регулярным выражением для того, чтобы преобразовать строку <tt class="doctest"><span class="pre"><span class="pysrc-string">'2009-12-31'</span></span></tt> в список целых чисел <tt class="doctest"><span class="pre">[2009, 12, 31]</span></tt>:</p>
<p class="last"><tt class="doctest"><span class="pre">[int(n) for n in re.findall(?, '2009-12-31')]</span></tt></p>
</div>
</div>
<div class="section" id="doing-more-with-word-pieces">
<h3>Что еще можно делать с частями слов?</h3>
<p>Раз мы уже научились использовать <tt class="doctest"><span class="pre">re.findall()</span></tt> для извлечения частей слов, то теперь есть интересные вещи, которые мы можем сделать с этими частями, как, например, склеить их обратно вместе или найти зависимость между ними.</p>
<p>Иногда отмечают, что английский текст весьма избыточен, и его по-прежнему легко читать, даже когда гласные внутри слов опущены.  Например, <span class="example">declaration</span> становится <span class="example">dclrtn</span>, а <span class="example">inalienable</span> становится <span class="example">inlnble</span>, сохраняя любые начальные или конечные последовательности гласных.   Регулярное выражение в нашем следующем примере соответствует начальной последовательности гласных, конечной последовательности гласных, и всем согласным; все остальное игнорируется.  Эта трехсторонняя дизъюнкция обрабатывается слева направо, если одна из трех частей соответствует слову, все последующие части регулярного выражения игнорируются.
Мы используем <tt class="doctest"><span class="pre">re.findall()</span></tt>, чтобы извлечь все совпадающие части, и <tt class="doctest"><span class="pre"><span class="pysrc-string">''</span>.join()</span></tt>, чтобы соединить их вместе (см <a class="reference internal" href="http://www.nltk.org/book/ch03.html#sec-formatting">3.9</a> для получения дополнительной информации об операции соединения).</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; regexp = r'^[AEIOUaeiou]+|[AEIOUaeiou]+$|[^AEIOUaeiou]'
&gt;&gt;&gt; def compress(word):
...     pieces = re.findall(regexp, word)
...     return ''.join(pieces)
...
&gt;&gt;&gt; english_udhr = nltk.corpus.udhr.words('English-Latin1')
&gt;&gt;&gt; print(nltk.tokenwrap(compress(w) for w in english_udhr[:75]))
Unvrsl Dclrtn of Hmn Rghts Prmble Whrs rcgntn of the inhrnt dgnty and
of the eql and inlnble rghts of all mmbrs of the hmn fmly is the fndtn
of frdm , jstce and pce in the wrld , Whrs dsrgrd and cntmpt fr hmn
rghts hve rsltd in brbrs acts whch hve outrgd the cnscnce of mnknd ,
and the advnt of a wrld in whch hmn bngs shll enjy frdm of spch and</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Далее, давайте объединим регулярные выражения с условным распределением частот.  Здесь мы будем извлекать все согласно-гласные последовательности из слов языка Rotokas, такие как <span class="example">ka</span> и <span class="example">si</span>.  Так как каждая из них является парой, это может быть использовано для инициализации условного распределения частоты.  Затем мы представляем в виде таблицы частоту каждой пары:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; rotokas_words = nltk.corpus.toolbox.words('rotokas.dic')
&gt;&gt;&gt; cvs = [cv for w in rotokas_words for cv in re.findall(r'[ptksvr][aeiou]', w)]
&gt;&gt;&gt; cfd = nltk.ConditionalFreqDist(cvs)
&gt;&gt;&gt; cfd.tabulate()
    a    e    i    o    u
k  418  148   94  420  173
p   83   31  105   34   51
r  187   63   84   89   79
s    0    0  100    2    1
t   47    8    0  148   37
v   93   27  105   48   49</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Рассмотрев строки для <span class="example">s</span> и <span class="example">t</span>, мы обнаружим, что они находятся в частичном "дополнительном распределении", которое является доказательством того, что они не являются отдельными фонемами в языке.  Таким образом, мы, вероятно, можем выбросить <span class="example">s</span> из алфавита Rotokas и просто иметь правило произношения, что буква <span class="example">t</span> произносится как <span class="example">s</span>, когда за ней идет <span class="example">i</span>.  (Обратите внимание , что единственная запись, имеющая <em>su</em>, а именно <em>kasuari</em>, 'cassowary' ('казуар') заимствовано из английского языка.)</p>
<p>Если мы хотим иметь возможность просмотреть слова, которые стоят за числами в таблице выше, то было бы полезно иметь индекс, позволяющий нам быстро найти список слов, содержащих данную пару согласного-гласного, например <tt class="doctest"><span class="pre">cv_index [<span class="pysrc-string">'su'</span>]</span></tt> должно дать нам все слова, содержащие <span class="example">su</span>.  Вот как мы можем это сделать:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; cv_word_pairs = [(cv, w) for w in rotokas_words
...                          for cv in re.findall(r'[ptksvr][aeiou]', w)]
&gt;&gt;&gt; cv_index = nltk.Index(cv_word_pairs)
&gt;&gt;&gt; cv_index['su']
['kasuari']
&gt;&gt;&gt; cv_index['po']
['kaapo', 'kaapopato', 'kaipori', 'kaiporipie', 'kaiporivira', 'kapo', 'kapoa',
'kapokao', 'kapokapo', 'kapokapo', 'kapokapoa', 'kapokapoa', 'kapokapora', ...]</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Эта программа обрабатывает каждое слово <tt class="doctest"><span class="pre">w</span></tt> по очереди и для каждого из них находит каждую подстроку, которая соответствует регулярному выражению <tt class="doctest"><span class="pre">«[ptksvr][aeiou]»</span></tt>.
В случае слова <span class="example">kasuari,</span> она находит <span class="example">ka</span>, <span class="example">su</span> и <span class="example">ri</span>.
Таким образом, список <tt class="doctest"><span class="pre">cv_word_pairs</span></tt> будет содержать <tt class="doctest"><span class="pre">(<span class="pysrc-string">'ka'</span>, <span class="pysrc-string">'kasuari'</span>)</span></tt>, <tt class="doctest"><span class="pre">(<span class="pysrc-string">'su'</span>, <span class="pysrc-string">'kasuari'</span>)</span></tt> и <tt class="doctest"><span class="pre">(<span class="pysrc-string">'ri'</span>, <span class="pysrc-string">'kasuari'</span>)</span></tt>.  Еще один шаг, используя <tt class="doctest"><span class="pre">nltk.Index()</span></tt>, преобразует это в полезный индекс.</p>
</div>
<div class="section" id="finding-word-stems">
<h3>Нахождение основ слов</h3>
<p>Когда мы используем систему веб-поиска, мы обычно не задумываемся (или замечаем), если слова в документе отличаются от наших условий поиска наличием различных окончаний.  Поиск <span class="example">laptops</span> находит документы, содержащие <span class="example">laptop</span>, и наоборот.
В самом деле, <span class="example">ноутбук</span> и <span class="example">ноутбуки</span> всего лишь две формы одного и того же словарного элемента (или леммы).
Для некоторых задач обработки языка мы хотим игнорировать окончания слов, а просто иметь дело с основами слов.</p>
<p>Существуют различные способы выделить основу слова.  Вот простой незамысловатый подход, который просто отбрасывает все, что выглядит как суффикс:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; def stem(word):
...     for suffix in ['ing', 'ly', 'ed', 'ious', 'ies', 'ive', 'es', 's', 'ment']:
...         if word.endswith(suffix):
...             return word[:-len(suffix)]
...     return word</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Хотя мы в конечном счете будем использовать встроенные в NLTK определители основ, интересно посмотреть, как мы можем использовать регулярные выражения для выполнения этой задачи.  Наш первый шаг заключается в создании дизъюнкции всех суффиксов.  Нам нужно заключить ее в скобки, чтобы ограничить сферу дизъюнкции.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; re.findall(r'^.*(ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processing')
['ing']</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Здесь <tt class="doctest"><span class="pre">re.findall()</span></tt> просто дал нам суффикс, несмотря на то, что регулярное выражение соответствовало слову целиком.  Это произошло потому, что круглые скобки имеют вторую функцию - выбирать подстроки, которые необходимо извлечь.  Если мы хотим использовать круглые скобки, чтобы
указать сферу дизъюнкции, а не выбирать материал, который будет выводиться,
мы должны добавить обозначение <tt class="doctest"><span class="pre">?:</span></tt>, которое является лишь одним из многих тайных тонкостей регулярных выражений.
Вот пересмотренный вариант.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; re.findall(r'^.*(?:ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processing')
['processing']</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Однако, на самом деле, мы хотели бы разделить слово на основу и суффикс.
Таким образом, мы должны просто взять в скобки обе части регулярного выражения:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; re.findall(r'^(.*)(ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processing')
[('process', 'ing')]</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Это выглядит многообещающим, но до сих пор есть одна проблема.   Давайте посмотрим на другое слово, <span class="example">processes</span>:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; re.findall(r'^(.*)(ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processes')
[('processe', 's')]</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Регулярное выражение неправильно нашло суффикс <span class="example">-s</span> вместо суффиксf <span class="example">-es</span>.  Это демонстрирует еще одну тонкость: оператор звездочка "жадный" и часть выражения <tt class="doctest"><span class="pre">.*</span></tt> пытается проглотить столько входных данных, сколько возможно.  Если мы используем "не жадный" версию оператора звезды, написанный <tt class="doctest"><span class="pre">*?</span></tt> , Мы получаем то, что мы хотим:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; re.findall(r'^(.?)(ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processes')
[('process', 'es')]</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Это работает даже тогда, когда мы допускаем пустой суффикс, сделав содержание второй скобки необязательным:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; re.findall(r'^(.*?)(ing|ly|ed|ious|ies|ive|es|s|ment)?$', 'language')
[('language', '')]</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Такой подход все равно имеет много проблем (вы можете обнаружить их?) но мы будем двигаться дальше, чтобы определить функцию для выделения основ и применить ее к целому тексту:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; def stem(word):
...     regexp = r'^(.*?)(ing|ly|ed|ious|ies|ive|es|s|ment)?$'
...     stem, suffix = re.findall(regexp, word)[0]
...     return stem
...
&gt;&gt;&gt; raw = """DENNIS: Listen, strange women lying in ponds distributing swords
... is no basis for a system of government. Supreme executive power derives from
... a mandate from the masses, not from some farcical aquatic ceremony."""
&gt;&gt;&gt; tokens = word_tokenize(raw)
&gt;&gt;&gt; [stem(t) for t in tokens]
['DENNIS', ':', 'Listen', ',', 'strange', 'women', 'ly', 'in', 'pond', 'distribut',
'sword', 'i', 'no', 'basi', 'for', 'a', 'system', 'of', 'govern', '.', 'Supreme',
'execut', 'power', 'deriv', 'from', 'a', 'mandate', 'from', 'the', 'mass', ',',
'not', 'from', 'some', 'farcical', 'aquatic', 'ceremony', '.']</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Обратите внимание на то, что наше регулярное выражение удалило <span class="example">s</span> не только из <span class="example">ponds</span>, но и из <span class="example">is</span> и <span class="example">basis</span>.  Он произвел некоторые не-слова, как, например, <span class="example">distribut</span> и <span class="example">deriv</span>, но они являются приемлемыми основами в некоторых приложениях.</p>
</div>
<div class="section" id="searching-tokenized-text">
<h3>Поиск по токенизированному тексту</h3>
<p>Вы можете использовать особый вид регулярного выражения для поиска нескольких слов в тексте (где текст представляет собой список токенов).  Например, <tt class="doctest"><span class="pre"><span class="pysrc-string">"&lt;a&gt; &lt;man&gt;"</span></span></tt> находит все экземпляры <span class="example">a man</span> в тексте.  Угловые скобки используются для обозначения границ токенов, и любой пробел между угловыми скобками игнорируется (поведение, которое является уникальным для метода NLTK <tt class="doctest"><span class="pre">findall()</span></tt> для текстов).  В следующем примере мы включаем выражение <tt class="doctest"><span class="pre">&lt;.*&gt;</span></tt> <a class="reference internal" href="http://www.nltk.org/book/ch03.html#single-token-wildcard"><span id="ref-single-token-wildcard"><img class="callout" alt="[1]" src="http://www.nltk.org/book/callouts/callout1.gif"></span></a>, которому будет соответствовать любой одиночный токен, и заключаем его в скобки, чтобы только подходящее слово (например , <span class="example">monied</span>), а не подходящая фраза <span class="example">(например, monied man)</span> попадала в результат.  Второй пример находит фразы, состоящие из трех слов, заканчивающиеся на слово <span class="example">bro</span> <a class="reference internal" href="http://www.nltk.org/book/ch03.html#three-word-phrases"><span id="ref-three-word-phrases"><img class="callout" alt="[2]" src="http://www.nltk.org/book/callouts/callout2.gif"></span></a>.  Последний пример находит последовательности из трех и более слов, начинающиеся с буквы <span class="example">l</span> <a class="reference internal" href="http://www.nltk.org/book/ch03.html#letter-l"><span id="ref-letter-l"><img class="callout" alt="[3]" src="http://www.nltk.org/book/callouts/callout3.gif"></span></a>.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; from nltk.corpus import gutenberg, nps_chat
&gt;&gt;&gt; moby = nltk.Text(gutenberg.words('melville-moby_dick.txt'))
&gt;&gt;&gt; moby.findall(r"&lt;a&gt; (&lt;.*&gt;) &lt;man&gt;") 
monied; nervous; dangerous; white; white; white; pious; queer; good;
mature; white; Cape; great; wise; wise; butterless; white; fiendish;
pale; furious; better; certain; complete; dismasted; younger; brave;
brave; brave; brave
&gt;&gt;&gt; chat = nltk.Text(nps_chat.words())
&gt;&gt;&gt; chat.findall(r"&lt;.*&gt; &lt;.*&gt; &lt;bro&gt;") 
you rule bro; telling you bro; u twizted bro
&gt;&gt;&gt; chat.findall(r"&lt;l.*&gt;{3,}") 
lol lol lol; lmao lol lol; lol lol lol; la la la la la; la la la; la
la la; lovely lol lol love; lol lol lol.; la la la; la la la</pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="note">
<p class="first admonition-title">Замечание</p>
<p class="last"><strong>Ваша очередь:</strong> 
Консолидируйте ваше понимание паттернов регулярных выражений и замен с помощью <tt class="doctest"><span class="pre">nltk.re_show(<em>р, s</em>)</span></tt>, которая аннотирует строку <em>s</em> с тем, чтобы показать каждое место, где было установлено соответствие модели <em>р</em>, и <tt class="doctest"><span class="pre">nltk.app.nemo()</span></tt>, которая предоставляет графический интерфейс для исследования регулярных выражений.  Если вы хотите еще попрактиковаться, попробуйте некоторые из упражнений на регулярные выражения в конце этой главы.</p>
</div>
<!-- TODO: Add code example for type-instance relations. -->
<p>Легко построить шаблоны поиска, когда лингвистическое явление, которое мы изучаем, привязано к конкретным словам.  В некоторых случаях, потребуется больше творчества.  Например, поиск в большом текстовом корпусе выражений вида <span class="example">х и другие у-и</span> позволяет обнаружить гипернимы (cf <a class="reference external" href="http://www.nltk.org/book/ch02.html#sec-wordnet">5</a>):</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; from nltk.corpus import brown
&gt;&gt;&gt; hobbies_learned = nltk.Text(brown.words(categories=['hobbies', 'learned']))
&gt;&gt;&gt; hobbies_learned.findall(r"&lt;\w*&gt; &lt;and&gt; &lt;other&gt; &lt;\w*s&gt;")
speed and other activities; water and other liquids; tomb and other
landmarks; Statues and other monuments; pearls and other jewels;
charts and other items; roads and other features; figures and other
objects; military and other areas; demands and other factors;
abstracts and other compilations; iron and other metals</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>При наличии достаточного количества текста, такой подход даст нам полезный запас информации о систематике объектов без необходимости какого-либо ручного труда.  Тем не менее, наши результаты поиска обычно содержат ложные срабатывания, то есть случаи, которые мы хотели бы исключить.
Например, результат: <span class="example">требования и другие факторы</span> предполагает, что <span class="example">требование</span> является экземпляром типа <span class="example">фактор</span>, но это предложение, на самом деле, о требованиях по заработной плате.  Тем не менее, мы могли бы построить собственную онтологию английских понятий, вручную исправляя результат таких поисков.</p>
<div class="note">
<p class="first admonition-title">Замечание</p>
<p class="last">Такое сочетание автоматической и ручной обработки является наиболее распространенным способом построения новых корпусов.  Мы вернемся к этому вопросу в <a class="reference external" href="http://www.nltk.org/book/ch11.html#chap-data">11.</a>.</p>
</div>
<p>Поиск по корпусам также страдает от проблемы ложных несрабатываний, то есть пропуск случаев, которые мы хотели бы включить.  Рискованно делать вывод, что некоторые лингвистические явления не присутствуют в корпусе только потому, что мы не смогли найти ни одного экземпляра шаблона поиска.
Может быть, мы просто недостаточно тщательно подумали о подходящих моделях.</p>
<div class="note">
<p class="first admonition-title">Замечание</p>
<p class="last"><strong>Ваша очередь:</strong> 
Выполните поиск экземпляров шаблона <span class="example">как х</span>, <span class="example">так и у</span>, чтобы обнаружить информацию о сущностях и их свойствах.</p>
</div>
<!-- searching for doubled final consonants: .*([bdgptk])1ed
transforming date strings
HTML stripping
spelling correction
textonyms -->
</div>
</div>
<div class="section" id="normalizing-text">
<span id="sec-normalizing-text"></span><h2>3.6 Нормализация текста</h2>
<p>В предыдущих примерах программ мы часто преобразовали текст в нижний регистр, прежде чем делать что-либо с его словами, например, <tt class="doctest"><span class="pre">set(w.lower() <span class="pysrc-keyword">for</span> w <span class="pysrc-keyword">in</span> text)</span></tt>.
Используя <tt class="doctest"><span class="pre">lower()</span></tt>, мы <span class="termdef">приводили</span> текст к нижнему регистру, чтобы различие между The и the игнорировалось.  Часто мы хотим пойти дальше этого и отбросить любые аффиксы, эта задача известна как выделение основы.
Еще один шаг состоит в том, чтобы убедиться, что полученная форма представляет собой известное слово в словаре, эта задача известна как лемматизация.  Мы рассмотрим каждый из них по порядку.  Во-первых, нам необходимо определить данные, которые мы будем использовать в этом разделе:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; raw = """DENNIS: Listen, strange women lying in ponds distributing swords
... is no basis for a system of government.  Supreme executive power derives from
... a mandate from the masses, not from some farcical aquatic ceremony."""
&gt;&gt;&gt; tokens = word_tokenize(raw)</pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="section" id="stemmers">
<h3>Выделители основы слова</h3>
<p>NLTK включает в себя несколько готовых выделителей основы слова, и если вам когда-нибудь понадобится выделитель основы слов, вы должны использовать один, предпочитая их созданию своих собственных с помощью регулярных выражений, так как они обрабатывают широкий спектр нерегулярных случаев.
Выделители основ Портера и Ланкастера следуют своим собственным правилам для отчистки от аффиксов.
Заметим, что выделитель основы Портера правильно обрабатывает слово <span class="example">lying</span> (устанавливая его соответствие слову <span class="example">lie</span>), тогда как выделитель основы Ланкастера нет.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; porter = nltk.PorterStemmer()
&gt;&gt;&gt; lancaster = nltk.LancasterStemmer()
&gt;&gt;&gt; [porter.stem(t) for t in tokens]
['DENNI', ':', 'Listen', ',', 'strang', 'women', 'lie', 'in', 'pond',
'distribut', 'sword', 'is', 'no', 'basi', 'for', 'a', 'system', 'of', 'govern',
'.', 'Suprem', 'execut', 'power', 'deriv', 'from', 'a', 'mandat', 'from',
'the', 'mass', ',', 'not', 'from', 'some', 'farcic', 'aquat', 'ceremoni', '.']
&gt;&gt;&gt; [lancaster.stem(t) for t in tokens]
['den', ':', 'list', ',', 'strange', 'wom', 'lying', 'in', 'pond', 'distribut',
'sword', 'is', 'no', 'bas', 'for', 'a', 'system', 'of', 'govern', '.', 'suprem',
'execut', 'pow', 'der', 'from', 'a', 'mand', 'from', 'the', 'mass', ',', 'not',
'from', 'som', 'farc', 'aqu', 'ceremony', '.']</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Выделение основ не является четко определенным процессом, и мы, как правило, выбираем выделитель, который лучше всего подходит для определенного приложения.  Выделитель Портера является хорошим выбором, если вы индексируете некоторые тексты и хотите поддерживать поиск с использованием альтернативных форм слов (это решение проиллюстрировано в листинге <a class="reference internal" href="http://www.nltk.org/book/ch03.html#code-stemmer-indexing">3.6</a>, который использует <em>объектно-ориентированные</em> методы программирования, выходящие за рамки этой книги, методы форматирования строк, которые будут рассмотрены в <a class="reference internal" href="http://www.nltk.org/book/ch03.html#sec-formatting">3.9</a>, и функцию <tt class="doctest"><span class="pre">enumerate()</span></tt>, которая будет объяснена в <a class="reference external" href="http://www.nltk.org/book/ch04.html#sec-sequences">4.2</a>).</p>
<span class="target" id="code-stemmer-indexing"></span><div class="pylisting">
<table border="0" cellpadding="0" cellspacing="0" class="pylisting" width="95%">
<tr><td class="codeblock">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_codeblock_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
class IndexedText(object):

    def __init__(self, stemmer, text):
        self._text = text
        self._stemmer = stemmer
        self._index = nltk.Index((self._stem(word), i)
                                 for (i, word) in enumerate(text))

    def concordance(self, word, width=40):
        key = self._stem(word)
        wc = int(width/4)                # words of context
        for i in self._index[key]:
            lcontext = ' '.join(self._text[i-wc:i])
            rcontext = ' '.join(self._text[i:i+wc])
            ldisplay = '{:&gt;{width}}'.format(lcontext[-width:], width=width)
            rdisplay = '{:{width}}'.format(rcontext[:width], width=width)
            print(ldisplay, rdisplay)

    def _stem(self, word):
        return self._stemmer.stem(word).lower()</pre>
</td>
</tr></table></td></tr>
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; porter = nltk.PorterStemmer()
&gt;&gt;&gt; grail = nltk.corpus.webtext.words('grail.txt')
&gt;&gt;&gt; text = IndexedText(porter, grail)
&gt;&gt;&gt; text.concordance('lie')
r king ! DENNIS : Listen , strange women lying in ponds distributing swords is no
 beat a very brave retreat . ROBIN : All lies ! MINSTREL : [ singing ] Bravest of
       Nay . Nay . Come . Come . You may lie here . Oh , but you are wounded !</span>
<span class="pysrc-output">doctors immediately ! No , no , please ! Lie down . [ clap clap ] PIGLET : Well
ere is much danger , for beyond the cave lies the Gorge of Eternal Peril , which
   you . Oh ... TIM : To the north there lies a cave -- the cave of Caerbannog --
h it and lived ! Bones of full fifty men lie strewn about its lair . So , brave k
not stop our fight ' til each one of you lies dead , and the Holy Grail returns t</pre>
</td>
</tr></table></td></tr>
<tr><td class="caption"><p class="caption"><a class="reference external" href="http://www.nltk.org/book/pylisting/code_stemmer_indexing.py" type="text/x-python"><span class="caption-label">Пример 3.6 (code_stemmer_indexing.py)</span></a> : <span class="caption-label">Рисунок 3.6:</span> Индексация текста с помощью выделителя основ</p></td></tr>
</table></div>
</div>
<div class="section" id="lemmatization">
<h3>Лемматизация</h3>
<p>WordNet лемматизатор удаляет только аффиксы, если полученное слово есть в его словаре.
Этот дополнительный процесс проверки делает лемматизатор медленнее, чем выше приведенные выделители.
Обратите внимание на то, что он не обрабатывает <span class="example">lying</span>, но он преобразует <span class="example">women</span> в <span class="example">woman</span>.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; wnl = nltk.WordNetLemmatizer()
&gt;&gt;&gt; [wnl.lemmatize(t) for t in tokens]
['DENNIS', ':', 'Listen', ',', 'strange', 'woman', 'lying', 'in', 'pond',
'distributing', 'sword', 'is', 'no', 'basis', 'for', 'a', 'system', 'of',
'government', '.', 'Supreme', 'executive', 'power', 'derives', 'from', 'a',
'mandate', 'from', 'the', 'mass', ',', 'not', 'from', 'some', 'farcical',
'aquatic', 'ceremony', '.']</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>WordNet лемматизатор является хорошим выбором, если вы хотите составить словарь некоторых текстов и хотите иметь список действительных лемм (или гнезд лексикона).</p>
<div class="note">
<p class="first admonition-title">Замечание</p>
<p class="last">Другая задача нормализации включает в себя определение <a name="non_standard_words_index_term"></a><span class="termdef">нестандартных слов</span>, включая номера, сокращения и сроки, и сопоставление любых таких токенов специальному словарю.  Например, каждое десятичное число может быть поставлено в соответствие одному токену <tt class="doctest"><span class="pre">0.0</span></tt>, а каждый акроним может быть поставлен в соответствие <tt class="doctest"><span class="pre">AAA</span></tt>. Это позволяет сохранить небольшой размер словаря и повышает точность многих задач моделирования языка.</p>
</div>
<!-- Non-Standard Words
- - - - - - - - - - - - - - - - - -

[Discuss the practice of mapping words such as numbers, abbreviations, dates to
a special vocabulary, based on Sproat et al 2001; new NLTK support planned...] -->
</div>
</div>
<div class="section" id="regular-expressions-for-tokenizing-text">
<span id="sec-tokenization"></span><h2>3.7 Регулярные выражения для токенизации текста</h2>
<p>Токенизация - это задача разделения строки на различимые языковые единицы, которые составляют часть языковых данных.
Несмотря на то, что это фундаментальная задача, мы смогли отложить ее до этого момента, потому что многие корпусы уже токенизированы, а также потому, что NLTK включает в себя несколько токенизаторов.
Теперь, когда вы знакомы с регулярными выражениями, вы можете узнать, как использовать их, чтобы разметить текст и иметь гораздо больший контроль над процессом.</p>
<div class="section" id="simple-approaches-to-tokenization">
<h3>Простые подходы к токенизации</h3>
<p>Самый простой метод токенизации текста заключается в разделении его, используя пробелы.
Рассмотрим следующий текст из <em>Алисы в стране чудес</em>:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; raw = """'When I'M a Duchess,' she said to herself, (not in a very hopeful tone
... though), 'I won't have any pepper in my kitchen AT ALL. Soup does very
... well without--Maybe it's always pepper that makes people hot-tempered,'..."""
</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Мы могли бы разделить этот необработанный текст по пробелам с помощью <tt class="doctest"><span class="pre">raw.split()</span></tt>.
Для того, чтобы сделать то же самое, используя регулярное выражение, не достаточно найти все символы пробела в строке <a class="reference internal" href="http://www.nltk.org/book/ch03.html#split-space"><span id="ref-split-space"><img class="callout" alt="[1]" src="http://www.nltk.org/book/callouts/callout1.gif"></span></a>, так как в этом случае в результат попадают токены, которые содержат символ новой строки <tt class="doctest"><span class="pre">\n</span></tt>; вместо этого мы должны найти любое количество пробелов, табуляций или символов новой строки <a class="reference internal" href="http://www.nltk.org/book/ch03.html#split-whitespace"><span id="ref-split-whitespace"><img class="callout" alt="[2]" src="http://www.nltk.org/book/callouts/callout2.gif"></span></a>:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; re.split(r' ', raw) 
["'When", "I'M", 'a', "Duchess,'", 'she', 'said', 'to', 'herself,', '(not', 'in',
'a', 'very', 'hopeful', 'tone\nthough),', "'I", "won't", 'have', 'any', 'pepper',
'in', 'my', 'kitchen', 'AT', 'ALL.', 'Soup', 'does', 'very\nwell', 'without--Maybe',
"it's", 'always', 'pepper', 'that', 'makes', 'people', "hot-tempered,'..."]
&gt;&gt;&gt; re.split(r'[ \t\n]+', raw) 
["'When", "I'M", 'a', "Duchess,'", 'she', 'said', 'to', 'herself,', '(not', 'in',
'a', 'very', 'hopeful', 'tone', 'though),', "'I", "won't", 'have', 'any', 'pepper',
'in', 'my', 'kitchen', 'AT', 'ALL.', 'Soup', 'does', 'very', 'well', 'without--Maybe',
"it's", 'always', 'pepper', 'that', 'makes', 'people', "hot-tempered,'..."]</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Регулярное выражение <tt class="doctest"><span class="pre">«[ \t\n]+»</span></tt> соответствует одному или нескольким пробелам, табуляциям <tt class="doctest"><span class="pre">(\t)</span></tt> или символам новой строки <tt class="doctest"><span class="pre">(\n)</span></tt>.  Другие символы пробела, такие как возврат каретки и формы ввода, на самом деле тоже должны быть включены.  Вместо этого мы будем использовать встроенную в <tt class="doctest"><span class="pre">re</span></tt> аббревиатуру, <tt class="doctest"><span class="pre">\s</span></tt>, что означает любой символ пробела.  Данное предложение можно переписать в виде <tt class="doctest"><span class="pre">re.split(г<span class="pysrc-string">'\s+'</span>, raw)</span></tt>.</p>
<div class="note">
<p class="first admonition-title">Замечание</p>
<p class="last"><strong>Важно:</strong> 
Не забывайте ставить перед регулярными выражениями префикс <tt class="doctest"><span class="pre">r</span></tt> (что означает "необработанный"), который приказывает интерпретатору Python обрабатывать строку в буквальном смысле, а не обрабатывать все символы обратной косой черты, которые он содержит.</p>
</div>
<p>Разделение по пробелам дает нам такие токены, как <tt class="doctest"><span class="pre"><span class="pysrc-string">'(not'</span></span></tt> и <tt class="doctest"><span class="pre"><span class="pysrc-string">'herself,'</span></span></tt>.
В качестве альтернативы можно использовать тот факт, что Python дает нам класс символов <tt class="doctest"><span class="pre">\w</span></tt> для символов слов, что эквивалентно <tt class="doctest"><span class="pre">[a-zA-Z0-9_]</span></tt>.
Он также определяет дополнение этого класса <tt class="doctest"><span class="pre">\W</span></tt>, то есть все символы, кроме букв, цифр и символа подчеркивания.  Мы можем использовать <tt class="doctest"><span class="pre">\W</span></tt> в простом регулярном выражении, чтобы разделить входной сигнал по чему-либо <em>отличному</em> от символов слов:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; re.split(r'\W+', raw)
['', 'When', 'I', 'M', 'a', 'Duchess', 'she', 'said', 'to', 'herself', 'not', 'in',
'a', 'very', 'hopeful', 'tone', 'though', 'I', 'won', 't', 'have', 'any', 'pepper',
'in', 'my', 'kitchen', 'AT', 'ALL', 'Soup', 'does', 'very', 'well', 'without',
'Maybe', 'it', 's', 'always', 'pepper', 'that', 'makes', 'people', 'hot', 'tempered',
'']</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Заметим, что это дает нам пустые строки в начале и в конце (чтобы понять, почему, попробуйте выполнить <tt class="doctest"><span class="pre"><span class="pysrc-string">'хх'</span>.split(<span class="pysrc-string">'х'</span>))</span></tt>.  Мы получаем те же лексемы, но без пустых строк с помощью <tt class="doctest"><span class="pre">re.findall(r<span class="pysrc-string">'\w+',</span> raw)</span></tt>, используя шаблон, который соответствует словам, а не пропускам.
Теперь, когда мы ищем соответствующие слова, мы в состоянии расширить это регулярное выражение, чтобы охватить более широкий круг случаев.
Регулярное выражение <tt class="doctest"><span class="pre">«\w+|\S\w*»</span></tt> сначала будет пытаться найти любую последовательность символов слов.  Если совпадение не будет найдено, он будет пытаться найти любой символ, <em>не являющийся</em> пробелом (<tt class="doctest"><span class="pre">\S</span></tt> является дополнением <tt class="doctest"><span class="pre">\s</span></tt>), за которым следует символ слова.  Это означает, что знаки препинания группируется с любыми следующими за ними буквами (например, <span class="example">'s</span>), а последовательности из двух и более символов пунктуации разделяются.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; re.findall(r'\w+|\S\w*', raw)
["'When", 'I', "'M", 'a', 'Duchess', ',', "'", 'she', 'said', 'to', 'herself', ',',
'(not', 'in', 'a', 'very', 'hopeful', 'tone', 'though', ')', ',', "'I", 'won', "'t",
'have', 'any', 'pepper', 'in', 'my', 'kitchen', 'AT', 'ALL', '.', 'Soup', 'does',
'very', 'well', 'without', '-', '-Maybe', 'it', "'s", 'always', 'pepper', 'that',
'makes', 'people', 'hot', '-tempered', ',', "'", '.', '.', '.']</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Давайте обобщим <tt class="doctest"><span class="pre">\w+</span></tt> в приведенном выше выражении, чтобы разрешить внутри слова дефис и апостроф: <tt class="doctest"><span class="pre">«\w+([-']\w+)*»</span></tt>.
Это выражение означает, что за <tt class="doctest"><span class="pre">\w+</span></tt> следует ноль и более экземпляров <tt class="doctest"><span class="pre">[-']\w+</span></tt>; этому будут соответствовать <span class="example">hot-tempered</span> и <span class="example">it's</span>.
(Мы должны включить <tt class="doctest"><span class="pre">?:</span></tt> в это выражение по причинам, рассмотренным ранее.)
Мы также добавим шаблон, соответствующий символам кавычки, чтобы отделить их от текста, который они обрамляют.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; print(re.findall(r"\w+(?:[-']\w+)*|'|[-.(]+|\S\w*", raw))
["'", 'When', "I'M", 'a', 'Duchess', ',', "'", 'she', 'said', 'to', 'herself', ',',
'(', 'not', 'in', 'a', 'very', 'hopeful', 'tone', 'though', ')', ',', "'", 'I',
"won't", 'have', 'any', 'pepper', 'in', 'my', 'kitchen', 'AT', 'ALL', '.', 'Soup',
'does', 'very', 'well', 'without', '--', 'Maybe', "it's", 'always', 'pepper',
'that', 'makes', 'people', 'hot-tempered', ',', "'", '...']</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Выражение выше также включает в себя <tt class="doctest"><span class="pre">«[-.(]+»</span></tt>, что приводит к тому, что двойной дефис, многоточие и открывающая скобка токенизируются отдельно.</p>
<p>Таблица <a class="reference internal" href="http://www.nltk.org/book/ch03.html#tab-re-symbols">3.4</a> перечисляет применяемые в регулярных выражениях обозначения классов символов, которые мы видели в этом разделе, в дополнение к некоторым другим полезным обозначениям.</p>
<span class="target" id="tab-re-symbols"></span><table border="1" class="docutils" id="tab-re-symbols">
<colgroup>
<col width="14%">
<col width="86%">
</colgroup>
<thead valign="bottom">
<tr><th class="head">Обозначения</th>
<th class="head">Функция</th>
</tr>
</thead>
<tbody valign="top">
<tr><td><tt class="doctest"><span class="pre">\b</span></tt></td>
<td>Граница слова (нулевая ширина)</td>
</tr>
<tr><td><tt class="doctest"><span class="pre">\d</span></tt></td>
<td>Любая десятичная цифра (эквивалент <tt class="doctest"><span class="pre">[0-9]</span></tt>)</td>
</tr>
<tr><td><tt class="doctest"><span class="pre">\D</span></tt></td>
<td>Любой нецифровой символ (эквивалент <tt class="doctest"><span class="pre">[^0-9]</span></tt>)</td>
</tr>
<tr><td><tt class="doctest"><span class="pre">\s</span></tt></td>
<td>Любой символ пробела (эквивалент <tt class="doctest"><span class="pre">[ \t\n\r\f\v]</span></tt>)</td>
</tr>
<tr><td><tt class="doctest"><span class="pre">\S</span></tt></td>
<td>Любой символ-непробел (эквивалент <tt class="doctest"><span class="pre">[^ \t \n\r \f\v]</span></tt>)</td>
</tr>
<tr><td><tt class="doctest"><span class="pre">\w</span></tt></td>
<td>Любой буквенно-цифровой символ (эквивалент <tt class="doctest"><span class="pre">[a-zA-Z0-9_]</span></tt>)</td>
</tr>
<tr><td><tt class="doctest"><span class="pre">\W</span></tt></td>
<td>Любой небуквенно-цифровой символ (эквивалент <tt class="doctest"><span class="pre">[^a-zA-Z0-9_]</span></tt>)</td>
</tr>
<tr><td><tt class="doctest"><span class="pre">\t</span></tt></td>
<td>Символ табуляции</td>
</tr>
<tr><td><tt class="doctest"><span class="pre">\n</span></tt></td>
<td>Символ новой строки</td>
</tr>
</tbody>
<td><p class="caption"><span class="caption-label">Таблица 3.4:</span> <p>Обозначения, применяемые в регулярных выражениях</p>
</p>
</td></table>
</div>
<div class="section" id="nltk-s-regular-expression-tokenizer">
<h3>Основанный на регулярных выражениях токенизатор NLTK</h3>
<p>Функция <tt class="doctest"><span class="pre">nltk.regexp_tokenize()</span></tt> похожа на <tt class="doctest"><span class="pre">re.findall()</span></tt> (поскольку мы использовали еее для токенизации).  Тем не менее, <tt class="doctest"><span class="pre">nltk.regexp_tokenize()</span></tt> более эффективна для решения этой задачи и позволяет избежать специальной обработки скобок.
Для удобства чтения разобьем регулярное выражение на несколько строк и добавим комментарий к каждой строке.  Специальный <tt class="doctest"><span class="pre">(?х)</span></tt> "флаг отладки" говорит Python вырезать встроенные пробелы и комментарии.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; text = 'That U.S.A. poster-print costs $12.40...'
&gt;&gt;&gt; pattern = r'''(?x)    # set flag to allow verbose regexps
...     ([A-Z]\.)+        # abbreviations, e.g. U.S.A.
...   | \w+(-\w+)*        # words with optional internal hyphens
...   | \$?\d+(\.\d+)?%?  # currency and percentages, e.g. $12.40, 82%
...   | \.\.\.            # ellipsis
...   | [][.,;"'?():-_`]  # these are separate tokens; includes ], [
... '''
&gt;&gt;&gt; nltk.regexp_tokenize(text, pattern)
['That', 'U.S.A.', 'poster-print', 'costs', '$12.40', '...']</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>При использовании флага отладки, вы больше не можете использовать <tt class="doctest"><span class="pre"><span class="pysrc-string">' '</span></span></tt>, чтобы найти символ пробела; вместо этого используйте <tt class="doctest"><span class="pre">\s</span></tt>.
Функция <tt class="doctest"><span class="pre">regexp_tokenize()</span></tt> имеет дополнительный параметр <tt class="doctest"><span class="pre">gaps</span></tt>.
Когда его значение <tt class="doctest"><span class="pre">Истина</span></tt>, регулярное выражение определяет промежутки между токенами так же, как с помощью функции <tt class="doctest"><span class="pre">re.split()</span></tt>.</p>
<div class="note">
<p class="first admonition-title">Замечание</p>
<p class="last">Мы можем оценить токенизатор путем сравнения полученных токенов со словарем, с помощью отчета о токенах, которых нет в словаре, используя функцию <tt class="doctest"><span class="pre">set(tokens).difference(wordlist)</span></tt>.  Вы, вероятно, захотите сначала перевести все токены в нижний регистр.</p>
</div>
</div>
<div class="section" id="further-issues-with-tokenization">
<h3>Дальнейшие вопросы токенизации</h3>
<p>Токенизация оказывается гораздо более трудной задачей, чем вы могли бы ожидать.
Ни одно решение не работает одинаково хорошо во всех случаях, каждый раз мы должны определять, что считать токеном, в зависимости от области применения.</p>
<p>При разработке токенизатора полезно иметь доступ к необработанному тексту, который был вручную токенизирован, чтобы сравнить результат вашего токенизатора с высококачественными токенами (или "золотым стандартом").  Коллекция корпусов NLTK включает в себя образец данных Penn Treebank, в том числе необработанный текст Wall Street Journal <tt class="doctest"><span class="pre">(nltk.corpus.treebank_raw.raw())</span></tt> и его токенизированную версию <tt class="doctest"><span class="pre">(nltk.corpus.treebank.words())</span></tt>.</p>
<p>Последний вопрос токенизации - наличие сокращений, таких как <span class="example">didn't</span>.  Если мы анализируем значение предложения, вероятно, будет более полезно восстановить эту форму до двух отдельных форм: <span class="example">did</span> и <span class="example">n't</span> (или <span class="example">not</span>).
Мы можем сделать эту работу с помощью таблицы соответствия.</p>
</div>
</div>
<div class="section" id="segmentation">
<span id="sec-segmentation"></span><h2>3.8 Сегментация</h2>
<p>В этом разделе обсуждаются более сложные понятия, которые вы возможно предпочтете пропустить, первый раз читая эту главу.</p>
<p>Токенизация является частным случаем более общей проблемы <a name="segmentation_index_term"></a><span class="termdef">сегментации</span>.
В этом разделе мы рассмотрим два других случая этой проблемы, которые используют методы, радикально отличающиеся от тех, которые мы видели до сих пор в этой главе.</p>
<div class="section" id="sentence-segmentation">
<h3>Выделение предложения</h3>
<p>Работа с текстами на уровне отдельных слов часто предполагает способность разделить текст на отдельные предложения.  Как мы уже видели, некоторые корпусы предоставляют доступ на уровне предложений.  В следующем примере мы вычисляем среднее количество слов в предложении в корпусе Брауна:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; len(nltk.corpus.brown.words()) / len(nltk.corpus.brown.sents())
20.250994070456922</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>В других случаях текст доступен только в виде потока символов.  Перед тем как разделить текст на токены, мы должны сегментировать его на предложения.  NLTK предоставляет для этого возможность, включая в себя выделитель предложений Punkt <a class="reference external" href="http://www.nltk.org/book/bibliography.html#kissstrunk2006" id="id1">(Kiss &amp; Strunk, 2006)</a>.
Вот пример его использования для сегментации текста романа.
(Обратите внимание, что если внутренние данные сегментатора были обновлены к тому моменту, когда Вы читаете это, вы увидите другой результат):</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; text = nltk.corpus.gutenberg.raw('chesterton-thursday.txt')
&gt;&gt;&gt; sents = nltk.sent_tokenize(text)
&gt;&gt;&gt; pprint.pprint(sents[79:89])
['"Nonsense!"',
 'said Gregory, who was very rational when anyone else\nattempted paradox.',
 '"Why do all the clerks and navvies in the\n'
 'railway trains look so sad and tired, so very sad and tired?',
 'I will\ntell you.',
 'It is because they know that the train is going right.',
 'It\n'
 'is because they know that whatever place they have taken a ticket\n'
 'for that place they will reach.',
 'It is because after they have\n'
 'passed Sloane Square they know that the next station must be\n'
 'Victoria, and nothing but Victoria.',
 'Oh, their wild rapture!',
 'oh,\n'
 'their eyes like stars and their souls again in Eden, if the next\n'
 'station were unaccountably Baker Street!"',
 '"It is you who are unpoetical," replied the poet Syme.']</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Обратите внимание на то, что этот пример действительно представляет собой одно предложение, передающее речь г-на Люсьена Грегори.
Тем не менее приведенная речь содержит несколько предложений, и они были разделены на отдельные строки.  Это разумное поведение для большинства приложений.</p>
<p>Сегментация на предложения - это трудная задача, потому что точка используется для обозначения аббревиатур, а некоторые точки одновременно показывают аббревиатуру и заканчивают предложение, как это часто бывает с акронимами, например <span class="example">U.S.A.</span></p>
<p>Чтобы увидеть другой подход к выделению предложений см. <a class="reference external" href="http://www.nltk.org/book/ch06.html#sec-further-examples-of-supervised-classification">2</a>.</p>
</div>
<div class="section" id="word-segmentation">
<h3>Выделение слов</h3>
<p>Для некоторых систем письменности, токенизация текста является более трудной задачей, потому что в ней нет никакого визуального представления границ слова.
Например, в китайском трехсимвольная строка: 爱国人 (ai4 "любить", guo2 "страна", ren2 "человек") может быть токенизирована, как 爱国 / 人, "человек, любящий страну" или как 爱/ 国人, "любить человека-страны".</p>
<p>Аналогичная проблема возникает при обработке разговорного языка, где слушающий должен сегментировать непрерывный поток речи на отдельные слова.
Особенно сложная разновидность этой проблемы возникает тогда, когда мы не знаем слова заранее.  Это проблема, с которой сталкивается изучающий язык, например, ребенок слушающий высказывания родителей.  Рассмотрим следующий искусственный пример, где границы слов были удалены:</p>
<span class="target" id="ex-kitty"></span><p><table border="0" cellpadding="0" cellspacing="0" class="example">
  <tr valign="top"><td width="30" align="right">']</td><td width="15"></td><td><p><table border="0" cellpadding="0" cellspacing="0" class="example">
  <tr valign="top"><td width="30" align="right">a.</td><td width="15"></td><td>doyouseethekitty</td></tr></table></p>
<p><table border="0" cellpadding="0" cellspacing="0" class="example">
  <tr valign="top"><td width="30" align="right">b.</td><td width="15"></td><td>seethedoggy</td></tr></table></p>
<p><table border="0" cellpadding="0" cellspacing="0" class="example">
  <tr valign="top"><td width="30" align="right">c.</td><td width="15"></td><td>doyoulikethekitty</td></tr></table></p>
<p><table border="0" cellpadding="0" cellspacing="0" class="example">
  <tr valign="top"><td width="30" align="right">d.</td><td width="15"></td><td>likethedoggy</td></tr></table></p>
</td></tr></table></p>
<p>Наша первая задача состоит в том, чтобы просто представить проблему: нам нужно найти способ, чтобы разделить содержимое текста в результате сегментации.  Мы можем сделать это с помощью аннотирования каждого символа логическим значением, указывающим, появляется ли прерывание слов после символа (идея, которая будет активно использоваться для "чанкинга" в <a class="reference external" href="http://www.nltk.org/book/ch07.html#chap-chunk">7.</a>).
Давайте предположим, что обучающемуся даются паузы между высказываниями, так как они часто соответствуют продолжительным паузам.  Вот возможное представление исходной и целевой сегментации:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; text = "doyouseethekittyseethedoggydoyoulikethekittylikethedoggy"
&gt;&gt;&gt; seg1 = "0000000000000001000000000010000000000000000100000000000"
&gt;&gt;&gt; seg2 = "0100100100100001001001000010100100010010000100010010000"</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Заметим, что строки сегментации состоят из нулей и единиц.  Они на один символ короче исходного текста, так как текст длиной <span class="math">n</span> может быть разделен только в <span class="math">n-1</span> местах.
Функция <tt class="doctest"><span class="pre">segment()</span></tt> в <a class="reference internal" href="http://www.nltk.org/book/ch03.html#code-segment">3.7</a> показывает, что мы можем получить первоначальный сегментированный текст из приведенного выше представления.</p>
<span class="target" id="code-segment"></span><div class="pylisting">
<table border="0" cellpadding="0" cellspacing="0" class="pylisting" width="95%">
<tr><td class="codeblock">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_codeblock_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
ef segment(text, segs):
    words = []
    last = 0
    for i in range(len(segs)):
        if segs[i] == '1':
            words.append(text[last:i+1])
            last = i+1
    words.append(text[last:])
    return words</pre>
</td>
</tr></table></td></tr>
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; text = "doyouseethekittyseethedoggydoyoulikethekittylikethedoggy"
&gt;&gt;&gt; seg1 = "0000000000000001000000000010000000000000000100000000000"
&gt;&gt;&gt; seg2 = "0100100100100001001001000010100100010010000100010010000"
&gt;&gt;&gt; segment(text, seg1)
['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']
&gt;&gt;&gt; segment(text, seg2)
['do', 'you', 'see', 'the', 'kitty', 'see', 'the', 'doggy', 'do', 'you',
'like', 'the', 'kitty', 'like', 'the', 'doggy']</pre>
</td>
</tr></table></td></tr>
<tr><td class="caption"><p class="caption"><a class="reference external" href="http://www.nltk.org/book/pylisting/code_segment.py" type="text/x-python"><span class="caption-label">Пример 3.7 (code_segment.py)</span></a>: <span class="caption-label">Рисунок 3.7:</span> Реконструкция сегментированного текста из строки-представления: <tt class="doctest"><span class="pre">seg1</span></tt> и <tt class="doctest"><span class="pre">seg2</span></tt> представляют начальные и конечные сегментации некоторого гипотетического направленной ребенку речи; функция <tt class="doctest"><span class="pre">segment()</span></tt> может использовать их, чтобы воспроизвести сегментированный текст.</p></td></tr>
</table></div>
<p>Теперь задача сегментации становится задачей поиска: найти битовую строку, которая позволяет правильно разделить текстовую строку на слова.
Мы предполагаем, что обучаемый приобретает слова и хранит их во внутреннем лексиконе.
Имея подходящий словарный запас, можно восстановить исходный текст как последовательность лексических единиц.  Следуя за <a class="reference external" href="http://www.nltk.org/book/bibliography.html#brent1995" id="id2">(Brent, 1995)</a>, мы можем определить <a name="objective_function_index_term"></a><span class="termdef">целевую функцию</span>, функцию подсчета очков, значение которой мы будем пытаться оптимизировать, исходя из размера лексикона (количества символов в словах плюс дополнительный разделительный символ, чтобы обозначить конец каждого слова) и объема информации необходимого для реконструкции исходного текста из этого лексикона.  Проиллюстрируем это в <a class="reference internal" href="http://www.nltk.org/book/ch03.html#fig-brent">3.8</a> .</p>
<span class="target" id="fig-brent"></span><div class="figure" id="fig-brent">
<img alt="../images/brent.png" src="http://www.nltk.org/images/brent.png" style="width:711.3px;height:267.59999999999997px">
<p class="caption"><span class="caption-label">Рисунок 3.8:</span> Расчет целевой функции: Имея гипотетическую сегментацию исходного текста (слева), вывести лексикон и таблицу деривации, которые позволяют реконструировать исходный текст, затем подсчитать количество символов, используемых каждым лексическим элементом (в том числе символом границы слова) и количество лексических единиц, используемых каждой деривацией, в качестве балла качества сегментации; меньшие количества баллов указывают на лучшую сегментацию.</p>
</div>
<p>Несложно реализовать эту целевую функцию так, как показано в листинге <a class="reference internal" href="http://www.nltk.org/book/ch03.html#code-evaluate">3.9</a>.</p>
<span class="target" id="code-evaluate"></span><div class="pylisting">
<table border="0" cellpadding="0" cellspacing="0" class="pylisting" width="95%">
<tr><td class="codeblock">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_codeblock_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
def evaluate(text, segs):
    words = segment(text, segs)
    text_size = len(words)
    lexicon_size = sum(len(word) + 1 for word in set(words))
    return text_size + lexicon_size</pre>
</td>
</tr></table></td></tr>
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; text = "doyouseethekittyseethedoggydoyoulikethekittylikethedoggy"
&gt;&gt;&gt; seg1 = "0000000000000001000000000010000000000000000100000000000"
&gt;&gt;&gt; seg2 = "0100100100100001001001000010100100010010000100010010000"
&gt;&gt;&gt; seg3 = "0000100100000011001000000110000100010000001100010000001"
&gt;&gt;&gt; segment(text, seg3)
['doyou', 'see', 'thekitt', 'y', 'see', 'thedogg', 'y', 'doyou', 'like',
 'thekitt', 'y', 'like', 'thedogg', 'y']
&gt;&gt;&gt; evaluate(text, seg3)
47
&gt;&gt;&gt; evaluate(text, seg2)
48
&gt;&gt;&gt; evaluate(text, seg1)
64</pre>
</td>
</tr></table></td></tr>
<tr><td class="caption"><p class="caption"><a class="reference external" href="http://www.nltk.org/book/pylisting/code_evaluate.py" type="text/x-python"><span class="caption-label">Пример 3.9 (code_evaluate.py)</span></a> : <span class="caption-label">Рисунок 3.9:</span> Вычисление затрат хранения лексикона и восстанавления исходного текста</p></td></tr>
</table></div>
<p>Последний шаг заключается в поиске последовательности нулей и единиц, которая сводит к минимуму эту целевую функцию, как показано в листинге <a class="reference internal" href="http://www.nltk.org/book/ch03.html#code-anneal">3.10</a>.  Обратите внимание на то, что лучшая сегментация включает в себя такие "слова", как <span class="example">thekitty</span>, так как в данных не хватает доказательств для дальнейшего разделения.</p>
<span class="target" id="code-anneal"></span><div class="pylisting">
<table border="0" cellpadding="0" cellspacing="0" class="pylisting" width="95%">
<tr><td class="codeblock">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_codeblock_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
 	
from random import randint

def flip(segs, pos):
    return segs[:pos] + str(1-int(segs[pos])) + segs[pos+1:]

def flip_n(segs, n):
    for i in range(n):
        segs = flip(segs, randint(0, len(segs)-1))
    return segs

def anneal(text, segs, iterations, cooling_rate):
    temperature = float(len(segs))
    while temperature &gt; 0.5:
        best_segs, best = segs, evaluate(text, segs)
        for i in range(iterations):
            guess = flip_n(segs, round(temperature))
            score = evaluate(text, guess)
            if score &lt; best:
                best, best_segs = score, guess
        score, segs = best, best_segs
        temperature = temperature / cooling_rate
        print(evaluate(text, segs), segment(text, segs))
    print()
    return segs</pre>
</td>
</tr></table></td></tr>
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; text = "doyouseethekittyseethedoggydoyoulikethekittylikethedoggy"
&gt;&gt;&gt; seg1 = "0000000000000001000000000010000000000000000100000000000"
&gt;&gt;&gt; anneal(text, seg1, 5000, 1.2)
61 ['doyouseetheki', 'tty', 'see', 'thedoggy', 'doyouliketh', 'ekittylike', 'thedoggy']
59 ['doy', 'ouseetheki', 'ttysee', 'thedoggy', 'doy', 'o', 'ulikethekittylike', 'thedoggy']
57 ['doyou', 'seetheki', 'ttysee', 'thedoggy', 'doyou', 'liketh', 'ekittylike', 'thedoggy']
55 ['doyou', 'seethekit', 'tysee', 'thedoggy', 'doyou', 'likethekittylike', 'thedoggy']
54 ['doyou', 'seethekit', 'tysee', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']
52 ['doyou', 'seethekittysee', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']
43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']
'0000100100000001001000000010000100010000000100010000000'</pre>
</td>
</tr></table></td></tr>
<tr><td class="caption"><p class="caption"><a class="reference external" href="http://www.nltk.org/book/pylisting/code_anneal.py" type="text/x-python"><span class="caption-label">Пример 3.10 (code_anneal.py)</span></a> : <span class="caption-label">Рисунок 3.10</span>: Недетерминистский поиск с использованием имитации эволюционирующего беспорядка (аннилинга): начинает поиск с сегментации на фразы; случайным образом возмущает нули и единицы пропорциональные "температуре"; при каждой итерации температура понижается и колебание границ уменьшается. Поскольку этот алгоритм поиска не является детерминистским, вы можете увидеть несколько иной результат.</p></td></tr>
</table></div>
<p>При наличии достаточного количества данных, можно автоматически сегментировать текст на слова с достаточной степенью точности.  Такие методы могут быть применены к токенизации письменных систем, которые не имеют никакого визуального представления границ слова.</p>
</div>
</div>
<div class="section" id="formatting-from-lists-to-strings">
<span id="sec-formatting"></span><h2>3.9 Форматирование: от списков к строкам</h2>
<p>Часто мы пишем программу, чтобы сообщить об одном элементе данных, как, например, некотором элементе корпуса, который соответствует определенному сложному критерию, или одной итоговой величине, такой как подсчет слов или результативность программы разметки.  Чаще всего мы пишем программу для получения структурированного результата, например, таблицы чисел или языковых форм или переформатирования исходных данных.  Когда результаты, которые должны быть представлены, лингвистические, текстовый вывод обычно наиболее естественный выбор.  Тем не менее, когда результаты численные, графический вывод может быть предпочтительным.  В этом разделе вы узнаете о различных способов представления результатов программ.</p>
<div class="section" id="from-lists-to-strings">
<h3>От списков к строкам</h3>
<p>Простейший структурированный объект, который мы используем для обработки текста, - это список слов.
Когда мы хотим вывести их на дисплей или в файл, мы должны преобразовать эти списки в строки.  Для этого в Python мы используем метод <tt class="doctest"><span class="pre">join()</span></tt>, а также указать строку, которая будет использоваться в качестве "клея" (связующего элемента).</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; silly = ['We', 'called', 'him', 'Tortoise', 'because', 'he', 'taught', 'us', '.']
&gt;&gt;&gt; ' '.join(silly)
'We called him Tortoise because he taught us .'
&gt;&gt;&gt; ';'.join(silly)
'We;called;him;Tortoise;because;he;taught;us;.'
&gt;&gt;&gt; ''.join(silly)
'WecalledhimTortoisebecausehetaughtus.'</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Итак <tt class="doctest"><span class="pre"><span class="pysrc-string">' '</span>.join(silly)</span></tt> означает: взять все элементы в <tt class="doctest"><span class="pre">silly</span></tt> и сцепить их как одну большую строку, используя <tt class="doctest"><span class="pre"><span class="pysrc-string">' '</span></span></tt> в качестве разделителя между элементами.  Т.е. <tt class="doctest"><span class="pre">join()</span></tt> является методом строки, которую вы хотите использовать в качестве соединителя.  (Многие люди находят эту нотацию <tt class="doctest"><span class="pre">join()</span></tt> нелогичной).
Метод <tt class="doctest"><span class="pre">join()</span></tt> работает только со списком строк - то, что мы называли текстом - сложный тип, который пользуется некоторыми привилегиями в Python.</p>
</div>
<div class="section" id="strings-and-formats">
<h3>Строки и форматы</h3>
<p>Мы видели, что есть два способа отображения содержимого объекта:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; word = 'cat'
&gt;&gt;&gt; sentence = """hello
... world"""
&gt;&gt;&gt; print(word)
cat
&gt;&gt;&gt; print(sentence)
hello
world
&gt;&gt;&gt; word
'cat'
&gt;&gt;&gt; sentence
'hello\nworld'</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Команда <tt class="doctest"><span class="pre"><span class="pysrc-keyword">print</span></span></tt> дает представляет собой попытку Python произвести наиболее читаемую форму объекта.
Второй метод - именования переменной в приглашении интерпретатора - показывает нам строку, которая может быть использована для воссоздания этого объекта.  Важно иметь в виду, что оба из них просто строки, отображаемые на благо вам, пользователям.  Они не дают нам никакого понятия относительно фактического внутреннего представления объекта.</p>
<p>Есть много других полезных способов отображения объекта в виде строки символов.  Это может быть в интересах читателя-человека или потому, что мы хотим <a name="export_index_term"></a><span class="termdef">экспортировать</span> наши данные в определенный формат файла для использования во внешней программе.</p>
<p>Форматированный вывод обычно содержит комбинацию переменных и предварительно заданных строк, например для распределения частот <tt class="doctest"><span class="pre">fdist</span></tt> мы могли бы сделать так:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; fdist = nltk.FreqDist(['dog', 'cat', 'dog', 'cat', 'dog', 'snake', 'dog', 'cat'])
&gt;&gt;&gt; for word in sorted(fdist):
...     print(word, '-&gt;', fdist[word], end='; ')
cat -&gt; 3; dog -&gt; 4; snake -&gt; 1;</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Операторы печати, которые содержат чередующиеся переменные и константы может быть трудно читать и поддерживать.  Другим решением является использование <a name="string_formatting_index_term"></a><span class="termdef">форматирование строк</span>.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; for word in sorted(fdist):
...    print('{}-&gt;{};'.format(word, fdist[word]), end=' ')
cat-&gt;3; dog-&gt;4; snake-&gt;1;</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Чтобы понять, что здесь происходит, давайте проверим саму строку формата.  (К настоящему времени это будет ваш обычный метод изучения нового синтаксиса.)</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; '{}-&gt;{};'.format ('cat', 3)
'cat-&gt;3;'</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Фигурные скобки <tt class="doctest"><span class="pre"><span class="pysrc-string">"{}"</span></span></tt> отмечают наличие <a name="replacement_field_index_term"></a><span class="termdef">поля замены</span>: оно действует как заменитель строки значений объектов, которые передаются методу <tt class="doctest"><span class="pre">str.format()</span></tt>. Мы можем вставлять <tt class="doctest"><span class="pre"><span class="pysrc-string">'{}'</span></span></tt> внутри строки, а затем заменить их строками, вызвав <tt class="doctest"><span class="pre">format()</span></tt> с соответствующими аргументами.  Строка, содержащая поля замены, называется <a name="format_string_index_term"></a><span class="termdef">строкой формата</span>.</p>
<p>Давайте дальше распакуем выше приведенный код, чтобы увидеть поближе это поведение:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; '{}-&gt;'.format('cat')
'cat-&gt;'
&gt;&gt;&gt; '{}'.format(3)
'3'
&gt;&gt;&gt; 'I want a {} right now'.format('coffee')
'I want a coffee right now'</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Мы можем иметь любое количество заменителей, но метод <tt class="doctest"><span class="pre">str.format</span></tt> должен вызываться с точно таким же количеством аргументов.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; '{} wants a {} {}'.format ('Lee', 'sandwich', 'for lunch')
'Lee wants a sandwich for lunch'
&gt;&gt;&gt; '{} wants a {} {}'.format ('sandwich', 'for lunch')
Traceback (most recent call last):
...
    '{} wants a {} {}'.format ('sandwich', 'for lunch')
IndexError: tuple index out of range</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Аргументы <tt class="doctest"><span class="pre">format()</span></tt> потребляются слева направо, и любые лишние аргументы просто игнорируются.</p>
<div class="system-message">
<p class="system-message-title">Системное сообщение: ОШИБКА/3 <tt class="docutils">(ch03.rst2</tt>, строка 2265)</p>
Неожиданный отступ.</div>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; '{} wants a {}'.format ('Lee', 'sandwich', 'for lunch')
'Lee wants a sandwich'</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Имя поля в строке формата может начинаться с цифры, которая относится к позиции аргумента функции <tt class="doctest"><span class="pre">format()</span></tt>. Что-то вроде <tt class="doctest"><span class="pre"><span class="pysrc-string">'from {} to {}'</span></span></tt> эквивалентно <tt class="doctest"><span class="pre"><span class="pysrc-string">'from {0} to {1}'</span></span></tt>, но мы можем использовать цифры, чтобы получить порядок отличный от порядка по умолчанию:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; 'from {1} to {0}'.format('A', 'B')
'from B to A'</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Мы также можем предоставить значения для заменителей косвенно. Вот пример использующий цикл <tt class="doctest"><span class="pre"><span class="pysrc-keyword">for</span></span></tt>:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; template = 'Lee wants a {} right now'
&gt;&gt;&gt; menu = ['sandwich', 'spam fritter', 'pancake']
&gt;&gt;&gt; for snack in menu:
...     print(template.format(snack))
...
<span class="pysrc-output">Lee wants a sandwich right now</span>
<span class="pysrc-output">Lee wants a spam fritter right now</span>
<span class="pysrc-output">Lee wants a pancake right now</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="lining-things-up">
<h3>Выстраивание вещей в ряд</h3>
<!-- In case we don&#39;t know in advance how wide a displayed value should be,
the width value can be replaced with a star in the formatting string,
then specified using a variable width-variable_.
width = 6
&#39;%-*s&#39; % (width, &#39;dog&#39;) # [_width-variable]
 &#39;dog   &#39; -->
<p>До сих пор наши строки формата генерировали вывод произвольной ширины на странице (или на экране).  Мы можем добавить отступы, чтобы получить вывод заданной ширины, вставив внутри фигурных скобок двоеточие <tt class="doctest"><span class="pre"><span class="pysrc-string">":"</span></span></tt> с последующим целым числом. Так что <tt class="doctest"><span class="pre">{:6}</span></tt> указывает на то, что мы хотим строку, которая ограничена по ширине 6 символами.  По умолчанию для чисел выравнивание осуществляется по правому краю <a class="reference internal" href="http://www.nltk.org/book/ch03.html#right-justified"><span id="ref-right-justified"><img class="callout" alt="[1]" src="http://www.nltk.org/book/callouts/callout1.gif"></span></a>, но мы можем поставить перед указателем ширины опцию выравнивания <tt class="doctest"><span class="pre"><span class="pysrc-string">'&lt;'</span></span></tt>, чтобы числа выравнивались по левому краю <a class="reference internal" href="http://www.nltk.org/book/ch03.html#left-justified"><span id="ref-left-justified"><img class="callout" alt="[2]" src="http://www.nltk.org/book/callouts/callout2.gif"></span></a>.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; '{:6}'.format(41) 
'    41'
&gt;&gt;&gt; '{:&lt;6}' .format(41) 
'41    '</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>По умолчанию строки выравниваются по левому краю, но с опцией выравнивания <tt class="doctest"><span class="pre"><span class="pysrc-string">'&gt;'</span></span></tt> они могут выравниваться по правому краю.</p>
<div class="system-message">
<p class="system-message-title">Системное сообщение: ОШИБКА / 3 <tt class="docutils">(ch03.rst2,</tt> строка 2313)</p>
Неожиданный отступ.</div>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; '{:6}'.format('dog') 
'dog   '
&gt;&gt;&gt; '{:&gt;6}'.format('dog') 
 '   dog'</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Другие управляющие символы могут быть использованы для указания знака и точности чисел с плавающей точкой; например <tt class="doctest"><span class="pre">{:.4f}</span></tt> указывает на то, что четыре цифры должны быть отображены после точки для числа с плавающей точкой.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; import math
&gt;&gt;&gt; '{:.4f}'.format(math.pi)
'3.1416'</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Форматирование строки достаточно сообразительно, чтобы знать, что если вы включите <tt class="doctest"><span class="pre"><span class="pysrc-string">'%'</span></span></tt> в свою спецификацию формата, то вы хотите представить значение в процентах; нет никакой необходимости умножать на 100.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; count, total = 3205, 9375
&gt;&gt;&gt; "accuracy for {} words: {:.4%}".format(total, count / total)
'accuracy for 9375 words: 34.1867%'</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Важным применением форматирования строк является представление данных в табличной форме.
Напомним, что в <a class="reference external" href="http://www.nltk.org/book/ch02.html#sec-extracting-text-from-corpora">1</a> мы видели, что данные представлялись в табличной форме с помощью условного распределения частот.
Давайте выполним табулирование данных сами, осуществляя полный контроль над заголовками и шириной столбцов, как показано в листинге <a class="reference internal" href="http://www.nltk.org/book/ch03.html#code-modal-tabulate">3.11</a>.
Обратите внимание на четкое разделение между работой по обработке языка и представлением результатов в табличной форме.</p>
<span class="target" id="code-modal-tabulate"></span><div class="pylisting">
<table border="0" cellpadding="0" cellspacing="0" class="pylisting" width="95%">
<tr><td class="codeblock">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_codeblock_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
 	
def tabulate(cfdist, words, categories):
    print('{:16}'.format('Category'), end=' ')                    # column headings
    for word in words:
        print('{:&gt;6}'.format(word), end=' ')
    print()
    for category in categories:
        print('{:16}'.format(category), end=' ')                  # row heading
        for word in words:                                        # for each word
            print('{:6}'.format(cfdist[category][word]), end=' ') # print table cell
        print()                                                   # end the row

&gt;&gt;&gt; from nltk.corpus import brown
&gt;&gt;&gt; cfd = nltk.ConditionalFreqDist(
...           (genre, word)
...           for genre in brown.categories()
...           for word in brown.words(categories=genre))
&gt;&gt;&gt; genres = ['news', 'religion', 'hobbies', 'science_fiction', 'romance', 'humor']
&gt;&gt;&gt; modals = ['can', 'could', 'may', 'might', 'must', 'will']
&gt;&gt;&gt; tabulate(cfd, modals, genres)
Category            can  could    may  might   must   will
news                 93     86     66     38     50    389
religion             82     59     78     12     54     71
hobbies             268     58    131     22     83    264
science_fiction      16     49      4     12      8     16
romance              74    193     11     51     45     43
humor                16     30      8      8      9     13</pre>
</td>
</tr></table></td></tr>
<tr><td class="caption"><p class="caption"><a class="reference external" href="http://www.nltk.org/book/pylisting/code_modal_tabulate.py" type="text/x-python"><span class="caption-label">Пример 3.11 (code_modal_tabulate.py)</span></a>: <span class="caption-label">Рисунок 3.11:</span> Частота модальных глаголов в различных разделах корпуса Брауна</p></td></tr>
</table></div>
<p>Вспомните из листинга в <a class="reference internal" href="http://www.nltk.org/book/ch03.html#code-stemmer-indexing">3.6</a>, что мы использовали формат строки <tt class="doctest"><span class="pre"><span class="pysrc-string">'{:{width}}'</span></span></tt> и связали значение с параметром <tt class="doctest"><span class="pre">width</span></tt> в <tt class="doctest"><span class="pre">format()</span></tt>.  Это позволяет задать ширину поля, используя переменную.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; '{:{width}}' % ("Monty Python", width=15)
'Monty Python   '</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Мы могли бы использовать эту функцию, чтобы автоматически настроить колонку так, чтобы она могла вместить все слова, используя <tt class="doctest"><span class="pre">width = max(len(w) <span class="pysrc-keyword">for</span> w <span class="pysrc-keyword">in</span> words)</span></tt>.</p>
</div>
<div class="section" id="writing-results-to-a-file">
<h3>Запись результатов в файл</h3>
<p>Мы видели, как читать текст из файлов (<a class="reference internal" href="http://www.nltk.org/book/ch03.html#sec-accessing-text">3.1</a>).
Часто бывает полезно записывать выходные данные также в файлы.  Следующий код открывает файл <tt class="doctest"><span class="pre">output.txt</span></tt> для записи и сохраняет выходные данные программы в файл.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; output_file = open('output.txt', 'w')
&gt;&gt;&gt; words = set(nltk.corpus.genesis.words('english-kjv.txt'))
&gt;&gt;&gt; for word in sorted(words):
...     print(word, file=output_file)</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Когда мы записываем нетекстовые данные в файл, мы должны сначала преобразовать их в строку.
Мы можем сделать это преобразование с помощью форматирования строк, как мы видели выше.
Запишем общее количество слов в наш файл:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; len(words)
2789
&gt;&gt;&gt; str(len(words))
'2789'
&gt;&gt;&gt; print(str(len(words)), file=output_file)</pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="caution">
<p class="first admonition-title">Внимание!</p>
<p class="last">Вы должны избегать имен файлов, содержащих пробелы, как, например, <tt class="doctest"><span class="pre">output file.txt</span></tt>, или которые идентичны, за исключением различия регистра, например <tt class="doctest"><span class="pre">Output.txt</span></tt> и <tt class="doctest"><span class="pre">output.TXT</span></tt>.</p>
</div>
</div>
<div class="section" id="text-wrapping">
<h3>Перенос текста по словам</h3>
<p>Когда результат нашей программы текстового типа, а не табличного, как правило, необходим перенос по словам, чтобы он отображался удобно.  Рассмотрим следующий результат, который выходит за границы строки и использует сложное предложение <tt class="doctest"><span class="pre"><span class="pysrc-keyword">print</span></span></tt>:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; saying = ['After', 'all', 'is', 'said', 'and', 'done', ',',
...           'more', 'is', 'said', 'than', 'done', '.']
&gt;&gt;&gt; for word in saying:
...     print(word, '(' + str(len(word)) + '),', end=' ')
After (5), all (3), is (2), said (4), and (3), done (4), , (1), more (4), is (2), said (4), than (4), done (4), . (1),</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Мы можем позаботиться о переносе текста по словам с помощью модуля Python <tt class="doctest"><span class="pre">textwrap</span></tt>.
Для максимальной ясности мы выделим каждый шаг в отдельную строку:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; from textwrap import fill
&gt;&gt;&gt; format = '%s (%d),'
&gt;&gt;&gt; pieces = [format % (word, len(word)) for word in saying]
&gt;&gt;&gt; output = ' '.join(pieces)
&gt;&gt;&gt; wrapped = fill(output)
&gt;&gt;&gt; print(wrapped)
After (5), all (3), is (2), said (4), and (3), done (4), , (1), more
(4), is (2), said (4), than (4), done (4), . (1),</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Обратите внимание на то, что между <tt class="doctest"><span class="pre">more</span></tt> и следующим за ним числом идет разрыв строки.
Если мы хотим избежать этого, мы могли бы переопределить форматирование строки так, чтобы оно не содержало пробелов, например, <tt class="doctest"><span class="pre"><span class="pysrc-string">'%s_(%d)'</span></span></tt>, тогда вместо того, чтобы печатать значение <tt class="doctest"><span class="pre">wrapped</span></tt>, мы могли бы напечатать <tt class="doctest"><span class="pre">wrapped.replace<span class="pysrc-string">('_'</span>, <span class="pysrc-string">' '</span>)</span></tt>.</p>
</div>
</div>
<div class="section" id="summary">
<h2>3.10 Резюме</h2>
<ul class="simple">
<li>В этой книге мы рассматриваем текст как список слов.  "Сырой текст" (необработанный текст) потенциально представляет собой длинную строку, содержащую форматирование слов и пробелов, он представляет собой то, как мы обычно храним и визуализируем текст.</li>
<li>Строка задается в Python с использованием одинарных или двойных кавычек: <tt class="doctest"><span class="pre"><span class="pysrc-string">'Monty Python'</span></span></tt>, <tt class="doctest"><span class="pre"><span class="pysrc-string">"Monty Python"</span></span></tt>.</li>
<li>Доступ к символам строки осуществляется с помощью индексов, считая от нуля: <tt class="doctest"><span class="pre"><span class="pysrc-string">'Monty Python'</span>[0]</span></tt> дает значение <tt class="doctest"><span class="pre">М</span></tt>.  Длина строка находится с помощью <tt class="doctest"><span class="pre">len()</span></tt>.</li>
<li>Подстроки доступны с помощью нотации среза: <tt class="doctest"><span class="pre"><span class="pysrc-string">'Monty Python'</span>[1: 5]</span></tt> дает значение <tt class="doctest"><span class="pre">onty</span></tt>.  Если начальный индекс опущен, то подстрока начинается с начала строки; если конечный индекс опущен, то срез продолжается до конца строки.</li>
<li>Строки могут быть разделены на списки: <tt class="doctest"><span class="pre"><span class="pysrc-string">'Monty Python'</span>.split()</span></tt> дает <tt class="doctest"><span class="pre">[<span class="pysrc-string">'Monty'</span>, <span class="pysrc-string">'Python'</span>]</span></tt>.  Списки могут быть объединены в строки: <tt class="doctest"><span class="pre"><span class="pysrc-string">'/'</span>.join([<span class="pysrc-string">'Monthy'</span>, <span class="pysrc-string">'Python'</span>])</span></tt> дает <tt class="doctest"><span class="pre"><span class="pysrc-string">'Monty/Python'</span></span></tt>.</li>
<li>Мы можем прочитать текст из файла <tt class="doctest"><span class="pre">input.txt</span></tt>, используя <tt class="doctest"><span class="pre">text = open(<span class="pysrc-string">'input.txt'</span>).read()</span></tt>.
Мы можем прочитать текст из <tt class="doctest"><span class="pre">url</span></tt> с помощью <tt class="doctest"><span class="pre">text = request.urlopen(url).read().decode(<span class="pysrc-string">'utf8'</span>)</span></tt>.
Мы можем перебирать строки текстового файла, используя <tt class="doctest"><span class="pre"><span class="pysrc-keyword">for</span> line <span class="pysrc-keyword">in</span> open(f)</span></tt>.</li>
<li>Мы можем записать текст в файл, открыв файл для записи <tt class="doctest"><span class="pre">output_file = open( <span class="pysrc-string">'output.txt'</span>, <span class="pysrc-string">'w'</span>)</span></tt>, а затем добавить содержимое в файл <tt class="doctest"><span class="pre"><span class="pysrc-keyword">print</span>(<span class="pysrc-string">"Monty Python"</span>, file = output_file)</span></tt>.</li>
<li>Тексты, найденные в Интернете, могут содержать нежелательные материалы (например, заголовки, разметки), которые должны быть удалены, прежде чем сделать какую-либо лингвистическую обработку.</li>
<li>Токенизация - это сегментация текста на основные единицы - или токены - такие, как слова и знаки препинания.
Токенизация на основе пробелов недостаточна для многих приложений, поскольку она связывает знаки препинания со словами.
NLTK предоставляет готовый токенизатор <tt class="doctest"><span class="pre">nltk.word_tokenize()</span></tt>.</li>
<li>Лемматизация это процесс, который находит соответствие различных форм слова (как, например, <span class="example">appeared</span>, <span class="example">appears</span>) к канонической, или цитируемой, форме слова, также известной как лексема или лемма (например, <span class="lex">appear</span>).</li>
<li>Регулярные выражения являются мощным и гибким способом задания шаблонов. После того, как мы импортировали модуль <tt class="doctest"><span class="pre">re</span></tt>, мы можем использовать <tt class="doctest"><span class="pre">re.findall()</span></tt>, чтобы найти все подстроки в строке, соответствующие шаблону.</li>
<li>Если строка регулярного выражения включает в себя обратную косую черту, вы должны сказать Python не обрабатывать строку, использовав сырую строку с префиксом <tt class="doctest"><span class="pre">r</span></tt>: <tt class="doctest"><span class="pre">r<span class="pysrc-string">'regexp'</span></span></tt>.</li>
<li>Когда обратный слэш используется перед определенными символами, например, <tt class="doctest"><span class="pre">\n</span></tt>, это приобретает особое значение (символ новой строки); однако, когда обратный слэш используется перед символами подстановки и операторами регулярных выражений, например, <tt class="doctest"><span class="pre">\.</span></tt>, <tt class="doctest"><span class="pre">\|</span></tt>, <tt class="doctest"><span class="pre">\$</span></tt>, эти символы <span class="emphasis">теряют</span> свой особый смысл и для них ищется буквальное соответствие.</li>
<li>Выражение форматирования строки <tt class="doctest"><span class="pre">template % arg_tuple</span></tt> состоит из шаблона формата строки <tt class="doctest"><span class="pre">template</span></tt>, который содержит параметры преобразования, такие как <tt class="doctest"><span class="pre">% -6s</span></tt> и <tt class="doctest"><span class="pre">% 0.2d</span></tt>.</li>
</ul>
</div>
<div class="section" id="further-reading">
<h2>7 Дополнительные материалы</h2>
<p>Дополнительные материалы для этой главы размещены на странице <tt class="doctest"><span class="pre">http://nltk.org/</span></tt>, в том числе ссылки на свободно доступные ресурсы в сети.  Не забудьте ознакомиться со справочными материалами Python на странице <tt class="doctest"><span class="pre">http://docs.python.org/</span></tt>.  (К примеру, эта документация охватывает "универсальную поддержку новой строки", объясняя, как работать с различными соглашениями о новой строке, используемыми различными операционными системами.)</p>
<p>Для получения дополнительных примеров обработки слов с помощью NLTK см. HOWTO материалы по токенизации, стеммингу и корпусам на <tt class="doctest"><span class="pre">http://nltk.org/howto</span></tt>. Главы 2 и 3 <a class="reference external" href="http://www.nltk.org/book/bibliography.html#jurafskymartin2008" id="id3">(Jurafsky &amp; Martin, 2008)</a> содержат более продвинутый материал по регулярным выражениям и морфологии.  Для ознакомления с более широким обсуждением обработки текста с помощью Python см. <a class="reference external" href="http://www.nltk.org/book/bibliography.html#mertz2003tpp" id="id4">(Mertz, 2003)</a>.
Для получения информации о нормализации нестандартных слов см. <a class="reference external" href="http://www.nltk.org/book/bibliography.html#sproat2001nor" id="id5">(Sproat et al, 2001)</a></p>
<p>Существует множество руководств по регулярным выражениям, как практических, так и теоретических.  Вводный курс по использованию регулярных выражений в Python, см. <em>Regular Expression HOWTO</em> автора Kuchling на сайте <tt class="doctest"><span class="pre">http://www.amk.ca/python/howto/regex/</span></tt>. Для получения всестороннего и детального руководства по использованию регулярных выражений, охватывающего их синтаксис в большинстве основных языков программирования, включая Python, см. <a class="reference external" href="http://www.nltk.org/book/bibliography.html#friedl2002mre" id="id6">(Friedl, 2002)</a>.
Другие презентации включают раздел 2.1 <a class="reference external" href="http://www.nltk.org/book/bibliography.html#jurafskymartin2008" id="id7">(Jurafsky &amp; Martin, 2008)</a>, а также главу 3 <a class="reference external" href="http://www.nltk.org/book/bibliography.html#mertz2003tpp" id="id8">(Mertz, 2003)</a>.</p>
<p>Есть много интернет-ресурсов по Юникод.  Полезными обсуждениями возможностей языка Python для работы с Юникод являются:</p>
<ul class="simple">
<li>Ned Batchelder, <em>Pragmatic Unicode,</em> <tt class="doctest"><span class="pre">http://nedbatchelder.com/text/unipain.html</span></tt></li>
<li><em>Unicode HOWTO,</em> Документация Python, <tt class="doctest"><span class="pre">http://docs.python.org/3/howto/unicode.html</span></tt></li>
<li>David Beazley, Mastering Python 3 I/O, <tt class="doctest"><span class="pre">http://pyvideo.org/video/289/pycon-2010--mastering-python-3-i-o</span></tt></li>
<li>Joel Spolsky, <em>The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets</em>, <em>(No Excuses!)</em>, <tt class="doctest"><span class="pre">http://www.joelonsoftware.com/articles/Unicode.html</span></tt></li>
</ul>
<p>Проблема токенизации китайского текста является одним из основных направлений SIGHAN, ACL специальной группы по обработке китайского языка <tt class="doctest"><span class="pre">http://sighan.org/</span></tt>.  Наш метод сегментирования английского текста следует за <a class="reference external" href="http://www.nltk.org/book/bibliography.html#brent1995" id="id9">(Brent, 1995)</a>; эта работа падает в область освоения языка <a class="reference external" href="http://www.nltk.org/book/bibliography.html#niyogi2006" id="id10">(Niyogi, 2006)</a>.</p>
<p>Словосочетания являются частным случаем выражений, состоящих из нескольких слов.
<a name="multiword_expression_index_term"></a><span class="termdef">Выражение, состоящее из нескольких слов</span> - это небольшая фраза, смысл и другие свойства которой не могут быть предсказаны исходя из ее слов взятых по отдельности, например, <span class="example">часть речи</span> <a class="reference external" href="http://www.nltk.org/book/bibliography.html#baldwinkim2010" id="id11">(Baldwin &amp; Kim, 2010)</a>.</p>
<p>Имитации "обжига" является эвристичной для нахождения хорошего приближения к оптимальному значению функции в большой, дискретном пространстве поиска, понятие основано на аналогии с обжигом в металлургии.
Методика описана во многих текстах по искусственному интеллекту.</p>
<p>Подход к обнаружению гипонимов в тексте с использованием шаблонов поиска, таких как <span class="example">х и другие у-ки</span> описывается <a class="reference external" href="http://www.nltk.org/book/bibliography.html#hearst1992hyp" id="id12">(Херст, 1992)</a>.</p>
</div>
<div class="section" id="exercises">
<h2>3.12 Упражнения</h2>
<ol class="arabic">
<li><p class="first">☼ Определение <tt class="doctest"><span class="pre"><span class="pysrc-string">'бесцветные'</span></span></tt> в строку <tt class="doctest"><span class="pre">S =.</span></tt>  Написать заявление Python, который изменяет это "бесцветные", используя только срез и конкатенации операций.</p>
</li>
<li><p class="first">☼ Мы можем использовать срез обозначения для удаления морфологических окончаний слов.  Например, <tt class="doctest"><span class="pre"><span class="pysrc-string">'собак</span> [-1]</span></tt> удаляет последний символ <tt class="doctest"><span class="pre">собак,</span></tt> оставляя <tt class="doctest"><span class="pre">собаку.</span></tt>  Используйте ломтика обозначения для удаления суффиксов из этих слов (мы вставили дефис , чтобы указать границу аффикс, но пропустить это из ваших строк): <tt class="doctest"><span class="pre">блюдо-эс,</span></tt> <tt class="doctest"><span class="pre">бегите-нин,</span></tt> <tt class="doctest"><span class="pre">нация-Эк,</span></tt> <tt class="doctest"><span class="pre">ун-делать,</span></tt> <tt class="doctest"><span class="pre">предварительного нагрева</span></tt> ,</p>
</li>
<li><p class="first">☼ Мы видели , как мы можем генерировать <tt class="doctest"><span class="pre">IndexError</span></tt> путем индексации за пределы конца строки.  Можно ли построить индекс, который идет слишком далеко влево, до начала строки?</p>
</li>
<li><p class="first">☼ Мы можем определить "шаг" размер для среза. Следующие возвращается каждый второй символ в срезе: <tt class="doctest"><span class="pre">Monty [6: 11: 2].</span></tt>
Он также работает в обратном направлении: <tt class="doctest"><span class="pre">Monty [10: 5: -2]</span></tt> Попробуйте это для себя, то экспериментировать с различными значениями шага.</p>
</li>
<li><p class="first">☼ Что произойдет , если вы попросите переводчика оценить <tt class="doctest"><span class="pre">Monty [:: - 1]?</span></tt>
Объясните, почему это разумный результат.</p>
</li>
<li><p class="first">☼ Опишите класс строк совпавших с помощью следующих регулярных выражений.</p>
<ol class="loweralpha simple">
<li><tt class="doctest"><span class="pre">[A-Za-Z] +</span></tt></li>
<li><tt class="doctest"><span class="pre">[AZ] [AZ] *</span></tt></li>
<li><tt class="doctest"><span class="pre">р [аеиоу] {2} т</span></tt></li>
<li><tt class="doctest"><span class="pre">\ D + (\. \ D +)?</span></tt></li>
<li><tt class="doctest"><span class="pre">([^ Аеиоу] [аеиоу] [^ аеиоу]) *</span></tt></li>
<li><tt class="doctest"><span class="pre">\ Ш + | [^ \ ш \ s] +</span></tt></li>
</ol>
<p>Проверьте свои ответы с помощью <tt class="doctest"><span class="pre">nltk.re_show ().</span></tt></p>
</li>
<li><p class="first">☼ Пишите регулярные выражения, чтобы соответствовать следующие классы строк:</p>
<blockquote>
<ol class="loweralpha simple">
<li>Один Определитель (предположим , что, <span class="example">ап,</span> и являются единственными определители).</li>
<li>Арифметическое выражение с помощью целых чисел, сложение, умножение и, например, <tt class="doctest"><span class="pre">2 * 3 + 8.</span></tt></li>
</ol>
</blockquote>
</li>
<li><p class="first">☼ Написать функцию полезности, которая принимает URL в качестве аргумента, и возвращает содержимое URL, со всеми HTML-разметки удалены.  Используйте <tt class="doctest"><span class="pre"><span class="pysrc-keyword">из</span> запроса URLLIB <span class="pysrc-keyword">импорта</span></span></tt> , а затем <tt class="doctest"><span class="pre">request.urlopen ( <span class="pysrc-string">'http://nltk.org/')</span> .read (). Декодировать ( <span class="pysrc-string">'utf8')</span></span></tt> , чтобы получить доступ к содержимому в URL.</p>
</li>
<li><p class="first">☼ Сохранить текст в файл <tt class="doctest"><span class="pre">corpus.txt.</span></tt>  Определим функцию <tt class="doctest"><span class="pre">нагрузки (F)</span></tt> , который считывает из файла с именем в его единственного аргумента, и возвращает строку , содержащую текст файла.</p>
<ol class="loweralpha simple">
<li>Используйте <tt class="doctest"><span class="pre">nltk.regexp_tokenize ()</span></tt> для создания токенизатор , что размечает различные виды знаков препинания в тексте.  Используйте один многострочный регулярных выражений, с встроенных комментариев, используя флаг отладки <tt class="doctest"><span class="pre">(?х).</span></tt></li>
<li>Используйте <tt class="doctest"><span class="pre">nltk.regexp_tokenize ()</span></tt> , чтобы создать токенизатор , что размечает следующие виды выражения: денежные суммы; даты; имена людей и организаций.</li>
</ol>
</li>
<li><p class="first">☼ Перепишите следующий цикл в виде списка понимания:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt;</span> Послал = [ <span class="pysrc-string">'The',</span> <span class="pysrc-string">'собака',</span> <span class="pysrc-string">'дал',</span> <span class="pysrc-string">'Джон',</span> <span class="pysrc-string">'The',</span> <span class="pysrc-string">'газета']</span> <span class="pysrc-prompt">&gt;&gt;&gt;</span> результат = [] <span class="pysrc-prompt">&gt;&gt;&gt;</span> <span class="pysrc-keyword">за</span> слово <span class="pysrc-keyword">в</span> отправлено: <span class="pysrc-more">...</span> word_len = (слово, Len (слово)) <span class="pysrc-more">...</span> result.append (word_len) <span class="pysrc-prompt">&gt;&gt;&gt;</span> результат <span class="pysrc-output">[( 'The', 3), ( 'собака', 3), ( 'дал', 4), ( 'John' , 4), (</span> далее <span class="pysrc-output">« ', 3), (' газета ', 9)]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</li>
<li><p class="first">☼ Определите строку , содержащую <tt class="doctest"><span class="pre">сырец</span></tt> предложение по собственному выбору.
Теперь разбейте <tt class="doctest"><span class="pre">сырое</span></tt> на какой - то символ, кроме пространства, такие как <tt class="doctest"><span class="pre"><span class="pysrc-string">'S'.</span></span></tt></p>
</li>
<li><p class="first">☼ Написать цикл <tt class="doctest"><span class="pre"><span class="pysrc-keyword">для</span></span></tt> вывода на печать символов строки, по одному в каждой строке.</p>
</li>
<li><p class="first">☼ В чем разница между вызовом <tt class="doctest"><span class="pre">разделить</span></tt> на строку без аргументов или с <tt class="doctest"><span class="pre"><span class="pysrc-string">''</span></span></tt> в качестве аргумента, например , <tt class="doctest"><span class="pre">sent.split ()</span></tt> по сравнению с <tt class="doctest"><span class="pre">sent.split ( <span class="pysrc-string">'')?</span></span></tt>  Что происходит, когда строка является разделение содержит символы табуляции, последовательных символов пробела, или последовательность вкладок и пространств?  (В холостом режиме вам нужно будет использовать <tt class="doctest"><span class="pre"><span class="pysrc-string">'\ т'</span></span></tt> , чтобы ввести символ табуляции.)</p>
</li>
<li><p class="first">☼ создать переменную <tt class="doctest"><span class="pre">слова</span></tt> , содержащие список слов.
Эксперимент с <tt class="doctest"><span class="pre">words.sort ()</span></tt> и <tt class="doctest"><span class="pre">отсортированных (слова).</span></tt>
В чем разница?</p>
</li>
<li><p class="first">☼ Исследуйте разницу между строками и целыми числами, введя следующую команду в приглашении Python: <tt class="doctest"><span class="pre"><span class="pysrc-string">"3"</span> * 7</span></tt> и <tt class="doctest"><span class="pre">3 * 7.</span></tt>
Попробуйте преобразование между строками и целыми числами , используя <tt class="doctest"><span class="pre">Int ( <span class="pysrc-string">"3")</span></span></tt> и <tt class="doctest"><span class="pre">ул (3).</span></tt></p>
</li>
<li><p class="first">☼ Используйте текстовый редактор , чтобы создать файл с именем <tt class="doctest"><span class="pre">prog.py</span></tt> , содержащий единственную строку <tt class="doctest"><span class="pre">Monty = <span class="pysrc-string">'Монти Пайтон'.</span></span></tt>
Затем начать новый сеанс работы с интерпретатором Python, и введите выражение <tt class="doctest"><span class="pre">Monty</span></tt> в командной строке.
Вы получите сообщение об ошибке от переводчика. Теперь попробуйте следующее (обратите внимание , что вы должны убирание <tt class="doctest"><span class="pre">.py</span></tt> часть файла):</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt;</span> <span class="pysrc-keyword">Из</span> прог <span class="pysrc-keyword">импорта</span> Monty <span class="pysrc-prompt">&gt;&gt;&gt;</span> Monty</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>На этот раз, Python должен вернуться со значением. Вы также можете попробовать <tt class="doctest"><span class="pre"><span class="pysrc-keyword">импорта</span> прогу,</span></tt> в этом случае Python должен быть способен оценить выражение <tt class="doctest"><span class="pre">prog.monty</span></tt> в командной строке.</p>
</li>
<li><p class="first">☼ Что происходит , когда строки <tt class="doctest"><span class="pre">форматирования% 6с</span></tt> <tt class="doctest"><span class="pre">и% -6s</span></tt> используются для отображения строк, которые длиннее шести символов?</p>
</li>
<li><p class="first">◑ Читайте в какой - нибудь текст из корпуса, разметить его, и распечатать список всех <span class="example">Wh</span> -Word типов , которые происходят. <span class="example">(WH</span> -слов на английском языке используются в вопросах, относительных положений и восклицаниями: <span class="example">кто,</span> <span class="example">что,</span> <span class="example">что,</span> и так далее.) Распечатать их в порядке.  Существуют ли слова продублированы в этом списке, из-за наличия конкретных различий и знаков препинания?</p>
</li>
<li><p class="first">◑ Создайте файл , состоящий из слов и (составил) частот, где каждая строка состоит из слова, символ пробела, и положительное целое число, например , <tt class="doctest"><span class="pre">нечеткое 53.</span></tt>  Прочитайте файл в список Python с использованием <tt class="doctest"><span class="pre">открытых (имя файла) .readlines ().</span></tt>
Затем разбить каждую строку в свои два поля с помощью <tt class="doctest"><span class="pre">разделения (),</span></tt> и преобразовать число в целое число , используя <tt class="doctest"><span class="pre">Int ().</span></tt>  Результат должен быть список вида: <tt class="doctest"><span class="pre">[[ <span class="pysrc-string">'нечеткие',</span> 53], ...].</span></tt></p>
</li>
<li><p class="first">◑ Написать код для доступа к любимым веб-страницу и извлечь текст из него.
Например, доступ к сайту погоды и извлечь верхнюю температуру прогноз для вашего города или города сегодня.</p>
</li>
<li><p class="first">◑ Написать функцию <tt class="doctest"><span class="pre">неизвестно ()</span></tt> , который принимает URL в качестве аргумента, и возвращает список неизвестных слов , которые происходят на этой странице.
Для того , чтобы сделать это, извлечь все подстроки , состоящие из строчных букв ( с помощью <tt class="doctest"><span class="pre">re.findall ())</span></tt> и удалите все элементы из этого набора , которые происходят в словах корпус <tt class="doctest"><span class="pre">(nltk.corpus.words).</span></tt>  Попробуйте классифицировать эти слова вручную и обсудить ваши выводы.</p>
</li>
<li><p class="first">◑ Рассмотрение результатов обработки URL <tt class="doctest"><span class="pre">http://news.bbc.co.uk/~~HEAD=dobj</span></tt> с использованием регулярных выражений , предложенных выше. Вы увидите, что есть еще достаточное количество нетекстовых данных существует, в частности, Javascript команды. Вы также можете обнаружить, что приговор перерывы не были должным образом сохранены. Определить дополнительные регулярные выражения, которые улучшают извлечение текста из этой веб-страницы.</p>
</li>
<li><p class="first">◑ возможность написать регулярное выражение для разметить текст таким образом , что слово <span class="example">не</span> разбивается на лексемы в <span class="example">делать</span> и <span class="example">не</span> вы?
Объясните , почему это регулярное выражение не будет работать: <tt class="doctest"><span class="pre">«не | \ ш +».</span></tt></p>
</li>
<li><p class="first">◑ Попробуйте написать код для преобразования текста в <em>hAck3r,</em> используя регулярные выражения и подстановки, где <tt class="doctest"><span class="pre">е</span></tt> → <tt class="doctest"><span class="pre">3,</span></tt> <tt class="doctest"><span class="pre">я</span></tt> → <tt class="doctest"><span class="pre">1,</span></tt> <tt class="doctest"><span class="pre">O</span></tt> → <tt class="doctest"><span class="pre">0,</span></tt> <tt class="doctest"><span class="pre">l</span></tt> → <tt class="doctest"><span class="pre">|</span></tt> , <tt class="doctest"><span class="pre">S</span></tt> → <tt class="doctest"><span class="pre"><tt class="doctest"><span class="pre">5.</span></tt></span></tt> → <tt class="doctest"><span class="pre">5w33t!</span></tt> , <tt class="doctest"><span class="pre">Ели</span></tt> → <tt class="doctest"><span class="pre">8.</span></tt>
Нормализация текст в нижний регистр перед преобразованием его.
Добавьте несколько замен ваших собственных.  Теперь попытайтесь сопоставить <tt class="doctest"><span class="pre">с</span></tt> до двух различных значений: <tt class="doctest"><span class="pre">$</span></tt> для начале слова <tt class="doctest"><span class="pre">с</span></tt> и <tt class="doctest"><span class="pre">5</span></tt> для слов-внутренняя <tt class="doctest"><span class="pre">с.</span></tt></p>
</li>
<li><p class="first">◑ <em>латынь Свиньи</em> является простое преобразование английского текста.  Каждое слово текста преобразуется следующим образом : переместить любой согласной (или согласного кластера) , который появляется в начале слова до конца, а затем добавить <span class="example">ау,</span> например , <span class="example">строка</span> → <span class="example">ingstray,</span> <span class="example">холостой</span> → <span class="example">idleay.</span> <tt class="doctest"><span class="pre">http://en.wikipedia.org/wiki/Pig_Latin</span></tt></p>
<ol class="loweralpha simple">
<li>Написать функцию, чтобы преобразовать слово Свинья латыни.</li>
<li>Написать код, который преобразует текст, а не отдельных слов.</li>
<li>Продлить его дальше , чтобы сохранить капитализацию, чтобы сохранить <tt class="doctest"><span class="pre">Цюй</span></tt> вместе (т.е. так , что становится <tt class="doctest"><span class="pre">тихо</span></tt> <tt class="doctest"><span class="pre">ietquay),</span></tt> а также определить , когда <tt class="doctest"><span class="pre">у</span></tt> используется как согласного (например , <tt class="doctest"><span class="pre">желтый)</span></tt> против гласной (например , <tt class="doctest"><span class="pre">стиль).</span></tt></li>
</ol>
</li>
<li><p class="first">◑ Скачать текст с языка, который имеет гласный гармонию (например, венгерский), экстракт гласного последовательности слов, и создать таблицу гласный Биграммные.</p>
</li>
<li><p class="first"><tt class="doctest"><span class="pre">Случайным</span></tt> образом модуль ◑ Python включает в себя <tt class="doctest"><span class="pre">выбор</span></tt> функции <tt class="doctest"><span class="pre">()</span></tt> , который случайным образом выбирает элемент из последовательности, например , <tt class="doctest"><span class="pre">выбор ( <span class="pysrc-string">"aehh")</span></span></tt> будет производить один из четырех возможных символов, с буквой <tt class="doctest"><span class="pre">ч</span></tt> быть в два раза чаще, чем другие.  Написать выражение генератор , который производит последовательность из 500 случайно выбранных букв , взятых из строки <tt class="doctest"><span class="pre"><span class="pysrc-string">"aehh",</span></span></tt> и поместить это выражение внутри вызова функции <tt class="doctest"><span class="pre"><span class="pysrc-string">''</span> .join (),</span></tt> чтобы объединить их в одну длинную строку.  Вы должны получить результат , который выглядит как неконтролируемое чихание или маниакальный смех: <tt class="doctest"><span class="pre">он хаха эи heheeh Пьеха.</span></tt>
Используйте <tt class="doctest"><span class="pre">раскол ()</span></tt> и <tt class="doctest"><span class="pre">присоединиться</span></tt> к <tt class="doctest"><span class="pre">()</span></tt> еще раз , чтобы нормализовать пропуски в этой строке.</p>
</li>
<li><p class="first">◑ Рассмотрим числовые выражения в следующем предложении из МедЛайн Корпус: <span class="example">Соответствующие фракции свободного кортизола в этих сывороток были 4,53 +/- 0,15% и 8,16 +/- 0,23%, соответственно.</span>
Если мы говорим , что числовое выражение <span class="example">4,53 +/- 0,15%</span> три слова?  Или мы должны сказать, что это одно сложное слово?  Или мы должны сказать , что это на самом деле <em>девять</em> слов, так как он прочитал "четыре целых пять три, плюс или минус ноль целых пятнадцать процентов"?  Или мы должны сказать, что это не "реальное" слово вообще, так как он не будет появляться в любом словаре?
Обсудите эти различные возможности.  Вы можете думать о доменах приложений, которые мотивируют по крайней мере, два из этих ответов?</p>
</li>
<li><p class="first">меры ◑ удобочитаемости используются для чтения забить трудности текста, для целей отбора текстов соответствующей сложности для изучающих язык.  Определим μ <sub>ш</sub> быть среднее число букв в слове, и ц <sub>ы</sub> быть среднее число слов в предложении, в данном тексте.  Автоматизированная индекс удобочитаемости (ARI) текста определяется как: <tt class="doctest"><span class="pre">4,71</span></tt> μ <sub>W</sub> <tt class="doctest"><span class="pre">+ 0,5</span></tt> мкм <sub>с</sub> <tt class="doctest"><span class="pre">- 21,43.</span></tt>
Подсчитать счет ARI для различных участков Браун корпус, в том числе раздел <tt class="doctest"><span class="pre">F</span></tt> (краеведческом) и <tt class="doctest"><span class="pre">J</span></tt> (уроки).  Используйте тот факт , что <tt class="doctest"><span class="pre">nltk.corpus.brown.words ()</span></tt> создает последовательность слов, в то время как <tt class="doctest"><span class="pre">nltk.corpus.brown.sents ()</span></tt> создает последовательность предложений.</p>
</li>
<li><p class="first">◑ Используйте Porter Штеммер нормализовать некоторые текст разбивается на лексемы, вызывая Штеммер на каждом слове.  Сделайте то же самое с Lancaster Stemmer и посмотреть, если вы заметили какие-либо различия.</p>
</li>
<li><p class="first">◑ Определите переменную <tt class="doctest"><span class="pre">говоривший</span></tt> содержит список <tt class="doctest"><span class="pre">[ <span class="pysrc-string">'После',</span> <span class="pysrc-string">'все',</span> <span class="pysrc-string">'есть',</span> <span class="pysrc-string">'сказал',</span> <span class="pysrc-string">'и',</span> <span class="pysrc-string">'сделал',</span> <span class="pysrc-string">',',</span> <span class="pysrc-string">'больше',</span> <span class="pysrc-string">'есть',</span> <span class="pysrc-string">'' сказал,</span> <span class="pysrc-string">'</span></span></tt> , <tt class="doctest"><span class="pre"><span class="pysrc-string">чем',</span> <span class="pysrc-string">'сделано',</span> <span class="pysrc-string">'.'</span> ].</span></tt>  Процесс этот список , используя <tt class="doctest"><span class="pre"><span class="pysrc-keyword">для</span></span></tt> цикла, и сохранить длину каждого слова в новой <tt class="doctest"><span class="pre">длины</span></tt> списка.  Подсказка: начните путем присвоения пустой список <tt class="doctest"><span class="pre">длин,</span></tt> используя <tt class="doctest"><span class="pre">длину = [].</span></tt> Тогда каждый раз через петлю, используйте <tt class="doctest"><span class="pre">Append ()</span></tt> , чтобы добавить другое значение длины к списку. Теперь сделайте то же самое, используя список понимание.</p>
</li>
<li><p class="first">◑ Определить переменную <tt class="doctest"><span class="pre">глупо</span></tt> содержать строку: <tt class="doctest"><span class="pre"><span class="pysrc-string">'новообразованные мягкие идеи невыразимое в бешенство</span> <span class="pysrc-string">способом.</span></span></tt>  (Это происходит с законной интерпретации , что двуязычные английский-испанский язык можно присвоить известной нонсенс фразе Хомского, <span class="example">бесцветные зеленые идеи яростно спят</span> согласно Википедии).  Теперь написать код для выполнения следующих задач:</p>
<ol class="loweralpha simple">
<li>Сплит <tt class="doctest"><span class="pre">глупо</span></tt> в список строк, по одному на слово, используя операцию Питона <tt class="doctest"><span class="pre">сплит (),</span></tt> и сохранить это в переменную под названием <tt class="doctest"><span class="pre">пресным.</span></tt></li>
<li>Извлечь вторую букву каждого слова в <tt class="doctest"><span class="pre">глупой</span></tt> и присоединиться к ним в строку, чтобы получить <tt class="doctest"><span class="pre"><span class="pysrc-string">'eoldrnnnna'.</span></span></tt></li>
<li>Объедините слова в <tt class="doctest"><span class="pre">пресным</span></tt> обратно в одну строку, используя <tt class="doctest"><span class="pre">присоединиться ().</span></tt>
Убедитесь, что слова в результирующей строке разделены пробелами.</li>
<li>Печать слова <tt class="doctest"><span class="pre">глупо</span></tt> в алфавитном порядке, по одному в каждой строке.</li>
</ol>
</li>
<li><p class="first">◑ Функция <tt class="doctest"><span class="pre">индексации ()</span></tt> может быть использован для просмотра элементов в последовательности.
Например, <tt class="doctest"><span class="pre"><span class="pysrc-string">"невыразимое"</span> .index ( <span class="pysrc-string">'е')</span></span></tt> говорит нам индекс первой позиции буквой <tt class="doctest"><span class="pre">е.</span></tt></p>
<ol class="loweralpha simple">
<li>Что происходит , когда вы смотрите подстроку, например <tt class="doctest"><span class="pre"><span class="pysrc-string">'невыразимую'</span> .index ( <span class="pysrc-string">'ре')?</span></span></tt></li>
<li>Определить переменную <tt class="doctest"><span class="pre">слова</span></tt> , содержащие список слов.  Теперь используйте <tt class="doctest"><span class="pre">words.index ()</span></tt> для поиска позиции отдельного слова.</li>
<li>Определить переменную <tt class="doctest"><span class="pre">глупо</span></tt> , как в приведенном выше упражнении.
С помощью функции <tt class="doctest"><span class="pre">индекса ()</span></tt> в сочетании с список нарезка для создания списка <tt class="doctest"><span class="pre">фразу</span></tt> , состоящую из всех слов , вплоть до (но не включая) <tt class="doctest"><span class="pre"><span class="pysrc-keyword">в</span></span></tt> в <tt class="doctest"><span class="pre">глупой.</span></tt></li>
</ol>
</li>
<li><p class="first">◑ Написать код для преобразования национальной принадлежности прилагательных , как <span class="example">канадский</span> и <span class="example">австралийский</span> их соответствующих существительных <span class="example">Канады</span> и <span class="example">Австралии</span> (см <tt class="doctest"><span class="pre">http://en.wikipedia.org/wiki/List_of_adjectival_forms_of_place_names).</span></tt></p>
</li>
<li><p class="first">◑ Прочитайте пост LanguageLog на фразы вида , <span class="example">как лучше</span> всего, <span class="example">как р может</span> и <span class="example">как лучший р может,</span> где <span class="example">р</span> является местоимение.   Исследовать это явление с помощью корпуса и метода <tt class="doctest"><span class="pre">FindAll ()</span></tt> для поиска текста разбивается на лексемы , описанный в <a class="reference internal" href="http://www.nltk.org/book/ch03.html#sec-useful-applications-of-regular-expressions">3.5</a> .
<tt class="doctest"><span class="pre">http://itre.cis.upenn.edu/~myl/languagelog/archives/002733.html</span></tt></p>
</li>
<li><p class="first">◑ Изучите версию <span class="emphasis">Lolcat</span> книги Бытия, доступной в качестве <tt class="doctest"><span class="pre">nltk.corpus.genesis.words ( <span class="pysrc-string">'lolcat.txt')</span></span></tt> и правила преобразования текста в <span class="emphasis">lolspeak</span> в <tt class="doctest"><span class="pre">http://www.lolcatbible.com/index.php ? название = How_to_speak_lolcat.</span></tt> Определить регулярные выражения для преобразования английских слов в соответствующие lolspeak слова.</p>
</li>
<li><p class="first">◑ Читайте о функции <tt class="doctest"><span class="pre">re.sub ()</span></tt> для подстановки строк с использованием регулярных выражений, используя <tt class="doctest"><span class="pre">помощь (re.sub)</span></tt> и консультационная дальнейшие показания для этой главы.  Используйте <tt class="doctest"><span class="pre">re.sub</span></tt> в написании кода для удаления HTML - теги из HTML - файла, а также нормализовать пропуски.</p>
</li>
<li><p class="first">★ интересный вызов для токенизации это слова, которые были разбиты на разрыв строки.  Например , если <em>долгосрочный</em> делится, то мы имеем строку <tt class="doctest"><span class="pre">долго- \ nterm.</span></tt></p>
<ol class="loweralpha simple">
<li>Написать регулярное выражение, которое идентифицирует слова, которые пишутся через дефис на разрыв строки.  Выражение нужно будет включать <tt class="doctest"><span class="pre">\ п</span></tt> характер.</li>
<li>Используйте <tt class="doctest"><span class="pre">re.sub ()</span></tt> , чтобы удалить <tt class="doctest"><span class="pre">\ п</span></tt> символ из этих слов.</li>
<li>Как вы могли бы определить слова , которые не должны оставаться дефис после того , как символ новой строки удаляется, например , <tt class="doctest"><span class="pre"><span class="pysrc-string">'энциклопедий \ npedia'?</span></span></tt>Икс</li>
</ol>
</li>
<li><p class="first">★ Прочитайте статью в Википедии на <em>Soundex.</em>  Реализовать этот алгоритм в Python.</p>
</li>
<li><p class="first">★ Получить исходные тексты из двух или более жанров и вычислить их соответствующие оценки сложности чтения, как в предыдущем упражнении на чтение трудности.
Например , сравнить ABC Rural News и ABC Science News <tt class="doctest"><span class="pre">(nltk.corpus.abc).</span></tt>
Используйте Punkt для выполнения сегментации предложения.</p>
</li>
<li><p class="first">★ Перепишите следующий вложенный цикл в виде вложенного списка понимания:</p>
<blockquote>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt;</span> Слова = [ <span class="pysrc-string">'атрибуции',</span> <span class="pysrc-string">'болтовня',</span> <span class="pysrc-string">'ораторское',</span> <span class="pysrc-more">...</span> <span class="pysrc-string">'секвойи',</span> <span class="pysrc-string">'цепкий',</span> <span class="pysrc-string">'однонаправленная']</span> <span class="pysrc-prompt">&gt;&gt;&gt;</span> vsequences = множество () <span class="pysrc-prompt">&gt;&gt;&gt;</span> <span class="pysrc-keyword">за</span> словом <span class="pysrc-keyword">в</span> <span class="pysrc-more">словах:. ..</span> гласные = [] <span class="pysrc-more">...</span> <span class="pysrc-keyword">для</span> полукокса <span class="pysrc-keyword">в</span> слове: <span class="pysrc-more">...</span> <span class="pysrc-keyword">если</span> символ <span class="pysrc-keyword">в</span> <span class="pysrc-string">'AEIOU':</span> <span class="pysrc-more">...</span> vowels.append (полукокса) <span class="pysrc-more">...</span> vsequences.add ( <span class="pysrc-string">''</span> .join (гласные)) <span class="pysrc-prompt">&gt;&gt; &gt;</span> сортируется (vsequences) <span class="pysrc-output">[ 'aiuio', 'eaiou', 'eouio', 'euoia', 'oauaio', 'uiieioa']</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<!-- sorted(set(&#39;&#39;.join(c for c in word if c in &#39;aeiou&#39;) for word in words)) -->
</blockquote>
</li>
<li><p class="first">★ Используйте WordNet для создания семантического индекса для текста коллекции.
Расширение программы поиска согласованием в <a class="reference internal" href="http://www.nltk.org/book/ch03.html#code-stemmer-indexing">3.6</a> , индексировать каждое слово , используя смещение его первого synset, например <tt class="doctest"><span class="pre">wn.synsets ( <span class="pysrc-string">'собака')</span> [0] .offset</span></tt> (и , возможно смещение некоторых из его предков в иерархии hypernym).</p>
</li>
<li><p class="first">★ С помощью многоязычного корпуса , таких как Всеобщая декларация прав человека Тела <tt class="doctest"><span class="pre">(nltk.corpus.udhr)</span></tt> и NLTK - х распределение частот и функциональность корреляции рангов <tt class="doctest"><span class="pre">(NLTK.FreqDist,</span></tt> <tt class="doctest"><span class="pre">nltk.spearman_correlation),</span></tt> разработать систему , которая угадывает язык ранее невидимого текста.
Для простоты работы с одной кодировки символов и несколько языков.</p>
</li>
<li><p class="first">★ Напишите программу, которая обрабатывает текст и обнаруживает случаи, когда слово было использовать с новым смыслом.
Для каждого слова, вычислить сходство WordNet между всеми synsets этого слова и всех synsets слов в его контексте.  (Обратите внимание, что это грубый подход, делает это хорошо является сложной, открытой проблемой исследования.)</p>
</li>
<li><p class="first">★ Читайте статью о нормализации нестандартных слов <a class="reference external" href="http://www.nltk.org/book/bibliography.html#sproat2001nor" id="id13">(Спрот</a> и <a class="reference external" href="http://www.nltk.org/book/bibliography.html#sproat2001nor" id="id13">др, 2001)</a> , и внедрить подобную систему для текста нормализации.</p>
</li>
</ol>
<!-- no longer works, need UserAgent spoofing
#. |soso| Define a function ``ghits()`` that takes a word as its argument and
   builds a Google query string of the form ``http://www.google.com/search?q=word``.
   Strip the |HTML| markup and normalize whitespace.  Search for a substring
   of the form ``Results 1 - 10 of about``, followed by some number
   `n`:math:,  and extract `n`:math:.
   Convert this to an integer and return it. -->
<!-- Footer to be used in all chapters -->
<div class="admonition-about-this-document admonition">
<p class="first admonition-title">Об этом документе ...</p>
<p>Обновлялся для NLTK 3.0.
Это глава из книги <em>Обработка естественного языка с помощью Python</em> написанной <a class="reference external" href="http://estive.net/">Стивеном Бердом</a> , <a class="reference external" href="http://homepages.inf.ed.ac.uk/ewan/">Эваном Клайном</a> и <a class="reference external" href="http://ed.loper.org/">Эдвардом Лопером</a> , Copyright © 2014 авторов.
Он распространяется с <em>Набором инструментов для естественного языка</em> <tt class="doctest"><span class="pre">[http://nltk.org/],</span></tt> версия 3.0 в соответствии с условиями <em>Creative Commons Attribution-Noncommercial-No Derivative Works 3.0 Лицензии Соединенных Штатов</em> [ <a class="reference external" href="http://creativecommons.org/licenses/by-nc-nd/3.0/us/">http://creativecommons.org/licenses/by-nc-nd/3.0/us/</a>].</p>
<p class="last">Этот документ был построен на ср 1 июля 2015 12:30:05 AEST</p>
</div>
</div>
</div>
</div>
</body>
</html>