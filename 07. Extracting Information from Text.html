<html lang="ru" dir="ltr" xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ascii"></meta>
<meta name="generator" content="Docutils 0.12: http://docutils.sourceforge.net/"></meta>
<title>7.Извлечение информации из текста</title>
<style type="text/css">/* :Author: Edward Loper, James Curran:Copyright: This stylesheet has been placed in the public domain.Stylesheet for use with Docutils.This stylesheet defines new css classes used by NLTK.It uses a Python syntax highlighting scheme that matchesthe colour scheme used by IDLE, which makes it easier forbeginners to check they are typing things in correctly. */
/* Include the standard docutils stylesheet. */
</style>
</head>
<body dir="ltr">
<div class="document" id="extracting-information-from-text">
<span id="chap-chunk"></span>
<h1 class="title">7. Извлечение информации из текста</h1>

<!-- -*- mode: rst -*- -->
<!-- -*- mode: rst -*- -->
<!-- CAP abbreviations (map to small caps in LaTeX) -->
<!-- Other candidates for global consistency -->
<!-- PTB removed since it must be indexed -->
<!-- WN removed since it must be indexed -->
<!-- misc & punctuation -->
<!-- cdots was unicode U+22EF but not working -->
<!-- exercise meta-tags -->
<!-- Unicode tests -->
<!-- phonetic -->
<!-- misc -->
<!-- used in Unicode section -->
<!-- arrows -->
<!-- unification stuff -->
<!-- Math & Logic -->
<!-- sets -->
<!-- Greek -->
<!-- Chinese -->
<!-- URLs -->
<!-- Python example - a snippet of code in running text -->
<!-- PlaceHolder example -  something that should be replaced by actual code -->
<!-- Linguistic eXample - cited form in running text -->
<!-- Emphasized (more declarative than just using *) -->
<!-- Grammatical Category - e.g. NP and verb as technical terms
.. role:: gc
   :class: category -->
<!-- Math expression - e.g. especially for variables -->
<!-- Textual Math expression - for words &#39;inside&#39; a math environment -->
<!-- Feature (or attribute) -->
<!-- Raw LaTeX -->
<!-- Raw HTML -->
<!-- Feature-value -->
<!-- Lexemes -->
<!-- Replacements that rely on previous definitions :-) -->
<!-- standard global imports

>>> from __future__ import division
>>> import nltk, re, pprint -->
<!-- XXX variety in using nltk.foo vs nltk.chunk.foo for chunk functions -->
<!-- XXX mention somewhere that for IE precision is often more important
than recall? -->
<p>Для любого данного вопроса вполне вероятно, что кто-то где-то написал ответ.  Количество текста на естественном языке, который доступен в электронном виде, поистине ошеломляют и растет с каждым днем.  Однако сложность естественного языка может сделать доступ к содержащейся в нем информации очень трудным.
Состояние дел в НЛП все еще очень далеко от того, чтобы строить общего назначения представления смысла из неограниченного текста.
Если мы вместо этого сосредоточим свои усилия на ограниченном наборе вопросов или "отношений сущностей", таких как "где различные объекты расположены" или "кто нанят какой компанией", мы сможем добиться значительного прогресса.
Цель этой главы - ответить на следующие вопросы:</p>
<ol class="arabic simple">
<li>Как мы можем построить систему, которая извлекает структурированные данные, такие как таблицы, из неструктурированного текста?</li>
<li>Каковы некоторые надежные методы идентификации сущностей и отношений, описанных в тексте?</li>
<li>Какие корпусы подходят для этой работы, и как мы используем их для обучения и оценки наших моделей?</li>
</ol>
<p>Параллельно мы будем применять методы из двух последних глав к проблемам чанкинга и распознавания именованных сущностей.</p>
<div class="section" id="information-extraction">
<span id="sec-information-extraction"></span><h1>1 Извлечение информации</h1>
<p>Информация поступает в разных формах и размерах. Одной из важных форм являются <a name="structured_data_index_term"></a><span class="termdef">структурированные данные</span>, в которых имеется регулярная и предсказуемая организация сущностей и отношений. Например, нас могли бы интересовать отношения между компаниями и местами. Для данной конкретной компании мы бы хотели быть в состоянии определить места, где она ведет свой бизнес; и наоборот, для данного места мы бы хотели узнать, какие компании ведут свой бизнес в этом месте. Если наши данные в табличной форме, такой как пример в <a class="reference internal" href="http://www.nltk.org/book/ch07.html#tab-db-locations">1.1</a>, то дать ответ на эти запросы несложно.</p>
<span class="target" id="tab-db-locations"></span><table border="1" class="docutils" id="tab-db-locations">
<colgroup>
<col width="50%">
<col width="50%">
</colgroup>
<thead valign="bottom">
<tr><th class="head">OrgName</th>
<th class="head">Название местоположения</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>Omnicom</td>
<td>Нью-Йорк</td>
</tr>
<tr><td>DDB Needham</td>
<td>Нью-Йорк</td>
</tr>
<tr><td>Kaplan Thaler Group</td>
<td>Нью-Йорк</td>
</tr>
<tr><td>BBDO South</td>
<td>Атланта</td>
</tr>
<tr><td>Georgia-Pacific</td>
<td>Атланта</td>
</tr>
</tbody>
<td><p class="caption"><span class="caption-label">Таблица 7.1</span>: <p>Данные местоположений</p>
</p>
</td></table>
<p>Если бы данные о местоположении хранились в Python как список кортежей <tt class="doctest"><span class="pre">(entity, relation, entity)</span></tt>, тогда бы вопрос "Какие организации работают в Атланте?" мог быть переведен следующим образом:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; locs = [('Omnicom', 'IN', 'New York'),
...         ('DDB Needham', 'IN', 'New York'),
...         ('Kaplan Thaler Group', 'IN', 'New York'),
...         ('BBDO South', 'IN', 'Atlanta'),
...         ('Georgia-Pacific', 'IN', 'Atlanta')]
&gt;&gt;&gt; query = [e1 for (e1, rel, e2) in locs if e2=='Atlanta']
&gt;&gt;&gt; print(query)
['BBDO South', 'Georgia-Pacific']</pre>
</td>
</tr></table></td></tr>
</table></div>
<span class="target" id="tab-db-answers"></span><table border="1" class="docutils" id="tab-db-answers">
<colgroup>
<col width="100%">
</colgroup>
<thead valign="bottom">
<tr><th class="head">OrgName</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>BBDO South</td>
</tr>
<tr><td>Georgia-Pacific</td>
</tr>
</tbody>
<td><p class="caption"><span class="caption-label">Таблица 1.2</span>: <p>Компании, которые работают в Атланте</p>
</p>
</td></table>
<p>Дело обстоит сложнее, если мы пытаемся получить подобную информацию из текста. Например, рассмотрим следующий фрагмент кода (из <tt class="doctest"><span class="pre">nltk.corpus.ieer</span></tt> для fileid <tt class="doctest"><span class="pre">NYT19980315.0085</span></tt>).</p>
<span class="target" id="ex-ie4"></span><p><table border="0" cellpadding="0" cellspacing="0" class="example">
  <tr valign="top"><td width="30" align="right">(1)</td><td width="15"></td><td>Четвертый счет Wells, переходящий в другое агентство, является подразделением упакованных бумажных изделий Georgia-Pacific Corp., который появился в Wells только прошлой осенью. Как Hertz и History Channel, он также уходит в агентство, которым владеет Omnicom, BBDO South - подразделение BBDO Worldwide.  BBDO South в Атланте, которая занимается корпоративной рекламой для Georgia-Pacific, возьмет на себя дополнительные обязанности для таких марок, как туалетная бумага Angel Soft и бумажные полотенца Sparkle, сказал Кен Халдин, представитель Georgia-Pacific в Атланте.</td></tr></table></p>
<p>Если вы прочитали <a class="reference internal" href="http://www.nltk.org/book/ch07.html#ex-ie4">(1)</a>, вы будете соберете информацию необходимую для ответа на пример вопроса.
Но как мы обучим машину понять достаточно о <a class="reference internal" href="http://www.nltk.org/book/ch07.html#ex-ie4">(1)</a>, чтобы вернуть ответы в <a class="reference internal" href="http://www.nltk.org/book/ch07.html#tab-db-answers">1.2</a>?  Это, очевидно, гораздо более сложная задача. В отличие от <a class="reference internal" href="http://www.nltk.org/book/ch07.html#tab-db-locations">1.1</a>, <a class="reference internal" href="http://www.nltk.org/book/ch07.html#ex-ie4">(1)</a> не содержит структуру, которая связывает имена организации с именами местоположения.</p>
<p>Один из подходов к решению этой проблемы предполагает построение очень общего представления смысла (<a class="reference external" href="http://www.nltk.org/book/ch10.html#chap-semantics">10</a>).
В этой главе мы примем другой подход, решив заранее, что мы будем искать  в тексте только очень специфические виды информации, например, отношения между организациями и местами.  Вместо того чтобы пытаться использовать текст, как <a class="reference internal" href="http://www.nltk.org/book/ch07.html#ex-ie4">(1)</a> для ответа на этот вопрос напрямую, мы сначала преобразуем <a name="unstructured_data_index_term"></a><span class="termdef">неструктурированные данные</span> предложений естественного языка в структурированные данные <a class="reference internal" href="http://www.nltk.org/book/ch07.html#tab-db-locations">1.1</a>. Затем мы воспользуемся преимуществами мощных инструментов формирования запросов, таких как SQL. Этот метод получения смысла из текста называется <a name="information_extraction_index_term"></a> <span class="termdef">Извлечением информации</span>.</p>
<p>Извлечение информации имеет множество применений, в том числе бизнес-аналитика, подведение итогов, анализ средств массовой информации, выявление настроений, патентный поиск и сканирование электронной почты. Особенно важная область современных исследований включает в себя попытки извлечения структурированных данных из доступной в электронном виде научной литературы, особенно в области биологии и медицины.</p>
<div class="section" id="information-extraction-architecture">
<h2>1.1 Архитектура извлечения информации</h2>
<p><a class="reference internal" href="http://www.nltk.org/book/ch07.html#fig-ie-architecture">1.1</a> показывает архитектуру для простой системы извлечения информации.  Она начинается с обработки документа с помощью нескольких процедур, обсуждаемых в <a class="reference external" href="http://www.nltk.org/book/ch03.html#chap-words">3</a> и <a class="reference external" href="http://www.nltk.org/book/ch05.html#chap-tag">5.</a> : сначала исходный текст документа разбивается на предложения с помощью выделителя предложений, каждое предложение далее делится на слова с помощью токенизатора.  Затем каждое предложение помечается метками частей речи, которые окажутся весьма полезными на следующем этапе для <a name="named_entity_detection_index_term"></a><span class="termdef">обнаружения именованных сущностей</span>.  На этом этапе мы ищем упоминания о потенциально интересных сущностях в каждом предложении.  Наконец, мы используем <a name="relation_detection_index_term"></a> <span class="termdef">обнаружение отношений</span> для поиска вероятных отношений между различными сущностями в тексте.</p>
<span class="target" id="fig-ie-architecture"></span><div class="figure" id="fig-ie-architecture">
<img alt="../images/ie-architecture.png" src="http://www.nltk.org/images/ie-architecture.png" style="width:451.25px;height:284.5px">
<p class="caption"><span class="caption-label">Рисунок 1.1:</span> Простая последовательная схема архитектуры для системы извлечения информации.
Эта система принимает необработанный текст документа в качестве входных данных и генерирует список кортежей <tt class="doctest"><span class="pre">(сущность, отношение, сущность)</span></tt> в качестве своего выхода.  Например, для данного документа, который указывает, что компания Georgia-Pacific находится в Атланте, он может сгенерировать кортеж <tt class="doctest"><span class="pre">([ORG: <span class="pysrc-string">"Georgia-Pacific"</span>] <span class="pysrc-string">"in"</span> [LOC: <span class="pysrc-string">"Атланта"</span>])</span></tt>.</p>
</div>
<p>Для выполнения первых трех задач мы можем определить простую функцию, которая просто соединяет вместе выделитель предложений по умолчанию <a class="reference internal" href="http://www.nltk.org/book/ch07.html#ie-segment"><span id="ref-ie-segment"><img class="callout" alt="[1]" src="http://www.nltk.org/book/callouts/callout1.gif"></span></a>, токенизатор слов <a class="reference internal" href="http://www.nltk.org/book/ch07.html#ie-tokenize"><span id="ref-ie-tokenize"><img class="callout" alt="[2]" src="http://www.nltk.org/book/callouts/callout2.gif"></span></a> и разметчик частей речи <a class="reference internal" href="http://www.nltk.org/book/ch07.html#ie-postag"><span id="ref-ie-postag"><img class="callout" alt="[3]" src="http://www.nltk.org/book/callouts/callout3.gif"></span></a> NLTK:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; def ie_preprocess(document):
...    sentences = nltk.sent_tokenize(document) 
...    sentences = [nltk.word_tokenize(sent) for sent in sentences] 
...    sentences = [nltk.pos_tag(sent) for sent in sentences]  <a name="ie-postag"></a><a href="http://www.nltk.org/book/ch07.html#ref-ie-postag"><img src="http://www.nltk.org/book/callouts/callout3.gif" alt="[3]" class="callout"></a></pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="note">
<p class="first admonition-title">Замечание</p>
<p class="last">Помните, что наши образцы программ предполагают, что Вы начинаете свой интерактивный сеанс или программу с: <tt class="doctest"><span class="pre"><span class="pysrc-keyword">import</span> nltk, re, pprint</span></tt></p>
</div>
<p>Далее, в обнаружении именованных сущностей, мы сегментируем и помечаем сущности, которые могли бы принять участие в интересующих нас отношениях друг с другом.  Как правило, это будут определенные словосочетания с существительным, такие как <span class="example">"the knights who say "ni"</span> или имена собственные, такие как <span class="example">"Monty Python"</span>.
В некоторых задачах полезно также рассмотреть неопределенные существительные или чанки существительных, такие как <cite>каждый студент</cite> или <cite>кошки</cite>, они не обязательно относятся к сущностям таким же образом, как определенные <tt class="doctest"><span class="pre">NPS</span></tt> и имена собственные.</p>
<p>И, наконец, в извлечении отношений мы ищем конкретные паттерны между парами сущностей, которые возникают рядом друг с другом в тексте, и используем эти паттерны для создания кортежей, записывающих отношения между этими сущностями.</p>
</div>
</div>
<div class="section" id="chunking">
<span id="sec-chunking"></span><h1>Chunking</h1>
<p>Основная техника, которую мы будем использовать для обнаружения объекта является <a name="chunking_index_term"></a><span class="termdef">чанкинг</span>, который сегментирует и помечает последовательности, состоящие из нескольких токенов, как показано на Рисунке <a class="reference internal" href="http://www.nltk.org/book/ch07.html#fig-chunk-segmentation">2.1</a>.  Меньшие ячейки показывают токенизацию на уровне слов и разметка частей речи, в то время как большие ячейки показывают группировку более высокого уровня.  Каждая из этих больших коробок называется <a name="chunk_index_term"></a><span class="termdef">группировкой</span>.
Как токенизация, которая опускает пробелы, группировка обычно выбирает подмножество токенов.
Так же, как при токенизации, части, выделенные группировщиком, не перекрывают друг друга в исходном тексте.</p>
<span class="target" id="fig-chunk-segmentation"></span><div class="figure" id="fig-chunk-segmentation">
<img alt="../images/chunk-segmentation.png" src="http://www.nltk.org/images/chunk-segmentation.png" style="width:493.75px;height:101.25px">
<p class="caption"><span class="caption-label">Рисунок 2.1:</span> Сегментация и маркировка на уровне токена и группы</p>
</div>
<p>В этом разделе мы рассмотрим группировку с некоторой степенью глубины, начав с определения и представления группировок.  Мы увидим регулярные выражения и n-грамм как подходы к группировке,  разработаем и оценим группировщики с помощью CoNLL-2000 группировочного корпуса. Затем мы вернемся в <a class="reference internal" href="http://www.nltk.org/book/ch07.html#sec-ner">(5)</a> и <a class="reference internal" href="http://www.nltk.org/book/ch07.html#sec-relextract">6</a> к задачам распознавания именованных объектов и извлечения отношений.</p>
<div class="section" id="noun-phrase-chunking">
<h2>2.1 Группировка словосочетаний с существительным</h2>
<p>Мы начнем с рассмотрения задачи группировки <a name="noun_phrase_chunking_index_term"></a><span class="termdef">именных фраз</span>, или <a name="np_chunking_index_term"></a><span class="termdef">NP-группировки</span>, в рамках которой мы ищем группировки, соответствующие отдельным именным фразам.  Например, вот некоторый текст из Wall Street Journal с <tt class="doctest"><span class="pre">NP</span></tt>-группировками, отмеченными с помощью квадратных скобок:</p>
<span class="target" id="ex-wsj-nx"></span><p><table border="0" cellpadding="0" cellspacing="0" class="example">
  <tr valign="top"><td width="30" align="right">(2)</td><td width="15"></td><td>[ The/DT market/NN ] for/IN [ system-management/NN software/NN ]
for/IN [ Digital/NNP ] [ 's/POS hardware/NN ] is/VBZ fragmented/JJ
enough/RB that/IN [ a/DT giant/NN ] such/JJ as/IN [ Computer/NNP
Associates/NNPS ] should/MD do/VB well/RB there/RB ./.</td></tr></table></p>
<p>Как мы можем видеть, <tt class="doctest"><span class="pre">NP</span></tt>-группировки часто более мелкие куски, чем полные именные фразы.  Например, <span class="example">the market for system-management software
for Digital's hardware</span> является одной именной фразой (содержащей две вложенные именные фразы), но она схвачена в <tt class="doctest"><span class="pre">NP</span></tt>-группировках более простой группировкой <span class="example">the market</span>.  Одной из причин этого различия является то, что <tt class="doctest"><span class="pre">NP</span></tt>-группировки определены таким образом, чтобы не содержать другие <tt class="doctest"><span class="pre">NP</span></tt>-группировки.  Следовательно, любые предложные фразы или придаточные предложения, которые модифицируют номинал, не будут включены в соответствующую <tt class="doctest"><span class="pre">ИФ</span></tt>-группировку, так как они почти наверняка содержат другие именные фразы.</p>
<p>Одним из наиболее полезных источников информации для <tt class="doctest"><span class="pre">ИФ</span></tt>-группировки является метки частей речи.  Это один из мотивов для выполнения разметки частей речи в нашей системе извлечения информации.  Мы демонстрируем этот подход, используя пример предложения, которое было помечено метками частей речи, в <a class="reference internal" href="http://www.nltk.org/book/ch07.html#code-chunkex">2.2</a>.  Для того, чтобы создать <tt class="doctest"><span class="pre">ИФ</span></tt>-группировщик, сначала мы определим <a name="chunk_grammar_index_term"></a><span class="termdef">группировочную грамматику</span>, состоящую из правил, которые указывают, как предложения должны быть сгруппированны.  В этом случае мы определим простую грамматику с одним правилом, выраженным регулярным выражением <a class="reference internal" href="http://www.nltk.org/book/ch07.html#chunkex-grammar"><span id="ref-chunkex-grammar"><img class="callout" alt="[2]" src="http://www.nltk.org/book/callouts/callout2.gif"></span></a>.  Это правило говорит о том , что ИФ группировка должна быть сформирована каждый раз, когда группировщик находит опциональный определитель <tt class="doctest"><span class="pre">(DT)</span></tt>, за которым следует любое число прилагательных <tt class="doctest"><span class="pre">(JJ)</span></tt>, а затем существительное <tt class="doctest"><span class="pre">(NN)</span></tt>.  Используя эту грамматику, мы создаем парсер группировок <a class="reference internal" href="http://www.nltk.org/book/ch07.html#chunkex-cp"><span id="ref-chunkex-cp"><img class="callout" alt="[3]" src="http://www.nltk.org/book/callouts/callout3.gif"></span></a> и проверяем его на нашем предложении <a class="reference internal" href="http://www.nltk.org/book/ch07.html#chunkex-test"><span id="ref-chunkex-test"><img class="callout" alt="(4)" src="http://www.nltk.org/book/callouts/callout4.gif"></span></a>.  Результатом является дерево, которое мы можем вывести в виде текста <a class="reference internal" href="http://www.nltk.org/book/ch07.html#chunkex-print"><span id="ref-chunkex-print"><img class="callout" alt="5%" src="http://www.nltk.org/book/callouts/callout5.gif"></span></a> или отобразить графически <a class="reference internal" href="http://www.nltk.org/book/ch07.html#chunkex-draw"><span id="ref-chunkex-draw"><img class="callout" alt="(6)" src="http://www.nltk.org/book/callouts/callout6.gif"></span></a>.</p>
<span class="target" id="code-chunkex"></span><div class="pylisting">
<table border="0" cellpadding="0" cellspacing="0" class="pylisting" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; sentence = [("the", "DT"), ("little", "JJ"), ("yellow", "JJ"), 
... ("dog", "NN"), ("barked", "VBD"), ("at", "IN"),  ("the", "DT"), ("cat", "NN")]

&gt;&gt;&gt; grammar = "NP: {&lt;DT&gt;?&lt;JJ&gt;*&lt;NN&gt;}" 

&gt;&gt;&gt; cp = nltk.RegexpParser(grammar) 
&gt;&gt;&gt; result = cp.parse(sentence) 
&gt;&gt;&gt; print(result) 
(S
  (NP the/DT little/JJ yellow/JJ dog/NN)
  barked/VBD
  at/IN
  (NP the/DT cat/NN))
&gt;&gt;&gt; result.draw() <a name="chunkex-draw"></a><a href="http://www.nltk.org/book/ch07.html#ref-chunkex-draw"><img src="http://www.nltk.org/book/callouts/callout6.gif" alt="(6)" class="callout"></a></pre>
</td>
</tr></table></td></tr>
<tr><td class="caption"><p class="caption"><a class="reference external" href="http://www.nltk.org/book/pylisting/code_chunkex.py" type="text/x-python"><span class="caption-label">Пример 2.2 (code_chunkex.py)</span></a>: <span class="caption-label">Рисунок 2.2</span>: Пример ИФ группировщика на основе простого регулярного выражения.</p></td></tr>
</table></div>
<img alt="tree_images / CH07-дерево-1.png" class="align-top" src="http://www.nltk.org/book/tree_images/ch07-tree-1.png" style="width:356.0px;height:144.0px">
</div>
<div class="section" id="tag-patterns">
<h2>2.2 Паттерны меток</h2>
<p>Правила, которые составляют грамматику группировки используют <a name="tag_patterns_index_term"></a><span class="termdef">паттерны меток</span> для описания последовательности помеченных слов.
Паттерн меток представляет собой последовательность меток частей речи, разделенных с помощью угловых скобок, например, <tt class="doctest"><span class="pre">&lt;DT&gt;?&lt;JJ&gt;*&lt;NN&gt;</span></tt>.  Паттерны меток похожи на шаблоны регулярных выражений (<a class="reference external" href="http://www.nltk.org/book/ch03.html#sec-regular-expressions-word-patterns">3.4</a>).
Теперь рассмотрим следующие именные фразы из Wall Street Journal:</p>
<pre class="literal-block">
nother/DT sharp/JJ dive/NN
trade/NN figures/NNS
any/DT new/JJ policy/NN measures/NNS
earlier/JJR stages/NNS
Panamanian/JJ dictator/NN Manuel/NNP Noriega/NNP
</pre>
<p>Мы можем подобрать паттерн для этих именных фраз с помощью небольшого уточнение первого паттерна меток выше, то есть <tt class="doctest"><span class="pre">&lt;DT&gt;?&lt;JJ.*&gt;*&lt;NN.*&gt;+</span></tt>.  Это выделит любую последовательность токенов, начинающихся с опционального определителя, за которым следуют ноль или более прилагательных любого типа (в том числе относительные прилагательные, как <tt class="doctest"><span class="pre">earlier/JJR</span></tt>), за которыми следует один или более существительных любого типа.  Однако легко найти намного больше сложных примеров, на которые это правило не распространяется:</p>
<pre class="literal-block">
his/PRP$ Mansion/NNP House/NNP speech/NN
the/DT price/NN cutting/VBG
3/CD %/NN to/TO 4/CD %/NN
more/JJR than/IN 10/CD %/NN
the/DT fastest/JJS developing/VBG trends/NNS
's/POS skill/NN
</pre>
<div class="note">
<p class="first admonition-title">Замечание</p>
<p class="last"><strong>Ваша очередь</strong>: 
Попробуйте придумать паттерны меток для этих случаев.
Проверьте их с помощью графического интерфейса <tt class="doctest"><span class="pre">nltk.app.chunkparser()</span></tt>.  Продолжайте совершенствовать ваши паттерны меток с помощью обратной связи данного инструмента.</p>
</div>
</div>
<div class="section" id="chunking-with-regular-expressions">
<h2>2.3 Группировка с использованием регулярных выражений</h2>
<p>Для того, чтобы найти структуру группировки для данного предложения, группировщик <tt class="doctest"><span class="pre">RegexpParser</span></tt> начинает с плоской структуры, в которой токены не сгруппированы.  Правила группировки применяются по очереди, последовательно обновляя структуру группировки.  После того, как все правила были применены, полученная структура группировки возвращается.</p>
<p>Листинг <a class="reference internal" href="http://www.nltk.org/book/ch07.html#code-chunker1">2.3</a> показывает простую грамматику группировки, состоящую из двух правил.  Первое правило находит опциональный определитель или притяжательное местоимение, ноль или более прилагательных, затем существительное.
Второе правило находит одно или более имен собственных.
Мы также определяем для примера предложение, которое должно быть сгруппировано <a class="reference internal" href="http://www.nltk.org/book/ch07.html#code-chunker1-ex"><span id="ref-code-chunker1-ex"><img class="callout" alt="[1]" src="http://www.nltk.org/book/callouts/callout1.gif"></span></a>, и запускаем группировщик для этого входа <a class="reference internal" href="http://www.nltk.org/book/ch07.html#code-chunker1-run"><span id="ref-code-chunker1-run"><img class="callout" alt="[2]" src="http://www.nltk.org/book/callouts/callout2.gif"></span></a>.</p>
<span class="target" id="code-chunker1"></span><div class="pylisting">
<table border="0" cellpadding="0" cellspacing="0" class="pylisting" width="95%">
<tr><td class="codeblock">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_codeblock_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
Грамматика = г <span class="pysrc-string">""</span> <span class="pysrc-string"><span class="pysrc-string">"НП:</span> {&lt;DT | PP \ $&gt;?&lt;JJ&gt; * &lt;NN&gt;} # Кусок Определитель / притяжательные, прилагательные и существительное</span> <span class="pysrc-string">{&lt;ННП&gt; +} # кусков последовательности имен собственных</span> <span class="pysrc-string">"" "ф</span> = NLTK.RegexpParser (грамматика) предложение = [( <span class="pysrc-string">"Рапунцель",</span> <span class="pysrc-string">"ННП"),</span> ( <span class="pysrc-string">"пусть",</span> <span class="pysrc-string">"ВБД"),</span> ( <span class="pysrc-string">"вниз",</span> <span class="pysrc-string">"РП"),</span> <a name="code-chunker1-ex"></a> <a href="http://www.nltk.org/book/ch07.html#ref-code-chunker1-ex"><img src="http://www.nltk.org/book/callouts/callout1.gif" alt="[1]" class="callout"></a> ( <span class="pysrc-string">"Ее",</span> <span class="pysrc-string">"PP $"),</span> ( <span class="pysrc-string">"длинный",</span> <span class="pysrc-string">"JJ"),</span> ( <span class="pysrc-string">"золотой",</span> <span class="pysrc-string">"JJ"),</span> ( <span class="pysrc-string">"волосы",</span> <span class="pysrc-string">"NN")]</span></pre>
</td>
</tr></table></td></tr>
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt;</span> <span class="pysrc-keyword">Печать</span> (cp.parse (предложение)) <a name="code-chunker1-run"></a> <a href="http://www.nltk.org/book/ch07.html#ref-code-chunker1-run"><img src="http://www.nltk.org/book/callouts/callout2.gif" alt="[2]" class="callout"></a> <span class="pysrc-output">(S</span> <span class="pysrc-output">(NP Рапунцель / ННП)</span> <span class="pysrc-output">пусть / ВБД</span> <span class="pysrc-output">вниз / RP</span> <span class="pysrc-output">(NP ее / PP $ длинный / JJ золотой / JJ волос / NN))</span></pre>
</td>
</tr></table></td></tr>
<tr><td class="caption"><p class="caption"><a class="reference external" href="http://www.nltk.org/book/pylisting/code_chunker1.py" type="text/x-python"><span class="caption-label">Пример 2.3 (code_chunker1.py)</span></a>: <span class="caption-label">Рисунок 2.3</span>: Группировщик простых именных фраз</p></td></tr>
</table></div>
<div class="note">
<p class="first admonition-title">Замечание</p>
<p class="last">Символ <tt class="doctest"><span class="pre">$</span></tt> является специальным символом в регулярных выражениях и должен быть экранирован обратной косой чертой, чтобы соответствовать метке <tt class="doctest"><span class="pre">PP$</span></tt>.</p>
</div>
<p>Если паттерн меток находит соответствие в перекрывающихся местах, крайне левое соответствие имеет преимущество.  Например, если мы применяем правило, которое соответствует двум последовательным существительным в тексте, содержащем три последовательных существительных, то только первые два существительных будут сгруппированы:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; nouns = [("money", "NN"), ("market", "NN"), ("fund", "NN")]
&gt;&gt;&gt; grammar = "NP: {&lt;NN&gt;&lt;NN&gt;}  # Chunk two consecutive nouns"
&gt;&gt;&gt; cp = nltk.RegexpParser(grammar)
&gt;&gt;&gt; print(cp.parse(nouns))
(S (NP money/NN market/NN) fund/NN)</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>После того, как мы создали группировку для <span class="example">money market</span>, мы удалили контекст, который позволил бы <span class="example">fund</span> включить в группировку.  Этой проблемы можно было бы избежать при более слабом правиле группировки, например, <tt class="doctest"><span class="pre">NP: {&lt;NN&gt;+}</span></tt>.</p>
<div class="note">
<p class="first admonition-title">Замечание</p>
<p class="last">Мы добавили комментарий к каждому из наших правил группировки.
Они не являются обязательными; когда они присутствуют, группировщик печатает эти комментарии как часть вывода отладки.</p>
</div>
</div>
<div class="section" id="exploring-text-corpora">
<h2>2.4 Исследование текстового корпуса</h2>
<p>В <a class="reference external" href="http://www.nltk.org/book/ch05.html#sec-tagged-corpora">2</a> мы видели, как мы могли бы допросить помеченный корпус, чтобы извлечь фразы, соответствующие конкретной последовательности меток частей речи.  Мы можем сделать ту же работу более легко с помощью группировщика следующим образом:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; cp = nltk.RegexpParser('CHUNK: {&lt;V.*&gt; &lt;TO&gt; &lt;V.*&gt;}')
&gt;&gt;&gt; brown = nltk.corpus.brown
&gt;&gt;&gt; for sent in brown.tagged_sents():
...     tree = cp.parse(sent)
...     for subtree in tree.subtrees():
...         if subtree.label() == 'CHUNK': print(subtree)
...
(CHUNK combined/VBN to/TO achieve/VB)
(CHUNK continue/VB to/TO place/VB)
(CHUNK serve/VB to/TO protect/VB)
(CHUNK wanted/VBD to/TO wait/VB)
(CHUNK allowed/VBN to/TO place/VB)
(CHUNK expected/VBN to/TO become/VB)
...
(CHUNK seems/VBZ to/TO overtake/VB)
(CHUNK want/VB to/TO buy/VB)</pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="note">
<p class="first admonition-title">Замечание</p>
<p class="last"><strong>Ваша очередь:</strong> 
Поместите приведенный выше пример внутрь функции <tt class="doctest"><span class="pre">find_chunks()</span></tt>, которая принимает строку группировки вроде <tt class="doctest"><span class="pre"><span class="pysrc-string">"CHUNK: {&lt;V.*&gt; &lt;TO&gt; &lt;V.*&gt;}"</span></span></tt> в качестве аргумента.
Используйте ее, чтобы найти в корпусе нескольких других паттернов, таких как четыре или более существительных подряд, например : <tt class="doctest"><span class="pre"><span class="pysrc-string">"NOUNS: {&lt;N.*&gt;{4,}}"</span></span></tt></p>
</div>
</div>
<div class="section" id="chinking">
<h2>2.5 Исключение</h2>
<p>Иногда легче определить, что мы хотим <span class="emphasis">исключить</span> из группировки.  Мы можем определить <a name="chink_index_term"></a><span class="termdef">исключение (chink, чинк)</span> как последовательность токенов, которая не включается в группировку.
В следующем примере <tt class="doctest"><span class="pre">barked/VBD at/IN</span></tt> является исключением:</p>
<pre class="literal-block">
[ the/DT little/JJ yellow/JJ dog/NN ] barked/VBD at/IN [ the/DT cat/NN ]
</pre>
<p>Исключение это процесс удаления последовательности токенов из группировки.  Если соответствующая последовательность токенов охватывает всю группировку, то вся группировка удаляется; если такая последовательность токенов появляется в середине группировки, эти токены будут удалены, оставляя две группировки на месте, где до этого была только одна.  Если такая последовательность на периферии группировки, эти токены будут удалены, и останется группировка меньшая по размеру.
Эти три варианта проиллюстрированы в таблице <a class="reference internal" href="http://www.nltk.org/book/ch07.html#tab-chinking-example">2.1</a>.</p>
<span class="target" id="tab-chinking-example"></span><table border="1" class="docutils" id="tab-chinking-example">
<colgroup>
<col width="18%">
<col width="29%">
<col width="28%">
<col width="25%">
</colgroup>
<thead valign="bottom">
<tr><th class="head">` `</th>
<th class="head">Вся группировка</th>
<th class="head">Середина группировки</th>
<th class="head">Конец группировки</th>
</tr>
</thead>
<tbody valign="top">
<tr><td><em>Вход</em></td>
<td>[a/DT little/JJ
dog/NN]</td>
<td>[a/DT little/JJ
dog/NN]</td>
<td>[a/DT little/JJ
dog/NN]</td>
</tr>
<tr><td><em>Операция</em></td>
<td>Chink "DT JJ NN"</td>
<td>Chink "JJ"</td>
<td>Chink "NN"</td>
</tr>
<tr><td><em>Паттерн</em></td>
<td>}DT JJ NN{</td>
<td>}JJ{</td>
<td>}NN{</td>
</tr>
<tr><td><em>Выход</em></td>
<td>a/DT little/JJ
dog/NN</td>
<td>[a/DT] little/JJ
[dog/NN]</td>
<td>[a/DT little/JJ]
dog/NN</td>
</tr>
</tbody>
<td><p class="caption"><span class="caption-label">Таблица 2.1</span>: <p>Три правила исключения, примененных к одной той же группировке</p>
</p>
</td></table>
<p>В листинге <a class="reference internal" href="http://www.nltk.org/book/ch07.html#code-chinker">2.4</a>, мы помещаем все предложение в единственную группировку, затем убираем исключения.</p>
<span class="target" id="code-chinker"></span><div class="pylisting">
<table border="0" cellpadding="0" cellspacing="0" class="pylisting" width="95%">
<tr><td class="codeblock">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_codeblock_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
grammar = r"""
  NP:
    {&lt;.*&gt;+}          # Chunk everything
    }&lt;VBD|IN&gt;+{      # Chink sequences of VBD and IN
  """
sentence = [("the", "DT"), ("little", "JJ"), ("yellow", "JJ"),
       ("dog", "NN"), ("barked", "VBD"), ("at", "IN"),  ("the", "DT"), ("cat", "NN")]
cp = nltk.RegexpParser(grammar)</pre>
</td>
</tr></table></td></tr>
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; print(cp.parse(sentence))
 (S
   (NP the/DT little/JJ yellow/JJ dog/NN)
   barked/VBD
   at/IN
   (NP the/DT cat/NN))</pre>
</td>
</tr></table></td></tr>
<tr><td class="caption"><p class="caption"><a class="reference external" href="http://www.nltk.org/book/pylisting/code_chinker.py" type="text/x-python"><span class="caption-label">Пример 2.4 (code_chinker.py)</span></a>: <span class="caption-label">Листинг 2.4</span>: Простой исключатель</p></td></tr>
</table></div>
<!-- We haven&#39;t talked about using conll yet; and these results are
very far from impressive anyway: :)

>>> from nltk.corpus import conll2000
>>> test_sents = conll2000.chunked_sents(&#39;test.txt&#39;, chunk_types=[&#39;NP&#39;])
>>> print(nltk.chunk.accuracy(cp, test_sents))
 0.5810414336070245 -->
<!-- Section: "Multiple Chunk Types" was here.  I moved it to
ch07-extras because I didn&#39;t see that it added much, and it didn&#39;t
feel very motivated. -->
<!-- Section" Chunking vs Parsing" was here.  I moved it to
ch07-extras for now.  We might fold it back in later in the chapter,
or somewhere in the parsing chapter, but here seemed like an odd
place for it. -->
</div>
<div class="section" id="representing-chunks-tags-vs-trees">
<h2>2.6 Представляющие группировок: метки против деревьев</h2>
<p>Как и подобает их промежуточному положению между разметкой и синтаксическим анализом (<a class="reference external" href="http://www.nltk.org/book/ch08.html#chap-parse">8.</a>), группировочные структуры могут быть представлены с помощью меток или деревьев.  Наиболее распространенное файловое представление использует <a name="iob_tags_index_term"></a><span class="termdef">IOB метки</span>.  В этой схеме каждый токен помечен одной из трех специальных меток группировки: <tt class="doctest"><span class="pre">I</span></tt> (внутри), <tt class="doctest"><span class="pre">O</span></tt> (снаружи) или <tt class="doctest"><span class="pre">B</span></tt> (в начале).  Токен помечается как <tt class="doctest"><span class="pre">B</span></tt>, если оно знаменует собой начало группировки.  Последующие токены в пределах группировки помечаются меткой <tt class="doctest"><span class="pre">I</span></tt>.  Все остальные токены помечаются меткой <tt class="doctest"><span class="pre">O</span></tt>. Метки <tt class="doctest"><span class="pre">B</span></tt> и <tt class="doctest"><span class="pre">I</span></tt> имеют суффикс типа группировки, например, <tt class="doctest"><span class="pre">B-NP</span></tt>, <tt class="doctest"><span class="pre">I-NP</span></tt>.  Разумеется, не нужно указывать тип группировки для токенов, которые появляются вне группировки, поэтому эти токены просто помечаются меткой <tt class="doctest"><span class="pre">O</span></tt>. Пример этой схемы показан на рисунке <a class="reference internal" href="http://www.nltk.org/book/ch07.html#fig-chunk-tagrep">2.5</a>.</p>
<span class="target" id="fig-chunk-tagrep"></span><div class="figure" id="fig-chunk-tagrep">
<img alt="../images/chunk-tagrep.png" src="http://www.nltk.org/images/chunk-tagrep.png" style="width:483.5px;height:85.5px">
<p class="caption"><span class="caption-label">Рисунок 2.5:</span> Представление с помощью меток структуры группировки</p>
</div>
<p>IOB метки стали стандартным способом представления структур группировки в файлах, и мы также будем использовать этот формат.  Вот как информация, содержащаяся в <a class="reference internal" href="http://www.nltk.org/book/ch07.html#fig-chunk-tagrep">2.5</a>, будет выглядеть в файле:</p>
<pre class="literal-block">
We PRP B-NP
saw VBD O
the DT B-NP
yellow JJ I-NP
dog NN I-NP
</pre>
<p>В этом представлении на каждой строке по одному токену, каждый со своей меткой части речи и меткой группировки.  Этот формат позволяет представить более одного типа группировки, если группировки не перекрывают друг друга.
Как мы видели ранее, структуры группировки также могут быть представлены с помощью деревьев.  Они имеют то преимущество, что каждая группировка является компонентом, которым можно манипулировать непосредственно.  Пример показан на рисунке <a class="reference internal" href="http://www.nltk.org/book/ch07.html#fig-chunk-treerep">2.6</a>.</p>
<span class="target" id="fig-chunk-treerep"></span><div class="figure" id="fig-chunk-treerep">
<img alt="../images/chunk-treerep.png" src="http://www.nltk.org/images/chunk-treerep.png" style="width:483.5px;height:174.0px">
<p class="caption"><span class="caption-label">Рисунок 2.6:</span> Представление структуры группировки в виде дерева</p>
</div>
<div class="note">
<p class="first admonition-title">Замечание</p>
<p class="last">NLTK использует деревья для своего внутреннего представления группировок, но предоставляет методы для чтения и записи таких деревьев в формате IOB.</p>
</div>
</div>
</div>
<div class="section" id="developing-and-evaluating-chunkers">
<h1>3 Разработка и оценка группировщиков</h1>
<p>Теперь у вас есть представление о том, что делает группировщик, но мы еще не объяснили, как оценить группировщик.
Как обычно, для этого требуется соответствующим образом аннотированный корпус.
Сначала мы рассмотрим механику преобразования формата IOB в древо NLTK, затем то, как это делается в большем масштабе с использованием сгруппированного корпуса.  Мы увидим, как оценить точность группирощика относительно корпуса, а затем рассмотрим еще несколько способов поиска NP-группировок, идущих от данных.
Наше внимание будет сосредоточено на расширении охвата группировщика.</p>
<!-- Section: "Developing chunkers" was here.  I moved it to
ch07-extras.  I don&#39;t think it added much. -->
<div class="section" id="reading-iob-format-and-the-conll-2000-corpus">
<h2>3.1 Чтение IOB формата и Корпус CoNLL 2000</h2>
<p>С помощью модуля <tt class="doctest"><span class="pre">corpus</span></tt> можно загрузить текст Wall Street Journal, который был помечен, а затем сгруппирован с помощью IOB нотации.  Категориями группировки в этом корпусе являются <tt class="doctest"><span class="pre">NP</span></tt>, <tt class="doctest"><span class="pre">VP</span></tt> и <tt class="doctest"><span class="pre">PP</span></tt>.  Как мы уже видели, каждое предложение представляется с помощью нескольких строк, как показано ниже:</p>
<pre class="literal-block">
he PRP B-NP
accepted VBD B-VP
the DT B-NP
position NN I-NP
...
</pre>
<p>Функция преобразования <tt class="doctest"><span class="pre">chunk.conllstr2tree()</span></tt> строит дерево для каждого из этих предложений.  Кроме того, она позволяет выбрать, какое подмножество из трех типов группировки использовать, здесь только для <tt class="doctest"><span class="pre">NP</span></tt> группировок:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; text = '''
... he PRP B-NP
... accepted VBD B-VP
... the DT B-NP
... position NN I-NP
... of IN B-PP
... vice NN B-NP
... chairman NN I-NP
... of IN B-PP
... Carlyle NNP B-NP
... Group NNP I-NP
... , , O
... a DT B-NP
... merchant NN I-NP
... banking NN I-NP
... concern NN I-NP
... . . O
... '''
&gt;&gt;&gt; nltk.chunk.conllstr2tree(text, chunk_types=['NP']).draw()</pre>
</td>
</tr></table></td></tr>
</table></div>
<img alt="tree_images / CH07-дерево-2.png" class="align-top" src="http://www.nltk.org/book/tree_images/ch07-tree-2.png" style="width:692.0px;height:116.0px">
<p>Мы можем использовать NLTK модуль corpus, чтобы получить доступ к большему количеству сгруппированных текстов.  Корпус CoNLL 2000 содержит 270K слов текста Wall Street Journal, разделенных на "тренировочную" и "тестовую" части, аннотированных метками частей речи и группировочными метками в формате IOB.  Мы можем получить доступ к этим данным с помощью <tt class="doctest"><span class="pre">nltk.corpus.conll2000</span></tt>.  Вот пример, который читает 100-ое предложение "тренировочной" части корпуса:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; from nltk.corpus import conll2000
&gt;&gt;&gt; print(conll2000.chunked_sents('train.txt')[99])
(S
  (PP Over/IN)
  (NP a/DT cup/NN)
  (PP of/IN)
  (NP coffee/NN)
  ,/,
  (NP Mr./NNP Stone/NNP)
  (VP told/VBD)
  (NP his/PRP$ story/NN)
  ./.)</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Как вы можете видеть, корпус CoNLL 2000 содержит три группировочных типа: <tt class="doctest"><span class="pre">NP</span></tt> группировки, которые мы уже видели; <tt class="doctest"><span class="pre">VP</span></tt> группировки, такие как <span class="example">has already delivered</span>; и <tt class="doctest"><span class="pre">PP</span></tt> группировки, такие как <span class="example">because of</span>.
Поскольку прямо сейчас нас интересуют только <tt class="doctest"><span class="pre">NP</span></tt> группировки, мы можем использовать аргумент <tt class="doctest"><span class="pre">chunk_types</span></tt>, чтобы выбрать только их:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; print(conll2000.chunked_sents('train.txt', chunk_types=['NP'])[99])
(S
  Over/IN
  (NP a/DT cup/NN)
  of/IN
  (NP coffee/NN)
  ,/,
  (NP Mr./NNP Stone/NNP)
  told/VBD
  (NP his/PRP$ story/NN)
  ./.)</pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="simple-evaluation-and-baselines">
<h2>3.2 Простая оценка и основания</h2>
<p>Теперь, когда мы умеем обращаться к сгруппированному корпусу, мы можем оценить группировщики.
Мы начнем с установления основания для тривиального анализатора группировки <tt class="doctest"><span class="pre">cp</span></tt>, который не создает никаких группировок:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; from nltk.corpus import conll2000
&gt;&gt;&gt; cp = nltk.RegexpParser("")
&gt;&gt;&gt; test_sents = conll2000.chunked_sents('test.txt', chunk_types=['NP'])
&gt;&gt;&gt; print(cp.evaluate(test_sents))
ChunkParse score:
    IOB Accuracy:  43.4%
    Precision:      0.0%
    Recall:         0.0%
    F-Measure:      0.0%</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Точность IOB метки указывает на то, что более чем треть слов помечены <tt class="doctest"><span class="pre">O</span></tt>, т.е. они находятся вне <tt class="doctest"><span class="pre">NP</span></tt> группировки.  Однако, поскольку наш разметчик не нашел <em>никаких</em> группировок, его точность, охват и f-мера - все равны нулю.  Теперь давайте попробуем наивный группировщик, использующий регулярное выражение, который ищет метки, начинающиеся с букв, которые являются характеристикой меток именных фраз (например, <tt class="doctest"><span class="pre">CD</span></tt>, <tt class="doctest"><span class="pre">DT</span></tt> и <tt class="doctest"><span class="pre">JJ</span></tt>).</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; grammar = r"NP: {&lt;[CDJNP].*&gt;+}"
&gt;&gt;&gt; cp = nltk.RegexpParser(grammar)
&gt;&gt;&gt; print(cp.evaluate(test_sents))
ChunkParse score:
    IOB Accuracy:  87.7%
    Precision:     70.6%
    Recall:        67.8%
    F-Measure:     69.2%</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Как вы можете видеть, этот подход позволяет достичь приличных результатов.  Однако мы можем улучшить его, приняв более ориентированный на данные подход, где мы используем учебный корпус, чтобы найти метки группировки (<tt class="doctest"><span class="pre">I</span></tt>, <tt class="doctest"><span class="pre">O</span></tt> или <tt class="doctest"><span class="pre">В</span></tt>), которые наиболее вероятны для каждой метки части речи.  Другими словами, мы можем построить группировкщик с помощью <em>юниграмм разметчика</em> (<a class="reference external" href="http://www.nltk.org/book/ch05.html#sec-automatic-tagging">4</a>).
Но вместо того, чтобы пытаться определить правильную метку части речи для каждого слова, мы пытаемся определить правильную метку группировки для данной метки части речи каждого слова.</p>
<p>В разделе <a class="reference internal" href="http://www.nltk.org/book/ch07.html#code-unigram-chunker">3.1</a> мы определяем класс <tt class="doctest"><span class="pre">UnigramChunker</span></tt>, который использует юниграмм разметчик для разметки предложений с группировочными метками.  Большая часть кода в этом классе используется просто для преобразования туда и обратно между представлением группировки в виде древа, используемым интерфейсом NLTK <tt class="doctest"><span class="pre">ChunkParserI</span></tt>, и IOB представлением, используемым встроенным разметчиком.
Класс определяет два метода: конструктор <a class="reference internal" href="http://www.nltk.org/book/ch07.html#code-unigram-chunker-constructor"><span id="ref-code-unigram-chunker-constructor"><img class="callout" alt="[1]" src="http://www.nltk.org/book/callouts/callout1.gif"></span></a>, который вызывается, когда мы строим новый UnigramChunker; и метод <tt class="doctest"><span class="pre">parse</span></tt> <a class="reference internal" href="http://www.nltk.org/book/ch07.html#code-unigram-chunker-parse"><span id="ref-code-unigram-chunker-parse"><img class="callout" alt="[3]" src="http://www.nltk.org/book/callouts/callout3.gif"></span></a>, который используется для группировки новых предложений.</p>
<span class="target" id="code-unigram-chunker"></span><div class="pylisting">
<table border="0" cellpadding="0" cellspacing="0" class="pylisting" width="95%">
<tr><td class="codeblock">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_codeblock_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
class UnigramChunker(nltk.ChunkParserI):
    def __init__(self, train_sents): 
        train_data = [[(t,c) for w,t,c in nltk.chunk.tree2conlltags(sent)]
                      for sent in train_sents]
        self.tagger = nltk.UnigramTagger(train_data) 

    def parse(self, sentence): 
        pos_tags = [pos for (word,pos) in sentence]
        tagged_pos_tags = self.tagger.tag(pos_tags)
        chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]
        conlltags = [(word, pos, chunktag) for ((word,pos),chunktag)
                     in zip(sentence, chunktags)]
        return nltk.chunk.conlltags2tree(conlltags)</pre>
</td>
</tr></table></td></tr>
<tr><td class="caption"><p class="caption"><a class="reference external" href="http://www.nltk.org/book/pylisting/code_unigram_chunker.py" type="text/x-python"><span class="caption-label">Пример 3.1 (code_unigram_chunker.py)</span></a> : <span class="caption-label">Листинг 3.1</span>: Группировка именных фраз с помощью Юниграмм Разметчика</p></td></tr>
</table></div>
<p>Конструктор <a class="reference internal" href="http://www.nltk.org/book/ch07.html#code-unigram-chunker-constructor"><img class="callout" alt="[1]" src="http://www.nltk.org/book/callouts/callout1.gif"></a> класса ожидает список тренировочных предложений в форме группировочных деревьев.  Сначала он преобразует обучающие данные в форму, которая подходит для обучения разметчика с помощью <tt class="doctest"><span class="pre">tree2conlltags</span></tt> для отображения каждого группировочного древа в список троек <tt class="doctest"><span class="pre">слов, метка, группировка</span></tt>.  Затем он использует эти преобразованные данные для обучения юниграмм разметчика и сохраняет его в <tt class="doctest"><span class="pre">self.tagger</span></tt> для последующего использования.</p>
<p>Метод <tt class="doctest"><span class="pre">parse</span></tt> <a class="reference internal" href="http://www.nltk.org/book/ch07.html#code-unigram-chunker-parse"><img class="callout" alt="[3]" src="http://www.nltk.org/book/callouts/callout3.gif"></a> принимает помеченное предложение в качестве входных данных и начинает с извлечения меток частей речи из этого предложения.  Затем он помечает метки частей речи группировочными метками IOB с помощью <tt class="doctest"><span class="pre">self.tagger</span></tt> разметчика, который был обучен в конструкторе.  Затем он извлекает метки группировки и соединяет их с первоначальным предложением, чтобы получить <tt class="doctest"><span class="pre">conlltags</span></tt>.  И, наконец, он использует <tt class="doctest"><span class="pre">conlltags2tree</span></tt>, чтобы преобразовать результат обратно в древо группировки.</p>
<p>Теперь, когда мы имеем <tt class="doctest"><span class="pre">UnigramChunker</span></tt>, мы можем обучить его с помощью  корпуса CoNLL 2000 и проверить его итоговую результативность:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; test_sents = conll2000.chunked_sents('test.txt', chunk_types=['NP'])
&gt;&gt;&gt; train_sents = conll2000.chunked_sents('train.txt', chunk_types=['NP'])
&gt;&gt;&gt; unigram_chunker = UnigramChunker(train_sents)
&gt;&gt;&gt; print(unigram_chunker.evaluate(test_sents))
ChunkParse score:
    IOB Accuracy:  92.9%
    Precision:     79.9%
    Recall:        86.8%
    F-Measure:     83.2%</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Этот группировщик показывает хорошие результаты, достигая общей f-меры 83%.  Давайте посмотрим на то, что он узнал с помощью своего юниграмм разметчика, чтобы присвоить метку каждой метки части речи в корпусе:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; postags = sorted(set(pos for sent in train_sents
...                      for (word,pos) in sent.leaves()))
&gt;&gt;&gt; print(unigram_chunker.tagger.tag(postags))
[('#', 'B-NP'), ('$', 'B-NP'), ("''", 'O'), ('(', 'O'), (')', 'O'),
 (',', 'O'), ('.', 'O'), (':', 'O'), ('CC', 'O'), ('CD', 'I-NP'),
 ('DT', 'B-NP'), ('EX', 'B-NP'), ('FW', 'I-NP'), ('IN', 'O'),
 ('JJ', 'I-NP'), ('JJR', 'B-NP'), ('JJS', 'I-NP'), ('MD', 'O'),
 ('NN', 'I-NP'), ('NNP', 'I-NP'), ('NNPS', 'I-NP'), ('NNS', 'I-NP'),
 ('PDT', 'B-NP'), ('POS', 'B-NP'), ('PRP', 'B-NP'), ('PRP$', 'B-NP'),
 ('RB', 'O'), ('RBR', 'O'), ('RBS', 'B-NP'), ('RP', 'O'), ('SYM', 'O'),
 ('TO', 'O'), ('UH', 'O'), ('VB', 'O'), ('VBD', 'O'), ('VBG', 'O'),
 ('VBN', 'O'), ('VBP', 'O'), ('VBZ', 'O'), ('WDT', 'B-NP'),
 ('WP', 'B-NP'), ('WP$', 'B-NP'), ('WRB', 'O'), ('``', 'O')]</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Он обнаружил, что большинство знаков препинания находятся вне NP группировок за исключением символов <tt class="doctest"><span class="pre"><span class="pysrc-comment">#</span></span></tt> и <tt class="doctest"><span class="pre">$</span></tt>, оба из которых используются в качестве маркеров валюты.  Он также установил, что определители <tt class="doctest"><span class="pre">(DT)</span></tt> и притяжательные (<tt class="doctest"><span class="pre">PRP$</span></tt> и <tt class="doctest"><span class="pre">$WP</span></tt>) возникают в начале NP группировок, в то время как именные типы (<tt class="doctest"><span class="pre">NN</span></tt>, <tt class="doctest"><span class="pre">NNP</span></tt>, <tt class="doctest"><span class="pre">NNPS</span></tt>, <tt class="doctest"><span class="pre">NNS</span></tt>) в основном возникают внутри NP группировок.</p>
<!-- Commented out because we use it but don&#39;t bother to define it in
the text of the book, since it&#39;s trivial:

>>> class BigramChunker(nltk.ChunkParserI):
...     def __init__(self, train_sents):
...         train_data = [[(t,c) for w,t,c in nltk.chunk.tree2conlltags(sent)]
...                       for sent in train_sents]
...         self.tagger = nltk.BigramTagger(train_data)
...
...     def parse(self, sentence):
...         pos_tags = [pos for (word,pos) in sentence]
...         tagged_pos_tags = self.tagger.tag(pos_tags)
...         chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]
...         conlltags = [(word, pos, chunktag) for ((word,pos),chunktag)
...                      in zip(sentence, chunktags)]
...         return nltk.chunk.conlltags2tree(conlltags) -->
<p>Построив юниграмм группировщик, довольно легко построить биграмм группировщик: мы просто изменяем имя класса <tt class="doctest"><span class="pre">BigramChunker</span></tt> и изменяем строку <a class="reference internal" href="http://www.nltk.org/book/ch07.html#code-unigram-chunker-buildit"><span id="ref-code-unigram-chunker-buildit"><img class="callout" alt="[2]" src="http://www.nltk.org/book/callouts/callout2.gif"></span></a> в <a class="reference internal" href="http://www.nltk.org/book/ch07.html#code-unigram-chunker">3.1</a>, чтобы построить <tt class="doctest"><span class="pre">BigramTagger</span></tt>, а не <tt class="doctest"><span class="pre">UnigramTagger</span></tt>.
Полученный группировщик имеет несколько более высокую результативность, чем юниграмм группировщик:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; bigram_chunker = BigramChunker(train_sents)
&gt;&gt;&gt; print(bigram_chunker.evaluate(test_sents))
ChunkParse score:
    IOB Accuracy:  93.3%
    Precision:     82.3%
    Recall:        86.8%
    F-Measure:     84.5%</pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="training-classifier-based-chunkers">
<h2>3.3 Обучение группировщиков на основе классификатора </h2>
<p>Оба типа группировщиков - на основе регулярных выражений и n-грамм - решают, какие куски создать, полностью на основе меток частей речи.
Однако иногда метки части речи недостаточны для определения того, каким образом следует сгруппировать предложение.
Например, рассмотрим следующие два утверждения:</p>
<p><table border="0" cellpadding="0" cellspacing="0" class="example">
  <tr valign="top"><td width="30" align="right">(3)</td><td width="15"></td><td><p><table border="0" cellpadding="0" cellspacing="0" class="example">
  <tr valign="top"><td width="30" align="right">a.</td><td width="15"></td><td>Joey/NN sold/VBD the/DT farmer/NN rice/NN ./.</td></tr></table></p>
<p><table border="0" cellpadding="0" cellspacing="0" class="example">
  <tr valign="top"><td width="30" align="right">b.</td><td width="15"></td><td>Nick/NN broke/VBD my/DT computer/NN monitor/NN ./.
</td></tr></table></p>
</td></tr></table></p>
<p>Эти два предложения имеют те же метки части речи, но они по-разному сгруппированы.  В первом предложении <span class="example">the farmer</span> и <span class="example">rice</span> являются отдельными группировками, в то время как соответствующий материал во втором предложении, <span class="example">the computer monitor</span>, единая группировка.  Ясно, что мы должны использовать информацию о содержании слов в дополнение к их меткам части речи, если мы хотим максимизировать результативность группировки.</p>
<p>Один из способов включить информацию о содержании слов - использовать разметчик на классификатора для группировки предложения.  Как и n-грамм группировщик, рассмотренный в предыдущем разделе, этот группировщик на основе классификатора будет работать присваивать IOB метки словам в предложении, а затем преобразует их в группировки.  Для самого разметчика на основе классификатора мы будем использовать тот же подход, который мы использовали в <a class="reference external" href="http://www.nltk.org/book/ch06.html#sec-supervised-classification">1</a>, чтобы построить разметчик частей речи.</p>
<p>Основной код NP группировщика на основе классификатора показан в листинге <a class="reference internal" href="http://www.nltk.org/book/ch07.html#code-classifier-chunker">3.2</a>.  Он состоит из двух классов.  Первый класс <a class="reference internal" href="http://www.nltk.org/book/ch07.html#consec-chunk-tagger"><span id="ref-consec-chunk-tagger"><img class="callout" alt="[1]" src="http://www.nltk.org/book/callouts/callout1.gif"></span></a> практически идентичен классу <tt class="doctest"><span class="pre">ConsecutivePosTagger</span></tt> из <a class="reference external" href="http://www.nltk.org/book/ch06.html#code-consecutive-pos-tagger">1.5</a>.
Единственные два отличия заключаются в том, что он вызывает другой экстрактор свойств <a class="reference internal" href="http://www.nltk.org/book/ch07.html#consec-use-fe"><span id="ref-consec-use-fe"><img class="callout" alt="[2]" src="http://www.nltk.org/book/callouts/callout2.gif"></span></a> и что он использует MaxentClassifier, а не NaiveBayesClassifier <a class="reference internal" href="http://www.nltk.org/book/ch07.html#consec-use-maxent"><span id="ref-consec-use-maxent"><img class="callout" alt="[3]" src="http://www.nltk.org/book/callouts/callout3.gif"></span></a>.  Второй класс <a class="reference internal" href="http://www.nltk.org/book/ch07.html#consec-chunker"><span id="ref-consec-chunker"><img class="callout" alt="(4)" src="http://www.nltk.org/book/callouts/callout4.gif"></span></a> в основе своей оборачивает класс разметчика, что превращает его в группировщик.  Во время обучения этот второй класс отображает деревья группировки в учебном корпусе на последовательности меток; в методе <tt class="doctest"><span class="pre">parse()</span></tt> он преобразует последовательность меток, представленную разметчиком, обратно в дерево группировки.</p>
<span class="target" id="code-classifier-chunker"></span><div class="pylisting">
<table border="0" cellpadding="0" cellspacing="0" class="pylisting" width="95%">
<tr><td class="codeblock">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_codeblock_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
class ConsecutiveNPChunkTagger(nltk.TaggerI): 

    def __init__(self, train_sents):
        train_set = []
        for tagged_sent in train_sents:
            untagged_sent = nltk.tag.untag(tagged_sent)
            history = []
            for i, (word, tag) in enumerate(tagged_sent):
                featureset = npchunk_features(untagged_sent, i, history) 
                train_set.append( (featureset, tag) )
                history.append(tag)
        self.classifier = nltk.MaxentClassifier.train( 
            train_set, algorithm='megam', trace=0)

    def tag(self, sentence):
        history = []
        for i, word in enumerate(sentence):
            featureset = npchunk_features(sentence, i, history)
            tag = self.classifier.classify(featureset)
            history.append(tag)
        return zip(sentence, history)

class ConsecutiveNPChunker(nltk.ChunkParserI): 
    def __init__(self, train_sents):
        tagged_sents = [[((w,t),c) for (w,t,c) in
                         nltk.chunk.tree2conlltags(sent)]
                        for sent in train_sents]
        self.tagger = ConsecutiveNPChunkTagger(tagged_sents)

    def parse(self, sentence):
        tagged_sents = self.tagger.tag(sentence)
        conlltags = [(w,t,c) for ((w,t),c) in tagged_sents]
        return nltk.chunk.conlltags2tree(conlltags)</pre>
</td>
</tr></table></td></tr>
<tr><td class="caption"><p class="caption"><a class="reference external" href="http://www.nltk.org/book/pylisting/code_classifier_chunker.py" type="text/x-python"><span class="caption-label">Пример 3.2 (code_classifier_chunker.py)</span></a>: <span class="caption-label">Листинг 3.2</span>: Группировка именных фраз с помощью последовательного классификатора</p></td></tr>
</table></div>
<!-- Pre-load megam, so we won&#39;t get random trace output when it&#39;s loaded:
>>> nltk.classify.config_megam()
[Found megam: ...] -->
<p>Единственный пробел, который осталось заполнить, - это экстрактор свойств.  Мы начнем с определения простого экстрактора свойств, который просто предоставляет метку части речи для текущего токена.  С этим экстрактором свойств наш группировщик на основе классификатора очень похож на юниграмм группировщик, что отражается в его работе:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; def npchunk_features(sentence, i, history):
...     word, pos = sentence[i]
...     return {"pos": pos}
&gt;&gt;&gt; chunker = ConsecutiveNPChunker(train_sents)
&gt;&gt;&gt; print(chunker.evaluate(test_sents))
ChunkParse score:
    IOB Accuracy:  92.9%
    Precision:     79.9%
    Recall:        86.7%
    F-Measure:     83.2%</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Мы можем также добавить свойство для предыдущей метки части речи.  Добавление этого свойства позволяет классификатору моделировать взаимодействие между соседними метками, и в результате получается группировщик, который тесно связан с биграмм группировщиком.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; def npchunk_features(sentence, i, history):
...     word, pos = sentence[i]
...     if i == 0:
...         prevword, prevpos = "&lt;START&gt;", "&lt;START&gt;"
...     else:
...         prevword, prevpos = sentence[i-1]
...     return {"pos": pos, "prevpos": prevpos}
&gt;&gt;&gt; chunker = ConsecutiveNPChunker(train_sents)
&gt;&gt;&gt; print(chunker.evaluate(test_sents))
ChunkParse score:
    IOB Accuracy:  93.6%
    Precision:     81.9%
    Recall:        87.2%
    F-Measure:     84.5%</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Далее мы попробуем добавить свойство для текущего слова, так как мы предположили, что содержание слова должно быть полезным для группировки.  Мы находим, что это свойство действительно улучшает производительность группировщика примерно на 1,5 процентных пункта (что соответствует снижении частоты ошибок на 10%).</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; def npchunk_features(sentence, i, history):
...     word, pos = sentence[i]
...     if i == 0:
...         prevword, prevpos = "&lt;START&gt;", "&lt;START&gt;"
...     else:
...         prevword, prevpos = sentence[i-1]
...     return {"pos": pos, "word": word, "prevpos": prevpos}
&gt;&gt;&gt; chunker = ConsecutiveNPChunker(train_sents)
&gt;&gt;&gt; print(chunker.evaluate(test_sents))
ChunkParse score:
    IOB Accuracy:  94.5%
    Precision:     84.2%
    Recall:        89.4%
    F-Measure:     86.7%</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>И, наконец, мы можем попытаться расширить экстрактор свойств с помощью различных дополнительных свойств, такими как предпросмотровые свойства<a class="reference internal" href="http://www.nltk.org/book/ch07.html#chunk-fe-lookahead"><span id="ref-chunk-fe-lookahead"><img class="callout" alt="[1]" src="http://www.nltk.org/book/callouts/callout1.gif"></span></a>, парные свойства <a class="reference internal" href="http://www.nltk.org/book/ch07.html#chunk-fe-paired"><span id="ref-chunk-fe-paired"><img class="callout" alt="[2]" src="http://www.nltk.org/book/callouts/callout2.gif"></span></a> и сложные контекстные свойства <a class="reference internal" href="http://www.nltk.org/book/ch07.html#chunk-fe-complex"><span id="ref-chunk-fe-complex"><img class="callout" alt="[3]" src="http://www.nltk.org/book/callouts/callout3.gif"></span></a>.  Это последнее свойство, называемое <tt class="doctest"><span class="pre">tags-since-dt</span></tt>, создает строку, описывающую набор всех меток части речи, которые встретились с последнего определителя или с начала предложения, если перед индексом <tt class="doctest"><span class="pre">i</span></tt> нет определителя.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; def npchunk_features(sentence, i, history):
...     word, pos = sentence[i]
...     if i == 0:
...         prevword, prevpos = "&lt;START&gt;", "&lt;START&gt;"
...     else:
...         prevword, prevpos = sentence[i-1]
...     if i == len(sentence)-1:
...         nextword, nextpos = "&lt;END&gt;", "&lt;END&gt;"
...     else:
...         nextword, nextpos = sentence[i+1]
...     return {"pos": pos,
...             "word": word,
...             "prevpos": prevpos,
...             "nextpos": nextpos, 
...             "prevpos+pos": "%s+%s" % (prevpos, pos),  
...             "pos+nextpos": "%s+%s" % (pos, nextpos),
...             "tags-since-dt": tags_since_dt(sentence, i)}   <a name="chunk-fe-complex"></a><a href="http://www.nltk.org/book/ch07.html#ref-chunk-fe-complex"><img src="http://www.nltk.org/book/callouts/callout3.gif" alt="[3]" class="callout"></a></pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; def tags_since_dt(sentence, i):
...     tags = set()
...     for word, pos in sentence[:i]:
...         if pos == 'DT':
...             tags = set()
...         else:
...             tags.add(pos)
...     return '+'.join(sorted(tags))</pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; chunker = ConsecutiveNPChunker(train_sents)
&gt;&gt;&gt; print(chunker.evaluate(test_sents))
ChunkParse score:
    IOB Accuracy:  96.0%
    Precision:     88.6%
    Recall:        91.0%
    F-Measure:     89.8%</pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="note">
<p class="first admonition-title">Замечание</p>
<p class="last"><strong>Ваша очередь:</strong> 
Попробуйте добавить различные свойства к экстрактору свойств  <tt class="doctest"><span class="pre">npchunk_features</span></tt> и посмотреть, сможете ли вы еще повысить результативность NP группировщика.</p>
</div>
</div>
</div>
<div class="section" id="recursion-in-linguistic-structure">
<span id="sec-recursion-in-linguistic-structure"></span><h1>4 Рекурсия в лингвистической структуре</h1>
<div class="section" id="building-nested-structure-with-cascaded-chunkers">
<h2>4.1 Построение вложенной структуры с помощью каскадных группировщиков</h2>
<p>До сих пор наши структуры группировки были относительно плоскими.  Деревья состоят из помеченных токенов, опционально (необязательно) сгруппированных под узлом группировки, таким как <tt class="doctest"><span class="pre">NP</span></tt>.  Однако можно построить структуры группировки произвольной глубины просто путем создания многоступенчатой грамматики группировки, содержащей рекурсивные правила.  <a class="reference internal" href="http://www.nltk.org/book/ch07.html#code-cascaded-chunker">4.1</a> имеет шаблоны для именных фраз, предложных фраз, глагольных фраз и предложений.
Это четырехступенчатая грамматика группировки, она может быть использована для создания структур, имеющих глубину не более четырех уровней.</p>
<!-- I changed this example grammar to use "CLAUSE" rather than "S",
since there&#39;s an "S" node that&#39;s automatically supplied by the
chunk parser.  And the fact that we have these two different "S"
nodes is confusing. -->
<span class="target" id="code-cascaded-chunker"></span><div class="pylisting">
<table border="0" cellpadding="0" cellspacing="0" class="pylisting" width="95%">
<tr><td class="codeblock">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_codeblock_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
Грамматика = г <span class="pysrc-string">"" <span class="pysrc-string">"НП:</span></span> <span class="pysrc-string">{&lt;DT | JJ | NN *.&gt; +} # Chunk последовательности DT, JJ, NN</span> <span class="pysrc-string">PP: {&lt;В&gt; &lt;NP&gt;} # Chunk предлоги следуют NP</span> <span class="pysrc-string">VP: {&lt;VB . *&gt; &lt;NP | PP | условие&gt; + $} # Chunk глаголы и их аргументы</span> <span class="pysrc-string">ОГОВОРКА: {&lt;NP&gt; &lt;VP&gt;} # Кусок NP, VP</span> <span class="pysrc-string">"" "ф</span> = NLTK.RegexpParser (грамматика) предложение = [( <span class="pysrc-string">"Мария",</span> <span class="pysrc-string">"НН"),</span> ( <span class="pysrc-string">"пила",</span> <span class="pysrc-string">"ВБД"),</span> ( далее <span class="pysrc-string">"",</span> <span class="pysrc-string">"DT"),</span> ( <span class="pysrc-string">"кошка",</span> <span class="pysrc-string">"НН"),</span> ( <span class="pysrc-string">"сидеть <span class="pysrc-string">","</span></span> <span class="pysrc-string">VB "),</span> <span class="pysrc-string">(" на <span class="pysrc-string">","</span></span> <span class="pysrc-string">IN "),</span> ( далее <span class="pysrc-string">" <span class="pysrc-string">","</span></span> <span class="pysrc-string">DT "),</span> <span class="pysrc-string">(" мат <span class="pysrc-string">","</span></span> <span class="pysrc-string">NN ")]</span></pre>
</td>
</tr></table></td></tr>
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt;</span> <span class="pysrc-keyword">Печать</span> (cp.parse (предложение)) <span class="pysrc-output">(S</span> <span class="pysrc-output">(NP Mary / NN)</span> <span class="pysrc-output">видел / ВБД</span> <span class="pysrc-output">(ПУНКТА</span> <span class="pysrc-output">(Н.П. / DT кот / NN)</span> <span class="pysrc-output">(VP сидеть / VB (PP / в (NP мат / DT / NN)))))</span></pre>
</td>
</tr></table></td></tr>
<tr><td class="caption"><p class="caption"><a class="reference external" href="http://www.nltk.org/book/pylisting/code_cascaded_chunker.py" type="text/x-python"><span class="caption-label">Пример 4.1 (code_cascaded_chunker.py)</span></a>: <span class="caption-label">Листинг 4.1</span>: Группировщик, который обрабатывает NP, PP, VP и S</p></td></tr>
</table></div>
<p>К сожалению, этот результат пропускает <tt class="doctest"><span class="pre">VP</span></tt> с корневым <span class="example">saw</span>.  Он также имеет и другие недостатки.  Давайте посмотрим, что произойдет, когда мы применим этот группировщик к предложению, имеющему более глубокую вложенность.  Обратите внимание на то, что он не в состоянии идентифицировать <tt class="doctest"><span class="pre">VP</span></tt> группировку, начинающуюся на <a class="reference internal" href="http://www.nltk.org/book/ch07.html#saw-vbd"><span id="ref-saw-vbd"><img class="callout" alt="[1]" src="http://www.nltk.org/book/callouts/callout1.gif"></span></a>.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; sentence = [("John", "NNP"), ("thinks", "VBZ"), ("Mary", "NN"),
...     ("saw", "VBD"), ("the", "DT"), ("cat", "NN"), ("sit", "VB"),
...     ("on", "IN"), ("the", "DT"), ("mat", "NN")]
&gt;&gt;&gt; print(cp.parse(sentence))
(S
  (NP John/NNP)
  thinks/VBZ
  (NP Mary/NN)
  saw/VBD # [_saw-vbd]
  (CLAUSE
    (NP the/DT cat/NN)
    (VP sit/VB (PP on/IN (NP the/DT mat/NN)))))</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Решение этих проблем заключается в том, чтобы заставить группировщик циклически обрабатывать свои паттерны: после того, как он попробует все из них, он повторяет процесс.
Добавим второй необязательный аргумент <tt class="doctest"><span class="pre">loop</span></tt>, чтобы определить, сколько раз набор шаблонов должны быть пройден:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; cp = nltk.RegexpParser(grammar, loop=2)
&gt;&gt;&gt; print(cp.parse(sentence))
(S
  (NP John/NNP)
  thinks/VBZ
  (CLAUSE
    (NP Mary/NN)
    (VP
      saw/VBD
      (CLAUSE
        (NP the/DT cat/NN)
        (VP sit/VB (PP on/IN (NP the/DT mat/NN)))))))</pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="note">
<p class="first admonition-title">Замечание</p>
<p class="last">Этот каскадный процесс позволяет создавать глубокие структуры.  Однако создание и отладка каскада является трудной задачей, и наступает момент, когда более эффективно будет сделать полный синтаксический анализ (см. <a class="reference external" href="http://www.nltk.org/book/ch08.html#chap-parse">8.</a>).
Кроме того, каскадный процесс может производить только деревья фиксированной глубины (не глубже, чем число стадий в каскаде), а этого недостаточно для полного синтаксического анализа.</p>
</div>
</div>
<div class="section" id="trees">
<h2>4.2 Деревья</h2>
<p><a name="tree_index_term"></a><span class="termdef">Дерево</span> представляет собой набор соединенных узлов с метками, каждый из которых можно достичь по уникальному пути от известного корневого узла.  Вот пример дерева (обратите внимание, что стандартно они рисуются верхом вниз):</p>
<p><table border="0" cellpadding="0" cellspacing="0" class="example">
  <tr valign="top"><td width="30" align="right">(4)</td><td width="15"></td><td><img alt="tree_images / CH07-дерево-3.png" class="align-top" src="http://www.nltk.org/book/tree_images/ch07-tree-3.png" style="width:211.0px;height:185.0px"></td></tr></table></p>
<p>Мы используем "семейную" метафору, чтобы говорить о взаимоотношениях узлов в дереве: например, <tt class="doctest"><span class="pre">S</span></tt> является <a name="parent_index_term"></a><span class="termdef">родителем</span> <tt class="doctest"><span class="pre">VP</span></tt>; и наоборот <tt class="doctest"><span class="pre">VP</span></tt> является <a name="child_index_term"></a><span class="termdef">ребенок</span> <tt class="doctest"><span class="pre">S</span></tt>.  Кроме того, поскольку <tt class="doctest"><span class="pre">NP</span></tt> и <tt class="doctest"><span class="pre">VP</span></tt> являются детьми <tt class="doctest"><span class="pre">S</span></tt>, они также <a name="siblings_index_term"></a><span class="termdef">братья и сестры</span>.
Для удобства есть также текстовый формат для определения деревьев:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
(S
   (NP Alice)
   (VP
      (V chased)
      (NP
         (Det the)
         (N rabbit))))</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Несмотря на то, что мы сосредоточимся на синтаксических деревьях, деревья могут быть использованы для кодирования <span class="emphasis">любой</span> гомогенный иерархической структуры, которая охватывает последовательность языковых форм (например, морфологическая структура, дискурсионная структура).
В общем случае значения листьев и узлов не должны быть строками.</p>
<p>В NLTK мы создаем дерево, передавая метку узла и список детей:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; tree1 = nltk.Tree('NP', ['Alice'])
&gt;&gt;&gt; print(tree1)
(NP Alice)
&gt;&gt;&gt; tree2 = nltk.Tree('NP', ['the', 'rabbit'])
&gt;&gt;&gt; print(tree2)
(NP the rabbit)</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Мы можем включить это древо в более крупные деревья следующим образом:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; tree3 = nltk.Tree('VP', ['chased', tree2])
&gt;&gt;&gt; tree4 = nltk.Tree('S', [tree1, tree3])
&gt;&gt;&gt; print(tree4)
(S (NP Alice) (VP chased (NP the rabbit)))</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Вот некоторые из методов дерева как объекта:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; print(tree4[1])
(VP chased (NP the rabbit))
&gt;&gt;&gt; tree4[1].label()
'VP'
&gt;&gt;&gt; tree4.leaves()
['Alice', 'chased', 'the', 'rabbit']
&gt;&gt;&gt; tree4[1][1][1]
'rabbit'</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Представление сложных деревьев с помощью квадратных скобок может быть трудно читать.
В этих случаях метод <tt class="doctest"><span class="pre">draw</span></tt> может быть очень полезным.
Он открывает новое окно, содержащее графическое представление дерева.  Окно отображения дерева позволяет увеличивать и уменьшать масштаб, сворачивать и разворачивать узлы и распечатать графическое представление в постскрипт файл (для включения в документ).</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; tree3.draw()                           </pre>
</td>
</tr></table></td></tr>
</table></div>
<img alt="../images/parse_draw.png" src="http://www.nltk.org/images/parse_draw.png" style="width:191.79999999999998px;height:176.39999999999998px">
</div>
<div class="section" id="tree-traversal">
<h2>4.3 Обход дерева</h2>
<p>Использование рекурсивной функции для обхода дерева является стандартом.
Листинг <a class="reference internal" href="http://www.nltk.org/book/ch07.html#code-traverse">4.2</a> демонстрирует это.</p>
<span class="target" id="code-traverse"></span><div class="pylisting">
<table border="0" cellpadding="0" cellspacing="0" class="pylisting" width="95%">
<tr><td class="codeblock">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_codeblock_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
def traverse(t):
    try:
        t.label()
    except AttributeError:
        print(t, end=" ")
    else:
        # Now we know that t.node is defined
        print('(', t.label(), end=" ")
        for child in t:
            traverse(child)
        print(')', end=" ")

 &gt;&gt;&gt; t = nltk.Tree('(S (NP Alice) (VP chased (NP the rabbit)))')
 &gt;&gt;&gt; traverse(t)
 ( S ( NP Alice ) ( VP chased ( NP the rabbit ) ) )</pre>
</td>
</tr></table></td></tr>
<tr><td class="caption"><p class="caption"><a class="reference external" href="http://www.nltk.org/book/pylisting/code_traverse.py" type="text/x-python"><span class="caption-label">Пример 4.2 (code_traverse.py)</span></a>: <span class="caption-label">Рисунок 4.2</span>: Рекурсивная функция для обхода дерева</p></td></tr>
</table></div>
<div class="note">
<p class="first admonition-title">Замечание</p>
<p class="last">Мы использовали технику, называемую <a name="duck_typing_index_term"></a><span class="termdef">утиной типизацией</span>, чтобы обнаружить, что <tt class="doctest"><span class="pre">t</span></tt> является деревом (т.е. <tt class="doctest"><span class="pre">t.label()</span></tt> определено).</p>
</div>
</div>
</div>
<div class="section" id="named-entity-recognition">
<span id="sec-ner"></span><h1>5 Распознавание именованных объектов</h1>
<p>В начале этой главы мы кратко представили именованные объекты (ИО). Именованные объекты - это определенные именные фразы, которые относятся к конкретным типам индивидуальных объектов, таких, как организации, лица, даты и так далее. В таблице <a class="reference internal" href="http://www.nltk.org/book/ch07.html#tab-ne-types">5.1</a> перечислены некоторые из наиболее часто используемых типов ИО. Все они должны быть понятны, кроме "объект": антропогенные артефакты в областях архитектуры и гражданского строительства; и "ГПО": гео-политические объекты, такие как город, штат/провинция и страна.</p>
<span class="target" id="tab-ne-types"></span><table border="1" class="docutils" id="tab-ne-types">
<colgroup>
<col width="22%">
<col width="78%">
</colgroup>
<thead valign="bottom">
<tr><th class="head">Тип ИО</th>
<th class="head">Примеры</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>ОРГАНИЗАЦИЯ</td>
<td><span class="example">Georgia-Pacific Corp.,</span> <span class="example">ВОЗ</span></td>
</tr>
<tr><td>ЧЕЛОВЕК</td>
<td><span class="example">Эдди Бонт</span>, <span class="example">Президент Обама</span></td>
</tr>
<tr><td>МЕСТО</td>
<td><span class="example">река Мюррей</span>, <span class="example">гора Эверест</span></td>
</tr>
<tr><td>ДАТА</td>
<td><span class="example">Июнь</span>, <span class="example">2008-06-29</span></td>
</tr>
<tr><td>ВРЕМЯ</td>
<td><span class="example">два пятьдесят до полудня</span>, <span class="example">1:30 после полудня</span></td>
</tr>
<tr><td>ДЕНЬГИ</td>
<td><span class="example">175 миллионов канадских долларов</span>, <span class="example">GBP 10,40</span></td>
</tr>
<tr><td>ПРОЦЕНТ</td>
<td><span class="example">двадцать процентов</span>, <span class="example">18,75%</span></td>
</tr>
<tr><td>ОБЪЕКТ</td>
<td><span class="example">Монумент Вашингтона</span>, <span class="example">Стоунхендж</span></td>
</tr>
<tr><td>ГПО</td>
<td><span class="example">Юго-Восточная Азия</span>, <span class="example">Midlothian</span></td>
</tr>
</tbody>
<td><p class="caption"><span class="caption-label">Таблица 7.1</span>: <p>Широко используемые типы именованного объекта</p>
</p>
</td></table>
<p>Целью системы <a name="named_entity_recognition_index_term"></a><span class="termdef">распознания именованного объекта</span> (РИО) заключается в идентификации всех текстуальных упоминаний именованных объектов. Эта задача может быть разбита на две подзадачи: определение границ ИО и идентификация его типа.
Несмотря на то, что распознание именованных объектов часто является прелюдией к выявлению отношений в рамках задачи извлечения информации, оно также может способствовать решению других задач.  Например, в рамках задачи подготовки ответов на вопросы (QA), мы пытаемся улучшить точность поиска информации путем возвращения не целых страниц, а только тех частей, которые содержат ответ на вопрос пользователя. Большинство систем QA принимают документы, возвращенные стандартным поиском информации, а затем пытаются выделить минимальный фрагмент текста документа, содержащий ответ. Теперь предположим, что вопрос был: "<span class="example">Кто был первым президентом США?</span>" и один из документов, который был извлечен, содержал следующий отрывок:</p>
<p><table border="0" cellpadding="0" cellspacing="0" class="example">
  <tr valign="top"><td width="30" align="right">(5)</td><td width="15"></td><td>Монумент Вашингтона является наиболее известной структурой в Вашингтоне, округ Колумбия, и одной из первых достопримечательностей города.  Он был построен в честь Джорджа Вашингтона, который привел страну к независимости, а затем стал ее первым президентом.</td></tr></table></p>
<p>Анализ вопроса приводит нас предположению, что ответ должен иметь вид <span class="example">X был первым президентом США</span>, где <cite>Х</cite> представляет собой не только именную фразу, но также относится к именованному объекту типа ЧЕЛОВЕК. Это должно позволить нам игнорировать первое предложение в отрывке.  Немсмотря на то, что текст содержит два вхождения <span class="example">Вашингтона</span>, распознание именованного объекта должно сказать нам, что ни один из них не имеет правильный тип.</p>
<p>Как мы действуем при идентификации именованного объекта?  Одним из вариантов мог бы быть поиск каждого слова в соответствующем списке имен.
Например, в случае мест, мы могли бы использовать <a name="gazetteer_index_term"></a><span class="termdef">gazetter</span>, или географический словарь, такой как Alexandria Gazetteer или Getty Gazetteer.  Однако делать это вслепую значит столкнуться с проблемами, как показано на Рисунке <a class="reference internal" href="http://www.nltk.org/book/ch07.html#fig-locations">5.1</a>.</p>
<span class="target" id="fig-locations"></span><div class="figure" id="fig-locations">
<img alt="../images/locations.png" src="http://www.nltk.org/images/locations.png" style="width:498.0px;height:264.75px">
<p class="caption"><span class="caption-label">Рисунок 5.1:</span> Определение местоположения с помощью простого поиска для новой истории: Поиск каждого слова в геосправочнике подвержен ошибкам; различия регистра могут помочь, но они не всегда присутствуют.</p>
</div>
<p>Заметим, что gazetteer имеет хороший охват мест во многих странах и неправильно находит такие места, как Санчес в Доминиканской Республике и Он во Вьетнаме.
Конечно, мы могли бы пропустить такие места из Геосправочника, но тогда мы не сможем идентифицировать их, когда они появятся в документе.</p>
<p>Дело становится еще сложнее в случае имен людей или организаций.
Любой список таких имен, вероятно, имеет плохой охват. Новые организации возникают каждый день, так что если мы имеем дело с современной лентой новостей или записей в блоге, то вряд ли мы сможем распознать многие объекты с помощью поиска по геосправочнику.</p>
<p>Другим важным источником трудностей является то, что многие именованные объекты неоднозначны. Так <span class="example">May</span> и <span class="example">North</span>, вероятно, будут частями именованных объектов для типов ДАТА и МЕСТО соответственно, но оба могли быть частью ИО типа ЧЕЛОВЕК; и наоборот <span class="example">Christian Dior</span> выглядит как человек, но более вероятно, имеет тип ОРГАНИЗАЦИЯ. Такой термин, как <span class="example">Yankee</span>, будет обычным модификатором в некоторых контекстах, но во фразе <span class="example">Yankee Infielders</span> будет помечен как объект типа ОРГАНИЗАЦИЯ. </p>
<p>Дальнейшие проблемы возникают в связи с именами, состоящими из нескольких слов, как <span class="example">Стэнфордский университет{/0,} и именами, которые содержат другие имена, такие как <span class="example">Библиотека Cecil H. Green</span> и <span class="example">Сервисный центр конференции Escondido Village</span></span>. Поэтому в рамках распознания именованного объекта мы должны быть в состоянии определить начало и конец последовательностей из нескольких токенов.</p>
<p>Распознание именованного объекта является задачей, которая хорошо подходит к типу подхода на основе классификатора, который мы видели в группировке именных фраз.  В частности, мы можем построить разметчик, который помечает каждое слово в предложении с помощью IOB формата, в рамках которого группировки помечаются соответствующим типом.
Вот часть голландских обучающих данных CONLL 2002 <tt class="doctest"><span class="pre">(conll2002)</span></tt>:</p>
<pre class="literal-block">
Eddy N B-PER
Bonte N I-PER
is V O
woordvoerder N O
van Prep O
diezelfde Pron O
Hogeschool N B-ORG
. Punc O
</pre>
<p>В этом представлении на каждой строке один токен, каждый со своей меткой части речи и своей меткой именованного объекта.  На основе этого учебного корпуса, мы можем построить разметчик, который может использоваться для разметки новых предложений; и затем использовать функцию <tt class="doctest"><span class="pre">nltk.chunk.conlltags2tree()</span></tt> для преобразования последовательности меток в древо группировки.</p>
<p>NLTK предоставляет классификатор, который уже обучен распознавать именованные объекты, доступ к которому можно получить с помощью функции <tt class="doctest"><span class="pre">nltk.ne_chunk()</span></tt>.  Если мы установим параметр <tt class="doctest"><span class="pre">binary= True</span></tt> <a class="reference internal" href="http://www.nltk.org/book/ch07.html#binary-ne"><span id="ref-binary-ne"><img class="callout" alt="[1]" src="http://www.nltk.org/book/callouts/callout1.gif"></span></a>, то именованные объекты будут просто помечены как <tt class="doctest"><span class="pre">NE{</span></tt>/0;} в противном случае классификатор добавляет метки категорий, такие как PERSON, ORGANIZATION и GPE.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; sent = nltk.corpus.treebank.tagged_sents()[22]
&gt;&gt;&gt; print(nltk.ne_chunk(sent, binary=True)) 
(S
  The/DT
  (NE U.S./NNP)
  is/VBZ
  one/CD
  ...
  according/VBG
  to/TO
  (NE Brooke/NNP T./NNP Mossman/NNP)
  ...)</pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; print(nltk.ne_chunk(sent)) 
(S
  The/DT
  (GPE U.S./NNP)
  is/VBZ
  one/CD
  ...
  according/VBG
  to/TO
  (PERSON Brooke/NNP T./NNP Mossman/NNP)
  ...)</pre>
</td>
</tr></table></td></tr>
</table></div>
<!-- Overview of ACE here: http://www.nist.gov/speech/tests/ace/2000/doc/ace-tides00/ -->
<!-- Leaving this out: I don&#39;t see that we need it really.

.. XXX change to "the NE classifier is?

.. XXX the following wants a normal citation.  (Would we ever say that a
   book was not freely available, but that you could buy it from XYZ
   publisher?)

   Both chunkers are trained based on the ACE-2 corpus.  This
   corpus is not freely available, but a license to use the corpus can be
   purchased from the Linguistic Data Consortium (catalog id LDC2003T11). -->
</div>
<div class="section" id="relation-extraction">
<span id="sec-relextract"></span><h1>6 Извлечение отношения</h1>
<!-- XXX next para introduces regexp zero-width assertions -->
<p>После того, как именованные объекты были идентифицированы, мы захотим извлечь отношения, которые существуют между ними. Как указывалось выше, мы, как правило, будем искать отношения между указанными типами именованных объектов. Один из способов достижения этой задачи состоит в том, чтобы изначально искать все тройки вида (<em>X</em>, α, <em>Y</em>), где <em>X</em> и <em>Y</em> именованные объекты нужных типов, а α является строкой слов, которая располагается между <em>X</em> и <em>Y</em>.Затем мы можем использовать регулярные выражения, чтобы вытащить только те экземпляры α, которые выражают отношение, которое мы ищем. В следующем примере выполняется поиск строк, содержащих слово <span class="example">in</span>. Специальное регулярное выражение (<tt class="doctest"><span class="pre">?!\b.+ing\b</span></tt>) представляет отрицательное смотрящее вперед утверждение, которое позволяет игнорировать такие строки, как <span class="example">succes in supervising the transition of</span>, в которых за <span class="example">in</span> следует герундий.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; IN = re.compile(r'.*\bin\b(?!\b.+ing)')
&gt;&gt;&gt; for doc in nltk.corpus.ieer.parsed_docs('NYT_19980315'):
...     for rel in nltk.sem.extract_rels('ORG', 'LOC', doc,
...                                      corpus='ieer', pattern = IN):
...         print(nltk.sem.rtuple(rel))
[ORG: 'WHYY'] 'in' [LOC: 'Philadelphia']
[ORG: 'McGlashan &amp; Sarrail'] 'firm in' [LOC: 'San Mateo']
[ORG: 'Freedom Forum'] 'in' [LOC: 'Arlington']
[ORG: 'Brookings Institution'] ', the research group in' [LOC: 'Washington']
[ORG: 'Idealab'] ', a self-described business incubator based in' [LOC: 'Los Angeles']
[ORG: 'Open Text'] ', based in' [LOC: 'Waterloo']
[ORG: 'WGBH'] 'in' [LOC: 'Boston']
[ORG: 'Bastille Opera'] 'in' [LOC: 'Paris']
[ORG: 'Omnicom'] 'in' [LOC: 'New York']
[ORG: 'DDB Needham'] 'in' [LOC: 'New York']
[ORG: 'Kaplan Thaler Group'] 'in' [LOC: 'New York']
[ORG: 'BBDO South'] 'in' [LOC: 'Atlanta']
[ORG: 'Georgia-Pacific'] 'in' [LOC: 'Atlanta']</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Поиск ключевого слова <span class="example">in</span> работает достаточно хорошо, хотя он также будет возвращать ложные срабатывания, такие как <tt class="doctest"><span class="pre">[ORG: House
Transportation Committee] , secured the most money <span class="pysrc-keyword">in</span> the [LOC: New
York]</span></tt>; вряд ли есть простой строчный метод исключения строк-заполнителей, как эта.</p>
<!-- TODO fix processing of tagged corpora -->
<p>Как было показано выше, голландский корпус <tt class="doctest"><span class="pre">conll2002</span></tt> содержит не только аннотацию именованных объектов, но и разметку частей речи. Это позволяет разрабатывать модели, которые являются чувствительными к этим меткам, как показано в следующем примере. Метод <tt class="doctest"><span class="pre">clause()</span></tt> выводит отношения в клаузальной форме, где символ бинарного отношения указан как значение параметра <tt class="doctest"><span class="pre">relsym</span></tt> <a class="reference internal" href="http://www.nltk.org/book/ch07.html#relsym"><span id="ref-relsym"><img class="callout" alt="[1]" src="http://www.nltk.org/book/callouts/callout1.gif"></span></a>.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar" onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"> </td>
<td class="pysrc"><pre class="doctest">
&gt;&gt;&gt; from nltk.corpus import conll2002
&gt;&gt;&gt; vnv = """
... (
... is/V|    # 3rd sing present and
... was/V|   # past forms of the verb zijn ('be')
... werd/V|  # and also present
... wordt/V  # past of worden ('become)
... )
... .*       # followed by anything
... van/Prep # followed by van ('of')
... """
&gt;&gt;&gt; VAN = re.compile(vnv, re.VERBOSE)
&gt;&gt;&gt; for doc in conll2002.chunked_sents('ned.train'):
...     for r in nltk.sem.extract_rels('PER', 'ORG', doc,
...                                    corpus='conll2002', pattern=VAN):
...         print(nltk.sem.clause(r, relsym="VAN")) 
VAN("cornet_d'elzius", 'buitenlandse_handel')
VAN('johan_rottiers', 'kardinaal_van_roey_instituut')
VAN('annie_lennox', 'eurythmics')</pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="note">
<p class="first admonition-title">Замечание</p>
<p class="last"><strong>Ваша Очередь:</strong> 
Замените последнюю строку <a class="reference internal" href="http://www.nltk.org/book/ch07.html#relsym"><img class="callout" alt="[1]" src="http://www.nltk.org/book/callouts/callout1.gif"></a> на <tt class="doctest"><span class="pre"><span class="pysrc-keyword">print</span>(rtuple(rel, lcon=True, rcon=True))</span></tt>. Это покажет вам конкретные слова, которые располагаются между двумя ИО, а также их левый и правый контекст в пределах 10 слов (по умолчанию). С помощью голландского словаря вы могли бы выяснить, почему результат <tt class="doctest"><span class="pre">VAN(<span class="pysrc-string">'annie_lennox Леннок'</span>, <span class="pysrc-string">'eurythmics'</span>)</span></tt> является ложным.</p>
</div>
<!-- This is too weak to include:

Message Understanding
- - - - - - - - - - - - - - - - - - - - -

A message understanding system
will extract salient chunks of text from a news story and populate a
database.

.. figure:: ../images/chunk-muc.png
   :scale: 60

   The Message Understanding Process (from Abney 1996)

Consider the units that have been selected in this process:
a name (``Garcia Alvarado``), a verb cluster (``was killed``),
a locative prepositional phrase (``on his vehicle``).  These
are examples of ``NP``, ``VP`` and ``PP`` chunks. -->
<!-- XXX there shouldn&#39;t be a conclusion here, but a bulletted summary -->
</div>
<div class="section" id="summary">
<h1>4.9 Резюме</h1>
<ul class="simple">
<li>Системы извлечения информации осуществляют поиск конкретных типов объектов и отношений в больших корпусах неструктурированного текста и используют их для заполнения структурированных баз данных.  Эти базы данных могут быть использованы, чтобы найти ответы на конкретные вопросы.</li>
<li>Типичная архитектура системы извлечения информации начинается с сегментирования, токенизации и частеречной разметки текста.
В полученных данных затем осуществляется поиск определенных типов объектов.
И, наконец, система извлечения информации рассматривает объекты, которые упоминаются рядом друг с другом в тексте, и пытается определить, имеются ли определенные отношения между этими объектами.</li>
<li>Распознавание объектов часто осуществляется с помощью группировщиков, которые сегментируют последовательности из нескольких токенов и помечают их как соответствующий тип объекта.  Распространенные типы объектов включают в себя организации, людей, места, даты, время, деньги и ГПО.</li>
<li>Группировщики могут быть построены с использованием систем на основе правил, таких как класс NLTK <tt class="doctest"><span class="pre">RegexpParser</span></tt>; или с использованием методов машинного обучения, таких как <tt class="doctest"><span class="pre">ConsecutiveNPChunker</span></tt>, представленный в этой главе.  В любом случае метки части речи часто являются очень важным свойством при поиске группировок.</li>
<li>Хотя группировщики специализируются на создании относительно плоских структур данных, где не допускается перекрытие группировок, они могут быть объединены каскадно для построения вложенных структур.</li>
<li>Выделение связи может осуществляться либо с помощью систем, основанных на правилах, которые, как правило, ищут в тексте определенные закономерности, которые соединяют объекты и промежуточные слова; либо с помощью систем машинного обучения, которые обычно пытаются узнать такие закономерности автоматически из учебного корпуса.</li>
</ul>
</div>
<div class="section" id="further-reading">
<h1>7 Дополнительные материалы</h1>
<p>Дополнительные материалы для этой главы размещены на странице <tt class="doctest"><span class="pre">http://nltk.org/</span></tt>, в том числе ссылки на свободно доступные ресурсы в сети.
Для получения большего количества примеров группировки с помощью NLTK, обратитесь к HOWTO по группировке на <tt class="doctest"><span class="pre">http://nltk.org/howto.</span></tt></p>
<p>Популярность группировки - в значительной степени заслуга пионерской работы Abney, например, <a class="reference external" href="http://www.nltk.org/book/bibliography.html#abney1996pst" id="id1">(Church, Young, &amp; Bloothooft, 1996)</a>. Касс группировщик Abney описан в <tt class="doctest"><span class="pre">http://www.vinartus.net/spa/97a.pdf</span></tt>.</p>
<p>Слово <a name="chink_index_term_2"></a><span class="termdef">трещина (chink)</span> первоначально означало последовательность слов-исключений согласно статье 1975 Ross и Tukey <a class="reference external" href="http://www.nltk.org/book/bibliography.html#abney1996pst" id="id2">(Church, Young, &amp; Bloothooft, 1996)</a>.</p>
<p>Формат IOB (или иногда <a name="bio_format_index_term"></a><span class="termdef">BIO Format</span>) был разработан для <tt class="doctest"><span class="pre">NP</span></tt> группировки авторами <a class="reference external" href="http://www.nltk.org/book/bibliography.html#ramshaw1995tcu" id="id3">(Ramshaw &amp; Marcus, 1995)</a> и был использован для совместной работы над задачей <tt class="doctest"><span class="pre">NP</span></tt> группировки, которую осуществила <em>Конференция по изучению естественного языка</em> (CoNLL) в 1999 году.  Такой же формат был принят CoNLL 2000 для аннотирования части текста Wall Street Journal в рамках совместной работы над задачей <tt class="doctest"><span class="pre">NP</span></tt> группировки.</p>
<p>Раздел 13.5 <a class="reference external" href="http://www.nltk.org/book/bibliography.html#jurafskymartin2008" id="id4">(Jurafsky &amp; Martin, 2008)</a> содержит обсуждение группировки.
Глава 22 охватывает извлечение информации, в том числе распознание именованных объектов.
Для получения информации о разработке текста в биологии и медицине, см. <a class="reference external" href="http://www.nltk.org/book/bibliography.html#ananiadou2006" id="id5">(Ananiadou &amp; McNaught, 2006)</a>.</p>
<!-- Alexandria Gazetteer: http://www.alexandria.ucsb.edu/gazetteer -->
<!-- Getty Gazetteer -->
<!-- Other topics that use an IE approach: anaphora resolution -->
<!-- [Mitkov2002]_, question answering [Pasca2003]_. -->
</div>
<div class="section" id="exercises">
<h1>9 Упражнения</h1>
<ol class="arabic simple">
<li>☼ Формат IOB классифицирует помеченных как маркеры <tt class="doctest"><span class="pre">I,</span></tt> <tt class="doctest"><span class="pre">O</span></tt> и <tt class="doctest"><span class="pre">B.</span></tt>  Почему необходимы три метки?  Какая проблема будет вызвана , если мы использовали теги <tt class="doctest"><span class="pre">ввода</span></tt> и <tt class="doctest"><span class="pre">вывода</span></tt> исключительно?</li>
<li>☼ Написать образец тега, чтобы соответствовать существительного фраз, содержащих падежах головы, например, "много / JJ исследователи / NNS", "две недели / CD / NNS", "как / DT новый / JJ позиций / NNS".
Попробуйте сделать это обобщающее шаблон тега, который обрабатывается существительное в единственном числе фразы.</li>
<li>☼ Выберите один из трех типов фрагмента в корпусе CoNLL.
Осмотрите корпус CoNLL и стараться соблюдать какие-либо закономерности в теге последовательностей POS, которые составляют этот вид кусок.  Разработка простого Chunker с использованием регулярных выражений Chunker <tt class="doctest"><span class="pre">NLTK.RegexpParser.</span></tt>
Если любой из этих тегов последовательностей, которые трудно кусок надежно.</li>
<li>☼ Раннее определение <em>кусок</em> был материал , который происходит между скважинами.
Разработка Chunker, которая начинается, помещая целое предложение в один блок, а затем делает остальную часть своей работы исключительно позвякивая.
Определите, какие теги (или тег последовательности), скорее всего, составляют скважины с помощью вашей собственной полезной программы.  Сравните производительность и простоту этого подхода по отношению к Chunker полностью основанной на правилах куска.</li>
<li>◑ Написать шаблон тега, чтобы покрыть существительного фразы, которые содержат герундии, например, "/ DT приема / VBG конца / НН", "помощник / Н.Н. управляющий / VBG редактор / НН".
Добавьте эти шаблоны к грамматике, по одному в каждой строке.  Проверьте свою работу, используя некоторые маркированные предложения своего собственного изобретения.</li>
<li>◑ Написать один или несколько шаблонов тегов для обработки скоординированные существительного фраз, например, "июль / ННП и / CC августа / ННП", "все / DT ваши / PRP $ менеджеров / NNS и / CC супервайзеры / NNS», «Компания / NN суды / NNS и / CC вершителями / NNS ".</li>
<li>◑ Выполните следующие задачи оценки для любого из chunkers вы разработали ранее.
(Обратите внимание, что большинство корпусы содержат разделения на порции некоторые внутренние противоречия, таким образом, что любой разумный подход на основе правил будет производить ошибки.)<ol class="loweralpha">
<li>Оцените свою Chunker на 100 предложений от фрагментированное корпуса, и сообщить о точности, напомним, и F-мера.</li>
<li>Используйте <tt class="doctest"><span class="pre">chunkscore.missed ()</span></tt> и <tt class="doctest"><span class="pre">chunkscore.incorrect ()</span></tt> методы для выявления ошибок , допущенных вашим Chunker.  Обсудить.</li>
<li>Сравните производительность вашего Chunker к исходному Chunker обсуждается в разделе, посвященном оценке данной главы.</li>
</ol>
</li>
<li>◑ Разработка Chunker для одного из типов фрагмента в корпусе CoNLL , используя кусок грамматики регулярных выражений на основе <tt class="doctest"><span class="pre">RegexpChunk.</span></tt>  Используйте любую комбинацию правил для отрывов, звон, слияния или разделения.</li>
<li>◑ Иногда слово неправильно помечено, например, глава существительным в "12 / CD или / CC так / RB случаев / VBZ".  Вместо того, чтобы требовать ручной коррекции выходного Таггер, хорошие chunkers способны работать с ошибочному выходом Taggers.  Посмотрите на другие примеры правильно Chunked словосочетания с неправильными тегами.</li>
<li>◑ The Биграммные Chunker оценки точности около 90%.
Изучите свои ошибки и попытаться выяснить, почему он не получает 100% точность.
Эксперимент с триграмме CHUNKING.  в состоянии улучшить производительность больше Вы?</li>
<li>★ Примените энграмм и методы мечения Brill к IOB куска мечения.
Вместо назначения POS-тегов на словах, здесь мы назначим IOB теги к POS-тегов.  Например , если тег <tt class="doctest"><span class="pre">DT</span></tt> (детерминанта) часто происходит в начале куска, то он будет помечен <tt class="doctest"><span class="pre">B</span></tt> (начать).  Оценка эффективности этих методов отрывов по отношению к обычным методам экспрессии комков, описанных в этой главе.</li>
<li>★ Мы видели в <a class="reference external" href="http://www.nltk.org/book/ch05.html#chap-tag">5.</a> что можно установить верхний предел для мечения производительности путем поиска неоднозначных н-г, N-грамм, которые помечены в более чем один из возможных путей в обучающих данных.
Примените тот же метод, чтобы определить верхнюю границу на выполнение п-грамм Chunker.</li>
<li>★ Выберите один из трех типов фрагмента в корпусе CoNLL.  Написать функции для выполнения следующих задач для выбранного типа:<ol class="loweralpha">
<li>Список всех последовательностей тегов, которые происходят с каждым экземпляром этого типа куска.</li>
<li>Подсчитайте частоту каждой последовательности тегов, и производят ранжированный список в порядке убывания частоты; каждая строка должна состоять из целого числа (частота) и последовательность тегов.</li>
<li>Проверьте последовательности тегов на высоких частотах.  Используйте их в качестве основы для разработки лучшего Chunker.</li>
</ol>
</li>
<li>★ Базовый Chunker представлены в разделе, посвященном оценке, как правило, создают большие куски, чем следовало.  Например, фраза: <tt class="doctest"><span class="pre">[каждое / DT раз / NN] [она / PRP] видит / VBZ [газета / DT / NN]</span></tt> содержит два последовательных ломти, и наша базовая Chunker будет неправильно сочетать первые два: <tt class="doctest"><span class="pre">[каждое / DT время / NN / она PRP].</span></tt>
Написать программу, которая находит какой из этих куска внутренние теги обычно происходит в начале куска, а затем разработать одно или несколько правил, которые будут дробить эти куски.
Комбинируйте их с существующим базовым Chunker и переоценивать его, чтобы увидеть, если вы обнаружили улучшенную базовую линию.</li>
<li>★ Разработка Chunker <tt class="doctest"><span class="pre">NP</span></tt> , который преобразует POS-меченый текст в список кортежей, где каждый кортеж состоит из глагола , за которым следует последовательность существительного фраз и предлоги, <tt class="doctest"><span class="pre">например, маленький кот сидел на ковре</span></tt> будет <tt class="doctest"><span class="pre">( <span class="pysrc-string">'сел',</span> <span class="pysrc-string">'на <span class="pysrc-string">','</span></span> <span class="pysrc-string">НП ')</span></span></tt> ...</li>
<li>★ Пенн Treebank содержит раздел помеченной текста Wall Street Journal, который был разбит на словосочетания.  Формат использует квадратные скобки, и мы сталкивались с этим несколько раз в этой главе.
Treebank корпус можно получить с помощью: <tt class="doctest"><span class="pre"><span class="pysrc-keyword">для</span> послана <span class="pysrc-keyword">в</span> nltk.corpus.treebank_chunk.chunked_sents (FILEID).</span></tt>  Эти плоские деревья, так же , как мы получили с помощью <tt class="doctest"><span class="pre">nltk.corpus.conll2000.chunked_sents ().</span></tt><ol class="loweralpha">
<li>Функции <tt class="doctest"><span class="pre">nltk.tree.pprint ()</span></tt> и <tt class="doctest"><span class="pre">nltk.chunk.tree2conllstr ()</span></tt> могут быть использованы для создания Treebank и IOB строки из дерева.
Прописывать функции <tt class="doctest"><span class="pre">chunk2brackets ()</span></tt> и <tt class="doctest"><span class="pre">chunk2iob ()</span></tt> , которые принимают одну порцию дерева в качестве единственного аргумента, и вернуть требуемую многострочный строковое представление.</li>
<li>Написать утилиты командной строки преобразования <tt class="doctest"><span class="pre">bracket2iob.py</span></tt> и <tt class="doctest"><span class="pre">iob2bracket.py</span></tt> , которые принимают файл в формате Treebank или CoNLL (соответственно) и преобразовать его в другой формат.  (Получить некоторые сырые Treebank или CoNLL данные из NLTK корпусы, сохраните его в файл, а затем использовать <tt class="doctest"><span class="pre"><span class="pysrc-keyword">для</span> строки <span class="pysrc-keyword">в</span> открытом (имя файла)</span></tt> , чтобы получить доступ к нему из Python.)</li>
</ol>
</li>
<li>★ N-грамм Chunker может использовать информацию , отличную от текущей частичной части речи тега и предыдущих тегов порций <span class="math">п-1.</span>
Исследовать другие модели контекста, такие как <span class="math">п-1</span> предыдущая часть из-тегов речи или некоторой комбинации предыдущих тегов куска вместе с предыдущими и следующими тегами часть-оф-речи.</li>
<li>★ Рассмотрим путь п-грамм Таггер использует последние теги сообщить свой выбор мечения.
Теперь наблюдать, как Chunker может повторно использовать эту информацию о последовательности.  Например, обе задачи будут использовать информацию, что существительные имеют тенденцию следовать прилагательные (на английском языке).  Казалось бы, что та же информация поддерживается в двух местах.  Это может стать проблемой, так как размер наборов правил растет?
Если да, то рассуждать о каких-либо способов, что эта проблема может быть решены.</li>
</ol>
<!-- Footer to be used in all chapters -->
<div class="admonition-about-this-document admonition">
<p class="first admonition-title">Об этом документе ...</p>
<p>Обновлялся для NLTK 3.0.
Это глава из книги <em>Обработка естественного языка с помощью Python</em> написанной <a class="reference external" href="http://estive.net/">Стивеном Бердом</a> , <a class="reference external" href="http://homepages.inf.ed.ac.uk/ewan/">Эваном Клайном</a> и <a class="reference external" href="http://ed.loper.org/">Эдвардом Лопером</a> , Copyright © 2014 авторов.
Он распространяется с <em>Набором инструментов для естественного языка</em> <tt class="doctest"><span class="pre">[http://nltk.org/],</span></tt> версия 3.0 в соответствии с условиями <em>Creative Commons Attribution-Noncommercial-No Derivative Works 3.0 Лицензии Соединенных Штатов</em> [ <a class="reference external" href="http://creativecommons.org/licenses/by-nc-nd/3.0/us/">http://creativecommons.org/licenses/by-nc-nd/3.0/us/</a>].</p>
<p class="last">Этот документ был построен на ср 1 июля 2015 12:30:05 AEST</p>
</div>
<!-- Not used anymore:
Identifying the boundaries of specific types of word sequences is also
required when we want to recognize pieces of syntactic
structure. Suppose for example that as a preliminary to named entity
recognition, we have decided that it would be useful to just pick out
noun phrases from a piece of text. To carry this out in a complete
way, we would probably want to use a proper syntactic parser. But
parsing can be quite challenging and computationally expensive |mdash|
is there an easier alternative? The answer is Yes: we can look for
sequences of part-of-speech tags in a tagged text, using one or more
patterns that capture the typical ingredients of a noun phrase. -->
</div>
</div>
</body>
</html>